{"posts":[{"title":"常见的网络排查工具和命令","content":"常见的网络排查工具和命令 命令 ping：测试目的ip是否可达，测试网络延迟和丢包情况 linux下执行ping命令会一直进行，-n可以指定ping的次数。windows下ping命令默认执行4次，需要一直ping的话加上-t参数 ping不通的原因可能是目标地址不可达，也有可能是对方禁ping。 linux服务器禁ping的方式： windows禁ping的方式：高级windows安全防火墙--&gt;入站规则--&gt;文件和打印机共享(回显请求 - ICMP-in)这两条规则不启用即可 ping命令使用的是ICMP协议 可以看到，我本地到8.219.118.44就不是很稳定，有丢包情况 tcping：基于TCP协议的ping工具 ping命令基于ICMP协议，如果服务端禁ping了，可以尝试使用tcping工具。比如检测8.219.118.44的22端口联通情况 traceroute工具：检测去程路由 该命令在windows系统下面为tracert。可以显示本机到目标IP之间经过所有的路由信息。当网络不稳定的时候，可以用这个命令来排查是哪一跳的网络比较慢。 traceroute使用的协议的ICMP协议，和ping命令一样 ubuntu系统安装traceroute命令：apt install traceroute MTR工具：检测回程路由 mtr使用的协议为ICMP协议，和ping命令，traceroute命令一样 windows安装mtr工具：安装WinMTR ubuntu系统安装mtr工具：apt install mtr-tiny --report参数默认会发送10个ICMP包，如果不加任何参数，会进入一个动态界面，会不断发包吗，查看实时丢包率。大多数情况下使用--report就够了。 mtr命令的输出结果： 第一列就是各个节点的 IP 地址 第二列（Loss%）是丢包率 第三列（Snt）是发包书 第四列（Last）是最后一次发包的时延 第五列（Avg）是平均时延 第六列（Best）是最好的一次的时延，然后是最差的一次的时延（Wrst） 以及最后一列（StDev）是数据包在每个节点上的标准偏差。标准偏差越高，说明在这个节点上的时延越不稳定。如果标准偏差较高，那么可以考虑查看最高时延和最低时延来判断该节点的网络状况。 telnet：检测端口连通性或者用来远程登陆 协议：TCP协议。 ubuntu系统安装telnet：apt install telnet 通常可以用来检测目标地址的指定端口有没有监听。 nc：网络工具 全称netcat，被称为网络安全界的“瑞士军刀”。意思就是功能非常强大的意思。 ubuntu系统安装nc工具：apt install netcat-traditional netstat/ss：查看网络连接情况 ubuntu系统安装netstat命令：apt install net-tools ip命令 tcpdump：常见的命令行抓包工具 tcpdump命令是使用较为复杂，不过网上有个别人整理的常见操作，需要用的时候参考一下就可以了：tcpdump Cheat Sheet tcpdump抓的是原始的网络数据包，可能不太好分析，一般使用wireshark或者科来网络分析工具来分析 wireshark：抓包分析工具 它的界面长这个样子，可以对指定的网卡抓包分析，很强大的一款工具 科来网络分析工具：抓包分析工具 界面比wireshark更友好一点，适合我这种小白用户使用 ","link":"http://quansen88.cn/XZSl5Ip-V/"},{"title":"计算机 linux 红帽认证 rhce证书 技术支持","content":" ","link":"http://quansen88.cn/3DmsVsFw5/"},{"title":"计算机 linux 红帽认证 rhce证书 技术支持","content":" ","link":"http://quansen88.cn/RHCE/"},{"title":"Docker registry部署私有镜像仓库","content":"准备工作： 一台2C4G的虚拟机，ubuntu22.04操作系统 域名证书，在阿里云上面申请 一、给机器安装docker环境（参考这里） 1.1 更新软件包列表 1.2 安装一些必要的软件包 1.3 配置docker存储库以及gpg密钥 1.4 安装docker 1.5 配置docker镜像加速器并启动docker 1.6 安装docker-compose命令，只需要下载下来放到bin目录下就可以了 下载地址：https://github.com/docker/compose/releases，选择2.10.0版本的docker-compose-linux-x86_64文件 二、部署registry 这里） 2.1 将域名证书放到虚拟机上面 #创建一个目录用来存放证书 2.2 创建一个密码文件，用户名为redhat，密码为redha656 2.3 创建registry容器 2.4 检查容器启动成功 2.5 配置DNS解析 将registry字段域名解析到该服务器ip 三、开始使用registry 3.1登陆registry 3.2 从dockerhub拉取httpd镜像 3.3 修改镜像标签，推送到自己的仓库 四、使用podman搜索和拉取镜像 4.1登陆registry 4.2搜索httpd镜像 4.3拉取镜像 完成！ ","link":"http://quansen88.cn/wIXBp-umG/"},{"title":"kms激活win11 Pro","content":"20210617kms激活win11 Pro 【kms服务器】参考：https://hub.docker.com/r/luodaoyi/kms-server 一、管理员权限运行cmd 根据系统版本安装key a. 获取系统版本信息 b. 得到对应key后，安装key [pro] 测试版居然能用win10的key 意料之外情理之中 官网key：https://technet.microsoft.com/en-us/library/jj612867.aspx 经测密钥无法使用怎么激活win11系统?win11激活密钥+激活工具分享_windows11_Windows系列_操作系统_脚本之家 (jb51.net) 或从下方查找 设置激活服务端的地址 服务器地址失效请百度找一个 本地kms可行 可尝试第三方激活软件 尝试激活 二、完成 Windows GVLK密钥对照表（KMS激活专用） Windows 11 操作系统 KMS激活序列号 Windows 11 home YTMG3-N6DKC-DKB77-7M9GH-8HVX7 Windows 11 pro [经测996测试版不能用但win10的可以]VK7JG-NPHTM-C97JM-9MPGT-3V66T 以下key来源于微软官网：https://technet.microsoft.com/en-us/library/jj612867.aspx Windows Server 2016 操作系统 KMS激活序列号 Windows Server 2016 Datacenter CB7KF-BWN84-R7R2Y-793K2-8XDDG Windows Server 2016 Standard WC2BQ-8NRM3-FDDYY-2BFGV-KHKQY Windows Server 2016 Essentials JCKRF-N37P4-C2D82-9YXRT-4M63B Windows 10 操作系统 KMS激活序列号 Windows 10 Professional W269N-WFGWX-YVC9B-4J6C9-T83GX Windows 10 Professional N MH37W-N47XK-V7XM9-C7227-GCQG9 Windows 10 Enterprise NPPR9-FWDCX-D2C8J-H872K-2YT43 Windows 10 Enterprise N DPH2V-TTNVB-4X9Q3-TJR4H-KHJW4 Windows 10 Education NW6C2-QMPVW-D7KKK-3GKT6-VCFB2 Windows 10 Education N 2WH4N-8QGBV-H22JP-CT43Q-MDWWJ Windows 10 Enterprise 2015 LTSB WNMTR-4C88C-JK8YV-HQ7T2-76DF9 Windows 10 Enterprise 2015 LTSB N 2F77B-TNFGY-69QQF-B8YKP-D69TJ Windows 10 Enterprise 2016 LTSB DCPHK-NFMTC-H88MJ-PFHPY-QJ4BJ Windows 10 Enterprise 2016 LTSB N QFFDN-GRT3P-VKWWX-X7T3R-8B639 Windows Server 2012 R2 和 Windows 8.1 操作系统 KMS激活序列号 Windows 8.1 Professional GCRJD-8NW9H-F2CDX-CCM8D-9D6T9 Windows 8.1 Professional N HMCNV-VVBFX-7HMBH-CTY9B-B4FXY Windows 8.1 Enterprise MHF9N-XY6XB-WVXMC-BTDCT-MKKG7 Windows 8.1 Enterprise N TT4HM-HN7YT-62K67-RGRQJ-JFFXW Windows Server 2012 R2 Server Standard D2N9P-3P6X9-2R39C-7RTCD-MDVJX Windows Server 2012 R2 Datacenter W3GGN-FT8W3-Y4M27-J84CP-Q3VJ9 Windows Server 2012 R2 Essentials KNC87-3J2TX-XB4WP-VCPJV-M4FWM Windows Server 2012 和 Windows 8 操作系统 KMS激活序列号 Windows 8 Professional NG4HW-VH26C-733KW-K6F98-J8CK4 Windows 8 Professional N XCVCF-2NXM9-723PB-MHCB7-2RYQQ Windows 8 Enterprise 32JNW-9KQ84-P47T8-D8GGY-CWCK7 Windows 8 Enterprise N JMNMF-RHW7P-DMY6X-RF3DR-X2BQT Windows Server 2012 BN3D2-R7TKB-3YPBD-8DRP2-27GG4 Windows Server 2012 N 8N2M2-HWPGY-7PGT9-HGDD8-GVGGY Windows Server 2012 Single Language 2WN2H-YGCQR-KFX6K-CD6TF-84YXQ Windows Server 2012 Country Specific 4K36P-JN4VD-GDC6V-KDT89-DYFKP Windows Server 2012 Server Standard XC9B7-NBPP2-83J2H-RHMBY-92BT4 Windows Server 2012 MultiPoint Standard HM7DN-YVMH3-46JC3-XYTG7-CYQJJ Windows Server 2012 MultiPoint Premium XNH6W-2V9GX-RGJ4K-Y8X6F-QGJ2G Windows Server 2012 Datacenter 48HP8-DN98B-MYWDG-T2DCC-8W83P Windows 7 and Windows Server 2008 R2 操作系统 KMS激活序列号 Windows 7 Professional FJ82H-XT6CR-J8D7P-XQJJ2-GPDD4 Windows 7 Professional N MRPKT-YTG23-K7D7T-X2JMM-QY7MG Windows 7 Professional E W82YF-2Q76Y-63HXB-FGJG9-GF7QX Windows 7 Enterprise 33PXH-7Y6KF-2VJC9-XBBR8-HVTHH Windows 7 Enterprise N YDRBP-3D83W-TY26F-D46B2-XCKRJ Windows 7 Enterprise E C29WB-22CC8-VJ326-GHFJW-H9DH4 Windows Server 2008 R2 Web 6TPJF-RBVHG-WBW2R-86QPH-6RTM4 Windows Server 2008 R2 HPC edition TT8MH-CG224-D3D7Q-498W2-9QCTX Windows Server 2008 R2 Standard YC6KT-GKW9T-YTKYR-T4X34-R7VHC Windows Server 2008 R2 Enterprise 489J6-VHDMP-X63PK-3K798-CPX3Y Windows Server 2008 R2 Datacenter 74YFP-3QFB3-KQT8W-PMXWJ-7M648 Windows Server 2008 R2 for Itanium-based Systems GT63C-RJFQ3-4GMB6-BRFB9-CB83V Windows Vista and Windows Server 2008 操作系统 KMS激活序列号 Windows Vista Business YFKBB-PQJJV-G996G-VWGXY-2V3X8 Windows Vista Business N HMBQG-8H2RH-C77VX-27R82-VMQBT Windows Vista Enterprise VKK3X-68KWM-X2YGT-QR4M6-4BWMV Windows Vista Enterprise N VTC42-BM838-43QHV-84HX6-XJXKV Windows Web Server 2008 WYR28-R7TFJ-3X2YQ-YCY4H-M249D Windows Server 2008 Standard TM24T-X9RMF-VWXK6-X8JC9-BFGM2 Windows Server 2008 Standard without Hyper-V W7VD6-7JFBR-RX26B-YKQ3Y-6FFFJ Windows Server 2008 Enterprise YQGMW-MPWTJ-34KDK-48M3W-X4Q6V Windows Server 2008 Enterprise without Hyper-V 39BXF-X8Q23-P2WWT-38T2F-G3FPG Windows Server 2008 HPC RCTX3-KWVHP-BR6TB-RB6DM-6X7HP Windows Server 2008 Datacenter 7M67G-PC374-GR742-YH8V4-TCBY3 Windows Server 2008 Datacenter without Hyper-V 22XQ2-VRXRG-P8D42-K34TD-G3QQC Windows Server 2008 for Itanium-Based Systems 4DWFP-JF3DJ-B7DTH-78FJB-PDRHK ","link":"http://quansen88.cn/xvRxb2T0y/"},{"title":" docker多阶段构建离线yum源(修改)","content":"docker多阶段构建离线yum源(修改) 有需要就会有需求 一、目录结构 二、Dockerfile 三、pkg.list 四、nginx.conf 五、index.html 六、最终效果： ","link":"http://quansen88.cn/b8x2Z_v5U/"},{"title":"wsl 另一个程序正在使用此文件，进程无法访问。","content":" wsl -d ubuntu20.04 报错： wsl 另一个程序正在使用此文件，进程无法访问。 网络： Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux 来自 https://blog.csdn.net/qq_38666896/article/details/113810463 不敢使用， net stop LxssManager 双击vbs 还是连不上 4. 再次重启 net stop LxssManager wsl进入 wsl -d ubuntu20.04 还是报错 另一个程序正在使用此文件，进程无法访问。 Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux 报错 'Enable-WindowsOptionalFeature' 不是内部或外部命令，也不是可运行的程序 或批处理文件。 Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux 没报错 wsl -l --running 没有正在运行的分发。 wsl -d ubuntu20.04 报错 另一个程序正在使用此文件，进程无法访问。 重启后就可以打开了 成因： 【真假难以确认，需要重现，但的确操作过】 在未开启的情况下尝试使用资源管理器打开该vhdx文件，导致资源管理器占用该文件 【资源管理器无法打开该vhdx文件，是否真的能挂载是一个谜】 踩坑： 直接重启，或清理资源管理器缓存再重启，是没有用的 【据网上所说，未重现，确认】 解决方案： A. 管理员打开powershell 运行： Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux B. 重启电脑 ","link":"http://quansen88.cn/rev-xznuT/"},{"title":" K8S安装过程笔记","content":"K8S安装过程笔记 以下所有操作均基于Cent OS 7操作系统。 来自：http://blog.hungtcs.top/2019/11/27/23-K8S安装过程笔记/ 基本环境配置 关闭selinux 关闭swap分区或禁用swap文件 修改网卡配置 启用内核模块 关闭防火墙 配置hosts kubectl、kubeadm、kubelet的安装 添加Kubernetes的yum源 此处使用alibaba的镜像源 安装kubelet、kubeadm、kubectl 启动kubelet服务 此时执行systemctl status kubelet查看服务状态，服务状态应为Error(255)， 如果是其他错误可使用journalctl -xe查看错误信息。 Docker安装和配置 Docker安装 docker的安装请查看官网文档(Overview of Docker editions)[https://docs.docker.com/install/overview/] Docker配置 配置cgroup-driver为systemd 预先拉取所需镜像 对预先拉取的镜像重新打tag Master节点的配置 以上步骤需要在node节点和master节点执行，当前步骤仅需在master节点执行。 Master节点的初始化 执行上述命令的输出为： 保存输出中的kubeadm join部分内容，用于添加node节点，或者使用kubeadm token list 和kubeadm token create --print-join-command查看 接下来执行剩余的初始化步骤 Calico网络插件的配置 Calico的官方文档地址为： https://docs.projectcalico.org/v3.10/getting-started/kubernetes/。 具体安装步骤： 安装Calico 监听安装进度 出现以下内容时为安装成功 测试 Node节点的初始化 登录node节点，执行加入集群的命令，完成加入集群操作 在master节点上查看添加结果 ","link":"http://quansen88.cn/f8YG9Dtq_/"},{"title":" ubuntu16.04图形化基础配置","content":"ubuntu16.04图形化基础配置 一、安装：略 二、环境配置 2.1软件源 参考server 2.2安装常用命令 2.3设置语言 设置里 2.4搜狗输入法 官方网站 2.5wps 官网 2.6ffmpeg转码器 2.7播放器 参考：https://www.jianshu.com/p/f24252c632d0 2.8单机vnc x11vnc 2.9real vnc v6.6 支持多用户连:https://www.realvnc.com/en/connect/download/vnc/linux/ 2.10 文本编辑器 vscode notepad 2.11 markdown trpora 2.12 3D特效 2.13左边菜单栏在底部显示 2.14 vmware桥接网卡配置 https://kb.vmware.com/s/article/287?lang=zh_CN 2.15 远程链接工具 securecrt 2.16 python pycharm 2.17 java eclipse Intellij IDEA 三、基于ubuntu的系统： Elementary OS：很好看 优麒麟，不好用 四、基于debian的deepin 软件多，好看，华为linux笔记本自带此系统 ubuntu官方有openstack，kubernetes解决方案 ","link":"http://quansen88.cn/f_vQ7vXqk/"},{"title":" EFK教程三：ElasticSearch多实例部署","content":"EFK教程三：ElasticSearch多实例部署 用途： ▷ 在第一篇《EFK教程 - 快速入门指南》中，阐述了EFK的安装部署，其中ES的架构为三节点，即master、ingest、data角色同时部署在三台服务器上。 ▷ 在第二篇《EFK教程 - ElasticSearch高性能高可用架构》中，阐述了EFK的data/ingest/master角色的用途及分别部署三节点，在实现性能最大化的同时保障高可用 前两篇文章，ES集群中只存在一个实例，而在本文中，将在一个集群中部署多个ES实例，来实现资源合理分配。例如data服务器存在SSD与SAS硬盘，可以将热数据存放到SSD，而冷数据存放到SAS，实现数据冷热分离。 ▷ 服务器配置： 名称 IP CPU 内存 SAS硬盘 SSD硬盘 访问端口 运输端口 filebeat 172.18.1.237 2 2G / / kibana 172.18.4.4 2 2G / / 5601 / elasticsearch-master-1 172.18.3.138 4 4G / / 9200 9300 elasticsearch-master-2 172.18.3.139 4 4G / / 9200 9300 elasticsearch-master-3 172.18.3.253 4 4G / / 9200 9300 elasticsearch-ingest-1 172.18.4.18 2 1G / / 9200 9300 elasticsearch-ingest-2 172.18.4.19 2 1G / / 9200 9300 elasticsearch-ingest-3 172.18.4.20 2 1G / / 9200 9300 elasticsearch-data-1-SAS 172.18.4.21 1 1G 10G / 9200 9300 elasticsearch-data1-SSD 172.18.4.21 1 1G / 10G 9201 9301 elasticsearch-data-2-SAS 172.18.4.22 1 1G 10G / 9200 9300 elasticsearch-data-2-SSD 172.18.4.22 1 1G / 10G 9201 9301 elasticsearch-data-3-SAS 172.18.4.23 1 1G 10G / 9200 9300 elasticsearch-data-3-SSD 172.18.4.23 1 1G / 10G 9201 9301 ▷ 架构图 一、先启动各节点的服务 查看各节点的健康状态 查看集群节点列表 二、es-data1部署双实例 1️⃣迁移索引： 确保索引不在当前实例上 2️⃣部署es-data1双实例 条件有限，没有挂载新的硬盘用，创建目录代替 代码目录 数据目录 访问端口 运输端口 /opt/elasticsearch-SAS /data/SAS 9200 9300 /opt/elasticsearch-SSD /data/SSD 9201 9301 三、es-data2部署双实例 1️⃣迁移索引： 条件有限，没有挂载新的硬盘用，创建目录代替 代码目录 数据目录 访问端口 运输端口 /opt/elasticsearch-SAS /data/SAS 9200 9300 /opt/elasticsearch-SSD /data/SSD 9201 9301 确保索引不在当前实例上 当前索引在es-data2，es-data3上 当前集群节点查看 迁移索引到别的节点 查看当前索引位置 2️⃣部署es-data2双实例 旧的SAS实例 新的SSD实例 注意节点名字，data位置，log位置，本结点访问端口，本结点运输端口，集群中其他主机及端口号，master节点端口号 启动两个实例： 四、es-data3部署双实例 1️⃣迁移索引： 条件有限，没有挂载新的硬盘用，创建目录代替 代码目录 数据目录 访问端口 运输端口 /opt/elasticsearch-SAS /data/SAS 9200 9300 /opt/elasticsearch-SSD /data/SSD 9201 9301 确保索引不在当前实例上 当前索引在es-data1，es-data3上 当前集群节点查看 迁移索引到别的节点 查看当前索引位置 2️⃣部署es-data2双实例 旧的SAS实例 新的SSD实例 注意节点名字，data位置，log位置，本结点访问端口，本结点运输端口，集群中其他主机及端口号，master节点端口号 启动两个实例 五、确认集群节点的信息 集群健康状态： 集群节点现在应该多了三个 当前索引位置 使用下面命令将索引迁移到每个data节点 六、测试 将所有索引迁移到SSD硬盘上 确认所有索引全在SSD硬盘上 将nginx11月份的日志索引迁移到SAS硬盘上 ","link":"http://quansen88.cn/P2z_fsOWw/"},{"title":" 修改nginx镜像时区","content":"修改nginx镜像时区 问题： 容器时间正确的要求： 宿主机时间正确 容器时区正确 宿主机时间 容器时区 对比两个镜像大小 日志时间正确了 ","link":"http://quansen88.cn/lg6bpjVDB/"},{"title":" ws+tls+web+cdn","content":"ws+tls+web+cdn 一、ws就是websocket 配置就是加了个streamsettings，把network配置成ws即可 二、tls就是传输层安装协议 也就是https证书，也就是说要有个域名 三、web 就是有个web页面用于伪装，这里用的是nginx，访问域名正常就跳到web界面，访问指定location跳转到vmess 四、cdn，就是用到了cdn 即cloudfare，找不到真实后端服务器（其实还是可以） 五、整个实验使用docker部署 如下图用到两个容器，一个nginx，一个vmess 六、vmess的配置 七、nginx配置 目录结构 nginx配置 proxy_pass那里还没经过测试，不行的话就用IP吧。注意：域名，证书，location的path 启动nginx ","link":"http://quansen88.cn/JgHhiXdnK/"},{"title":" JS实现网站内容的禁止复制和粘贴、另存为","content":"JS实现网站内容的禁止复制和粘贴、另存为 参考：https://www.cnblogs.com/lxg0/p/7251386.html google搜索“document.oncontextmenu=true;document.onselectstart=true”会有更多详细文章 使右键和复制失效 使菜单&quot;文件&quot;－&quot;另存为&quot;失效” 使右键和复制失效 方法一 在网页中加入以下代码： 方法二 在网页中加入以下代码： 或者加入在加入： 方法三 如果只限制复制，可以在加入以下代码： 使菜单&quot;文件&quot;－&quot;另存为&quot;失效 如果只是禁止了右键和选择复制，别人还可以通过浏览器菜单中的&quot;文件&quot;－&quot;另存为&quot;拷贝文件。为了使拷贝失效，可以在与之间加入以下代码： 这样，用户在另存网页时，就会出现&quot;无法保存Web页&quot;的错误。 另外，也可以使用event.preventDefault() 方法来阻止oncontextmenu() 还有onselectstart() 既然可以禁止，那么当然也可以启用它，将事件重新赋值即可，可以赋值为null，或字符串、布尔值都行。如： ","link":"http://quansen88.cn/0tPsmegXQ/"},{"title":" 关于docker的scratch镜像与helloworld","content":"关于docker的scratch镜像与helloworld 参考：https://hub.docker.com/_/scratch?tab=description 参考：https://segmentfault.com/a/1190000000628247 FROM scratch 官方说明：该镜像是一个空的镜像，可以用于构建busybox等超小镜像，可以说是真正的从零开始构建属于自己的镜像。要知道，一个官方的ubuntu镜像有60MB+，CentOS镜像有70MB+ 可以把一个可执行文件扔进来直接执行 一、注意：scratch不可用被pull FROM scratch专门用于构建最小镜像，直接pull会报以下错误，scratch是一个保留名称 二、如何制作大小为0 的镜像 既然scratch不能被拉取，如何做到docker image ls看到一个0字节的镜像 官方给出了下面方法： 三、如何跑一个helloworld 可以参考：https://github.com/docker-library/hello-world/ 3.1C语言不行，docker是go语言写的，跑的话报错 Dockerfile 果然报错 ubuntu当然可以 官方的这个竟然有点看不懂了，c语言：https://github.com/docker-library/hello-world 3.2go语言 使用go语言写：https://github.com/adriaandejonge/helloworld 一个helloworld都这么大... 也没用过go，网上了解到加个选项就能变小：https://www.jianshu.com/p/1405b0c2c5a3 3.3改写官方的helloword hello.c 编译 dockerfile 四、补充 gcc -D可以定义宏，起到替换、条件编译的功能；即hello.c中定义了一个宏，我可以在gcc编译时使用-D替换该宏。就好像我docker镜像定义了一些变量，但是docker run仍可以-e传递变量，覆盖原有的变量 gcc -static指定强制使用静态库， -O 对程序进行优化编译、链接。采用这个选项，整个源代码会在编译、链接过程中进行优化处理，这样产生的可执行文件的执行效率可以提高，但是编译、链接的速度就相应地要慢一些，而且对执行文件的调试会产生一定的影响，造成一些执行效果与对应源文件代码不一致等一些令人“困惑”的情况。因此，一般在编译输出软件发行版时使用此选项。 -Os 使用了所有-O2的优化选项，但又不缩减代码尺寸的方法 https://www.cnblogs.com/luolizhi/p/5737091.html -nostartfiles 连接的使用不使用标准系统库。只有你指定的库才能够传递给连接器。不链接系统标准启动文件,而标准库文件仍然正常使用 -fno-asynchronous-unwind-tables 用来不生成CFI指令 -o 输出文件名 stribe 给文件脱裤子。具体就是从特定文件中剥掉一些符号信息和调试信息。 在strip之后， 文件变小了， 仍然可以执行， 这就就节省了很多空间。 ","link":"http://quansen88.cn/4ZumkVtyg/"},{"title":"WDS部署","content":"参考：https://blog.51cto.com/14449541/2426900 https://www.itsk.com/forum.php?mod=viewthread&amp;tid=391485&amp;highlight=wds 条件： 激活的windows2016系统 win10 1909镜像 1.服务器安装WindowsSever系统启用添加WDS服务 2.添加带网卡驱动的PE做启动映像 3.客户机BIOS开启PXE 4.启动菜单选择PXE启动（支持UEFI启动） 5.进入PE做系统等操作 一、WDS部署服务的配置 1.1、添加角色和功能 1.2、安装完成后左边多了一个WDS 1.3、继续配置WDS 1.4添加启动映像 1.5添加其他pe的启动映像 比如wepe 其他pe：http://bbs.wuyou.net/forum.php?mod=viewthread&amp;tid=370573 链接：https://pan.baidu.com/s/1b_IiRQ6JwspSeKIwau2VcA 提取码：9qgr 1.6启动客户机测试一下 1.7pe定制说明 暂时没这个需要，不做了 1.8网络映射 这一步的目的是上面操作只设置了启动映像，并没有安装映像，因此这一步可以通过windows共享，或者ftp或者smb让pe系统连到共享服务器上获取镜像，不过这样就需要pe带网络功能了，很遗憾，wepe不带网络功能，可以选择百度云中的镜像作为启动映像 如果pe确实没网络，下面添加安装映像 1.9添加安装映像 1.10把电脑的名字改短一点，待会儿要登陆 1.11找一个电脑测试 ","link":"http://quansen88.cn/UcUw5zbco/"},{"title":" KVM实验（一）","content":"KVM实验（一） 参考：https://www.cnblogs.com/wn1m/p/11281576.html 一、验证是否开启虚拟化 二、安装工具 qemu-kvm(kvm在用户空间的管理工具),libvirt(一个服务，其下组件可用来管理kvm虚拟机) libvirt安装完后会创建virbr0网桥 三、相关命令 四、启动服务 五、libvirt0-client已经安装，virt-install安装下，管理虚拟机的 六、安装vncserver待会儿要用（好像不需要） 七、创建自己的网桥br0，不用自动创建的 删除之前的网桥 八、下载镜像 九、创建10G磁盘空间 十、创建虚拟机 十一、vnc连接 失败了，连不上，网上也找不到资料，都是virt-manager管理的，之前我用ubuntu是可以的 换了vnc可以连上了：https://www.realvnc.com/download/file/viewer.files/VNC-Viewer-6.19.1115-Windows-64bit.exe 销毁虚拟机： 十二、令一种方法来创建虚拟机 创建系统盘 开始安装： 安装界面： 语言设置： 时区： ntp配置： 关闭kdump 网络配置：开启启动 root密码： b开始安装 成功了： 十三、关于如何看虚拟机的ip 网上大多是virsh edit [虚拟机名字]得到mac地址，然后arp看本机arp路由表 脚本来自：https://www.v2ex.com/t/197481 十四、虚拟机的其他操作 14.1查看所有虚拟机列表 14.2启动虚拟机 14.3关闭虚拟机 14.4设置虚拟机开机自启动 14.5挂起和恢复虚拟机 14.6重启虚拟机 14.7强制关闭虚拟机 通过这一步，可以发现virsh只不过是一个管理工具而已 14.8查看虚拟机网卡信息 可以看到mac信息 14.9查看 kvm 虚拟机磁盘信息 14.10查看虚拟机配置文件信息 14.11查看虚拟机的基本信息 十五、调整虚拟机磁盘大小 1、当前磁盘大小 2、查看虚拟机磁盘位置 3、查看磁盘信息 4、给磁盘加10G 5、重启虚拟机查看 下面实验证明了调整磁盘一定要关机后操作，然后启动 再次调整： vrish reboot还是不行，先关机，再开机就好了 十六、调整虚拟机内存 当前虚拟机内存 调整 调整后 十七、使用xml文件创建虚拟机 先传一个模版虚拟机 编写配置文件（大佬给的，暂时不会改） 使用配置文件定义虚拟机，然后开机 连接虚拟机试试 有点小问题，没有IP 修改配置文件，加上mac地址(mac地址还不能随便填，网上生成的不能用，我就照着其他的mac改了几位) ","link":"http://quansen88.cn/y0_4xzSo0/"},{"title":" kvm实战（二）","content":"kvm实战（二） 一、安装相关软件 二、启动服务 三、修改网卡配置 四、删除默认网卡，网络 五、镜像 六、创建磁盘 七、virt-install创建虚拟机 vnc连(这里遇到了一个坑，建议去官网下载vnc viewer连) 八、第一次备份（可以不用） 九、基本优化 十、第二次备份（可以作为模版用了） 十一、使用模版机克隆 1、准备xml文件 需要改的地方:name，memory，currentMemory，vcpu，source file（磁盘位置，镜像那也可以改下），mac address（不要随机生成，改几位就行） mac地址也可以用vmware生成 2、按照配置文件把qcow2文件和镜像放到对应目录 3、导入xml文件，启动 4、关于mac地址 参考：https://www.douban.com/note/733401994/ MAC（Media Access Control，介质访问控制）地址，或称为MAC位址、硬件地址，用来定义网络设备的位置。MAC集成在网卡，由48bit的2进制的数字组成，0~23位数字叫作组织唯一标志符（organizationally unique，是识别局域网节点的标识）。24~47位是由厂家自己分配，其中第48位是组播地址标志位。网卡的物理地址通常是由网卡生产厂家写入网卡的EPROM芯片中，芯片中的数据可以通过程序进行擦写，它存储的是传输数据时真正赖以标识发出数据的电脑和接收数据的主机的地址。也就是说，在网络底层的物理传输过程中，数据传输是通过物理地址来识别主机的，它一定是全球唯一的。 ","link":"http://quansen88.cn/iFS2Gihr6/"},{"title":" EFK教程 - EFK快速入门指南","content":"EFK教程 - EFK快速入门指南 参考：https://mp.weixin.qq.com/s/Kzqllh5VQedss2u-DSrDhQ 通过部署elasticsearch（三节点）+filebeat+kibana快速入门EFK，并搭建起可用的demo环境测试效果 用途： ▷ 通过filebeat实时收集nginx访问日志、传输至elasticsearch集群 ▷ filebeat将收集的日志传输至elasticsearch集群 ▷ 通过kibana展示日志 实验架构： ▷ 服务器配置： 名称 IP CPU 内存 filebeat 172.18.1.237 2 2G kibana 172.18.4.4 2 2G elasticsearch-1 172.18.3.138 4 4G elasticsearch-2 172.18.3.139 4 4G elasticsearch-3 172.18.3.253 4 4G ▷ 架构图 一、安装elasticsearch 三个机器都执行脚本 二、安装filebeat 三、安装kibana 四、nginx安装（用于生成日志，被filebeat收集） 五、elasticsearch配置 es-1(172.18.3.138) vim /opt/elasticsearch/config/elasticsearch.yml es-1(172.18.3.139) vim /opt/elasticsearch/config/elasticsearch.yml es-1(172.18.3.253) vim /opt/elasticsearch/config/elasticsearch.yml 六、filebeat配置 nginx(172.18.1.237) vim /opt/filebeat/filebeat.yml 七、kibana配置 kibana(172.18.4.4) vim /opt/kibana/config/kibana.yml 八、启动服务 kibana启动会报错： 暂时解决：用root启动：/opt/kibana/bin/kibana -c /opt/kibana/config/kibana.yml --allow-root 九、kibana界面配置 1、访问到下面界面表示kibana成功了： 2、点‘try ouer sample data’ 3、选no，不让kibana统计信息 4、选web log那个模版，点击添加data到kibana 5、进入视图（dashboard） 十、测试 1、访问nginx，产生日志 2、在kibana上看数据 （1）创建索引模版 （2）输入你要创建的索引模板的名字 （3）查看之前curl的数据 还可以转换成json查看 十一、获取集群的一些信息 1、查看集群的健康状态 关于这些参数参考：https://blog.csdn.net/weixin_44723434/article/details/90452083 停掉一个节点： 2、获取集群节点的列表 可以看到，有三个节点，以及机器的cpu负载情况，此时es-3是master 3、列出所有的索引 4、查询节点状态 http://172.18.3.253:9200/_nodes/stats?pretty 5、查看ES哪些进程在消耗资源 ","link":"http://quansen88.cn/jUw_76RJ6/"},{"title":"vsphere6.7（EXSI）服务器版的vmware","content":"花一天时间试玩vsphere6.7（EXSI）服务器版的vmware 要注册账号（2019年11月14注册）： 看了下。不管是标准版，企业版，测试版的6.7下载的软件包都是同一个，区别应该在于激活密钥 主要有两个镜像：EXXI镜像，VCenter镜像 EXSI和VMware有点像，不过可以直接装在裸机上，Vcenter需要装在windows server上，管理EXSI平台 **链接：**https://pan.baidu.com/s/1x8K4dnMdhg7uz11Hyi7v2A **提取码：**tqaw VMware vSphere 6 Enterprise Plus 0A65P-00HD0-3Z5M1-M097M-22P7H **参考文档：**https://pan.baidu.com/s/18Cq9marptM-Rbym9l7RvtQ **这个是新的文档：**https://www.lanzous.com/i7ewj1i **上面如果失效：**https://blog.csdn.net/techgroup/article/details/100053477 一、安装EXSI参考：https://blog.csdn.net/weixin_42758707/article/details/100525596 需要注意的地方：不需要DHCP服务器，路由器分配IP就行，ip最好设置为固定IP，可以开启ssh 填写密钥的地方： 开启ssh后可以使用ssh登陆 二、创建虚拟机根vmware一样，要先上传镜像再创建，可以创建Linux，MacOS，windows 也可以从ovf导入 三、其他功能 支持虚拟机资源监控，克隆虚拟机，建立快照，导出为模版等功能 支持用VMware连ESXI平台(CTRL+L),连接之后可以创建或删除虚拟机，还可以对虚拟机开关机 四、VMware vSphere Client6.0（看样子官方不再长期支持了） https://yq.aliyun.com/articles/636965 https://wsgzao.github.io/post/vmware-vsphere-client/ 五、解决ssh无法密码登陆的问题(提示密钥登陆) CTRL+ALT+F1进入命令行，修改/etc/ssh/sshd_config 重启services.sh 六、安装vcenter 安装到windows server2016中，应该还有其他办法 **安装文档：**https://www.lanzous.com/i7eh24j 安装很简单，整个安装过程比较慢，可能要半个小时甚至更长 牛逼，8G，不搞了 换了个电脑，继续实验 七、vcenter管理ESXI vcenter地址：vcenter.jd.com(172.18.3.252) exsi1地址：172.18.3.151 exsi2地址：172.18.3.255 步骤：先创建数据中心，然后数据中心中添加主机（exsi节点） 管理参考：https://www.cnblogs.com/djlsunshine/p/11372482.html 新建数据中心： 添加主机（添加exsi节点） 设置是否启用锁定模式，如果启用了锁定模式，管理员就不能够使用vSphere客户端直接登录到ESXI主机，只能通过vCenter Server对主机进行管理。在这里不启用锁定模式 **激活参考：**https://www.lanzous.com/i7eikla 激活码复制粘贴全部导入了。一个机器一个激活码：https://blog.csdn.net/lizhiyuan_eagle/article/details/79989216 然后就可以看到exsi中的虚拟机： 遇到的小问题，我克隆的第一个exsi变成第二个exsi，被识别数来了，只能再装一台： vcenter同样支持管理虚拟机，连接虚拟机 八、迁移exsi1的虚拟机到exsi2 冷迁移，直接迁 取消挂载cdrom再迁移 热迁移，要添加虚拟交换机在每个exsi网络上 主机—配置—虚拟交换机—添加网络： exsi2一样，添加个虚拟交换机，ip不能一样 然后就可以迁移了 整个迁移过程网络没有丢包，ssh也没有中断 九、vcenter正确激活姿势 激活码：HY6X2-8ZK8M-M8EU9-X31NK-3ARL6 先添加新的许可证 然后资产中分配许可证 ","link":"http://quansen88.cn/KM2XU8UXT/"},{"title":" windows server2016  kms激活","content":"windows server2016 kms激活 就这几条命令 分割线，下面的不用看 ","link":"http://quansen88.cn/4UbjY6War/"},{"title":" keepalived(一)知识点","content":"keepalived(一)知识点 keepalived配置中文注释（CTRL+F搜索）：https://blog.51cto.com/koala003/1876584 1、keepalived的配置段分为三大部分 全局配置；vrrp实例配置；lvs配置 2、默认配置文件组成 3、另一个服务器的配置 4、默认keepalived为抢占模式 如果不写，就是抢占模式，node1恢复后，因为优先级高，会抢回VIP 官方文档原话：VRRP will normally preempt a lower priority 如果想让优先级低的小弟拿到VIP后一直使用，就需要加上 nopreempt选项 5、抓包可以看到通告的内容 6、keepalived主主模式 即node1和node2都配置两个vrrp实例，每个vrrp实例一个vip；node1和node2一人一个vip 域名要添加两个A记录，分别指向这两个VIP node1的配置文件 node2配置 7、notify脚本 例如：VIP转移时，发送邮件到我的邮箱 邮箱配置 测试一下可以用 keepalived配置(要加引号，注意) 8、keepalived的vrrp_script keepalived调用外部的辅助脚本进行资源监控,要配合track_script一起用 （1）先定义脚本 (2)再调用脚本** ","link":"http://quansen88.cn/keepalivedyi-zhi-shi-dian/"},{"title":"小的网站结构【haproxy nginx】","content":"小的网站结构 说明：如果部署在云上，比如阿里云上，不需要自己部署keepalived，直接买阿里云的slb即可，slb然后分发流量到两台haproxy机器 一、先部署两个web服务器 编译安装nginx（脚本很粗糙） 编译php脚本 nginx配置wordpress 测试当前服务器是否正常 同步代码到web2 二、部署数据库主从 二进制安装脚本 数据库密码 主数据库配置： 从数据库配置 三、mysql服务器充当NFS服务器 配置主NFS 007-web1挂载测试 测试没问题同步到web2 配置自动同步 四、配置haproxy 编译安装haproxy（粗糙的脚本） 配置文件的书写（不写stat就完全一样） 五、配置keepalived VIP用192.168.38.188 邮件配置 编译安装keepalived 发邮件脚本 nginx检查脚本 lb1的keepalived.conf lb2的keepalived.conf 测试VIP转移 六、域名解析后就可以了，解析到vip 安装wordpress即可 七、将haproxy+keepalived换成keepalived+LVS lvs1:192.168.38.134 lvs2:192.168.38.135 VIP:192.168.38.189 说明：如果部署在云上，比如阿里云上，不需要自己部署lvs，直接买阿里云的slb即可，slb然后分发流量到两台web机器，不过这种不推荐，推荐slb走自己的haproxy，进行7层反代 编译安装keepalived同上 邮件服务配置同上 notify脚本同上 check脚本 lvs1的keepalived.conf lvs2的keepalivbed.conf 测试VIP转移 web1和web2绑定VIP 八、排查、lvs不显示后端服务器 手动curl发现返回302 解决：web服务器创建test.html测试页面做健康检查 两个lvs修改健康检查 随后停止并启动keepalived,就好了 另外wordpress的图片目录为uploads不是upload 九、优化 NFS权限限制 权限改成755还是成功了 问什么呢？为啥能上传成功，且用户为mysql 原因：web客户端的nginx用户ID为995 NFS这边mysql用户的id也是995 /data/wordpress/2019是已经生成的，属主为mysql（id995） 但是wordpress无法在/data/wordpress目录下生成新目录，可以设置acl权限给id为995用户(最好手动创建一个id为995的用户) 或者NFS设置权限,类似于下面这样： web1和web2的网站数据同步是比较困难的，wordpress变化的数据比较多，主题，图片等等，不只是uploads目录，最好都放NFS吧 ","link":"http://quansen88.cn/xiao-de-wang-zhan-jie-gou-haproxy-nginx/"},{"title":"lnmp+analyzer","content":" 此时还不能访问： 访问不了，老师说是这个项目的问题，wordpress都是好的 不纠结了； ","link":"http://quansen88.cn/lnmpanalyzer/"},{"title":"haproxy","content":"acl： The use of Access Control Lists (ACL) provides a flexible solution to perform content switching and generally to take decisions based on content extracted from the request, the response or any environmental status. acl [flags] [operator] [] ... ：ACL names must be formed from upper and lower case letters, digits, '-' (dash), '_' (underscore) , '.' (dot) and ':' (colon). 的类型： - boolean - integer or integer range - IP address / network - string (exact, substring, suffix, prefix, subdir, domain) - regular expression - hex block -i : ignore case during matching of all subsequent patterns. -m : use a specific pattern matching method -n : forbid the DNS resolutions -u : force the unique id of the ACL -- : force end of flags. Useful when a string looks like one of the flags. [operator] 匹配整数值：eq、ge、gt、le、lt ： dst : ip dst_port : integer src : ip src_port : integer Pre-defined ACLs ACL name Equivalent to Usage FALSE always_false never match HTTP req_proto_http match if protocol is valid HTTP HTTP_1.0 req_ver 1.0 match HTTP version 1.0 HTTP_1.1 req_ver 1.1 match HTTP version 1.1 HTTP_CONTENT hdr_val(content-length) gt 0 match an existing content-length HTTP_URL_ABS url_reg [/:]😕/ match absolute URL with scheme HTTP_URL_SLASH url_beg / match URL beginning with &quot;/&quot; HTTP_URL_STAR url * match URL equal to &quot;&quot; LOCALHOST src 127.0.0.1/8 match connection from local host METH_CONNECT method CONNECT match HTTP CONNECT method METH_GET method GET HEAD match HTTP GET or HEAD method METH_HEAD method HEAD match HTTP HEAD method METH_OPTIONS method OPTIONS match HTTP OPTIONS method METH_POST method POST match HTTP POST method METH_TRACE method TRACE match HTTP TRACE method RDP_COOKIE req_rdp_cookie_cnt gt 0 match presence of an RDP cookie REQ_CONTENT req_len gt 0 match data in the request buffer TRUE always_true always match WAIT_END wait_end wait for end of content analysis ","link":"http://quansen88.cn/20191104haproxy/"},{"title":" zabbix监控php","content":"zabbix监控php 可以参考：https://blog.csdn.net/qq_33317586/article/details/83622754 配置www.conf 要确保： 1、php启动用户和nginx进程用户一样 2、sock文件可以被nginx读 3、pm.status要和nginx中配置一样 配置nginx 访问测试 还支持json，html,支持full php-fpm status详解 full讲解 监控： 公司zabbix监控都用xml格式或者默认格式，web监控用html ","link":"http://quansen88.cn/zabbix-jian-kong-php/"},{"title":"temp文档DOS简单攻击防御脚本1","content":"DOS简单攻击防御脚本1 解决DOS攻击⽣产案例：根据web⽇志或⽹络连接数，监控当某个ip并发连接 数或者短时间内pv达到100，即调⽤防⽕墙命令封掉对应的ip，监控频率每隔5分 钟；防⽕墙命令为iptables -A INPUT -s IP -j REJECT？ CentOS7 pki目录一键生成证书 博主，求分享博客主题😢😋 练习： 前提：授权tom@172.16.%.%对hidb数据库上students表有所有访问权限；而后通过tom用户完成以下操作； 1、将birthdate字段改为age； 2、向students中插入100行数据； 用户名为stu1-stu100；性别随机为M或F；年龄为18-100之间的随机数； 3、以性别为分组，显示每组的平均年龄； 4、显示年龄大于40的用户 练习： 1、创建数据库hidb，默认字符集为'utf8'； 2、创建表students，拥有以下字段： stuid，整数，自动增长； name gender birthdate class 3、将students的class字段修改为classid； 4、为name字段添加索引； mysql面试题：https://www.cnblogs.com/aishangJava/p/11306919.html s 模块通过yum安装的：yum install nginx-module-geoip；数据库文件：https://www.lanzous.com/i71mekj 密码:i2ik，放在/etc/nginx目录下面 子配置： dsa ","link":"http://quansen88.cn/20191103temp-wen-dang-dos-jian-dan-gong-ji-fang-yu-jiao-ben-1/"},{"title":"rewrite","content":"rewrite 全站https的rewrite 网站就一个首页，不管访问什么都跳到首页 cat www.uscwifi.cn.conf 对用户的浏览器进行匹配 IE浏览器匹配 判断文件是否存在，不存在则跳转至首页 ","link":"http://quansen88.cn/20191101rewrite/"},{"title":"nginx神奇的斜线","content":"nginx神奇的斜线 来自：https://blog.csdn.net/scdxmoe/article/details/52512143 来自：https://www.cnblogs.com/007sx/p/7151720.html 同样的坑：http://ju.outofmemory.cn/entry/374096 访问的URL：http://192.168.1.4/proxy/test.html 第一种： 被代理到：http://127.0.0.1:81/test.html 第二种（相对于第一种，后面少了一个/） 会被代理到http://127.0.0.1:81/proxy/test.html 这个url 第三种 会被代理到http://127.0.0.1:81/ftlynx/test.html 这个url。 第四种（(相对于第三种，最后少一个 / )） 会被代理到http://127.0.0.1:81/ftlynxtest.html 这个url ","link":"http://quansen88.cn/20191101nginx-shen-qi-de-xie-xian/"},{"title":"nginx高级","content":"nginx . 匹配除换行符以外的任意字符0 ？ 重复0次或1次 + 重复1次或更多次 * 最少链接数，哪个机器连接数少就分发 \\d 匹配数字 ^ 匹配字符串的开始 $ 匹配字符串的结尾 {n} 重复n次 {n,} 重复n次或更多次 [c] 匹配单个字符c [a-z] 匹配任意一个小写字母 \\ 转义字符 ( ) 用于匹配括号之间的内容，通过$1、$2调用 rewrite index\\.php$ /pages/maintain.html break; last 停止rewrite检测 break 停止rewrite检测（与last有很大区别） redirect 返回302临时重定向，地址栏显示跳转后的地址 permanent 返回301永久重定向，地址栏显示跳转后的地址 编译安装nginx nginx配置选项 nginx进程 CPU亲和性 错误日志： nginx实现访问控制 nginx 中配置用户名密码验证访问控制 配置错误页面 try_files:当匹配 location 后尝试安装指定的查询文件顺序去指定路径下查找响应文件 配置 nginx 为文件下载服务器 nginx上传文件 nginx 打开文件缓存功能 隐藏 nginx 服务器版本信息 限制客户端请求方法 开启 nginx 的状态显示功能 nginx 使用第三方模块echo nginx内置变量和自定义变量 自定义nginx访问日志格式 自定义日志格式为json格式，方便日后elk处理 python脚本处理日志 nginx 开启传输文件压缩功能 开启 https 功能 配置 nginx 服务器 favicon.ico 小图标 nginx状态监控 ","link":"http://quansen88.cn/20191101nginx-gao-ji/"},{"title":"nginx防盗链","content":"nginx防盗链 本篇文章可以参考：https://segmentfault.com/a/1190000018001501 一般都是根据请求报文的referer来做防盗链的 比如51cto文章中的图片，经常看到网上很多人转载51cto的文章，但图片都不能访问，单独拿出图片链接到浏览器打开就可以访问， 用curl来模拟访问,不加referer可以正常访问： 加了别的referer就是403 加了含有blog.51cto.com的refert就是正常 正常的referer信息，可以通过不同的访问方式查看日志看到 referer可以伪造，比如curl -e就可以伪造 在图片的location里加个判断，不是本域名就拒绝 之前公司网站的nginx这么配置 这是一个nginx模版，需要的时候可以在里面加referer判断，不写的话就没用 referer的伪造 curl -e只能终端访问伪造，网站怎么办？ 可以百度新浪图床 403，新浪图床打不开，会有很多惊喜，网友给的临时解决办法： 办法一： 办法二： 办法三： 测试方法三： nginx正常配置： 测试页面 访问失败：403 修改nginx配置:51cto的图片空referer是可以访问的 add_header参考：http://nginx.org/en/docs/http/ngx_http_headers_module.html#add_header Referrer Policy可以参考：https://www.cnblogs.com/caixw/p/referrer-policy.html cat /etc/nginx/conf.d/www.uscwifi.cn.conf 然后就可以访问了。不过这样肯定会影响baidu的收录 ","link":"http://quansen88.cn/20191101nginx-fang-dao-lian/"},{"title":"auth_basic_module","content":"auth_basic_module 参考：http://nginx.org/en/docs/http/ngx_http_auth_basic_module.html 密码文件格式,密码支持明文和密文，密文使用openssl passwd或htpasswd生成 案例一： **[root@imooc-nginx ~]# cat /etc/nginx/conf.d/www.uscwifi.cn.conf ** 案例二： 我发现当http段和server段中都加auth_basic认证时，只有server生效 **[root@imooc-nginx ~]# cat /etc/nginx/nginx.conf ** **案例三：还可以写在location内 ","link":"http://quansen88.cn/auth_basic_module/"},{"title":"nginx全站https","content":"全站https 方法一： 方法二：rerurn 301 方法三：if判断 方法四：这个不推荐写一块，但是还是要知道 $scheme是nginx内置的变量 表示请求的协议，如ftp；https，http ","link":"http://quansen88.cn/20191030nginx-quan-zhan-https/"},{"title":"dockerfile中基本镜像apline添加glibc","content":"dockerfile中基本镜像apline添加glibc 参考：http://imoocc.com/jeson/2018/08/16/dockerfileaplineglibc/ 方法一：使用官方的镜像： 方法二：使用dockerfile来 国内服务器这么慢怎么办，没事国外服务器就块了 ","link":"http://quansen88.cn/20191030dockerfile-zhong-ji-ben-jing-xiang-apline-tian-jia-glibc/"},{"title":"alpine镜像支持中文字符","content":"alpine镜像支持中文字符 参考：https://www.clxz.top/2019/05/09/160241/ 本实验未经过生产环境测试 方法一：他构建好的镜像 方法二：使用他的dcokerfile构建 $ cat locale.md 在dockerfile中修改语言环境 小结： 删了一些东西，重新构建 Dockerfile locale.md ","link":"http://quansen88.cn/20191030alpine-jing-xiang-zhi-chi-zhong-wen-zi-fu/"},{"title":"nginx配置TLS1.3","content":"nginx配置TLS1.3 重新编译nginx结合最新的openssl [root@node1 conf.d]# cat /apps/nginx/conf.d/ssl.conf 访问效果： ","link":"http://quansen88.cn/20191029nginx-pei-zhi-tls13/"},{"title":"ngx_http_fastcgi_module 的那些事","content":"ngx_http_fastcgi_module 的那些事 问题来自于：https://segmentfault.com/q/1010000010786459 解决参考：https://segmentfault.com/a/1190000002667095 是什么？ 顾名思义，是Nginx用来处理FastCGI的模块。FastCGI是什么？这个以后再讲，可以说的是现在LNMP架构里面，PHP一般是以PHP-CGI的形式在运行，它就是一种FastCGI，我们在进程中看到的PHP-FPM是PHP-CGI的管理调度器。 为什么要详解一下？ 因为LNMP不像LAMP，且早期Nginx不支持path_info，导致网上有大量旧版本的Nginx教程干扰视线。 为了更加清晰准确使用LNMP，估需要深入了解一下整个ngx_http_fastcgi_module。 四个常见、重要的配置项 fastcgi_pass 作用域：location, if in location 设置FastCGI服务，其值可以是一个域名、IP地址:端口、或者是一个Unix的Socket文件。 同时，它也只支持一个FastCGI服务集群。 upstream集群定义不在本次讨论范围，更多玩法请参考官方文档。 fastcgi_param 作用域：http, server, location 设置一个传递给FastCGI服务的参数，可以是文本或者是变量。 可传递的参数，遵循CGI/1.1规范定义。 可以从Github上面看到Nginx在3年前实现FastCGI的参数传递后，基本就没变过了。 fastcgi_index 作用域：http, server, location 当请求以/结尾的时候，会将请求传递给所设置的index.php文件处理。 fastcgi_split_path_info 作用域：location Nginx默认获取不到PATH_INFO的值，得通过fastcgi_split_path_info指定定义的正则表达式来给$fastcgi_path_info赋值。 其正则表达式必须要有两个捕获。 第一个捕获的值会重新赋值给$fastcgi_script_name变量。 第二个捕获到的值会重新赋值给$fastcgi_path_info变量。 例子： 原始请求是 /show.php/article/0001。 通过分割，FastCGI得到的结果是： SCRIPT_FILENAME: /path/to/php/show.php PATH_INFO: /article/0001 Nginx在0.7.31以前是没有fastcgi_split_path_info这个指令的，而0.7.x这个版本一直存活了好多年，后面才高歌猛进，导致网上存在大量旧版本通过正则自己设置PATH_INFO的方法。 踩了好多次依旧不记得怎么设置的ThinkPHP 为什么总是踩坑？因为我们都会通过重写来隐藏index.php文件，而ThinkPHP的教程，默认教的是旧版Nginx写法，且URL_MODE必须设置为3也说得很隐晦（URL_MODE默认为0）。 例如ThinkPHP的说明有一段旧版的Nginx设置指引。 该规则是通过将请求rewrite给/index.php?s=来实现的，其ThinkPHP的URL_MODE配置必须为3，也就是兼容模式。 如果使用本文中的传递PATH_INFO方式，且隐藏index.php，则ThinkPHP的URL_MODE需要改为2。 如果使用本文中的传递PATH_INFO方式，但不隐藏index.php，则ThinkPHP的URL_MODE改为1。 还有个一个叫 cgi.fix_pathinfo cgi.fix_pathinfo参数，藏在PHP-FPM的php.ini配置里面，其默认值为1。 这里存在一个安全风险，我也不通，详情不表，看鸟哥的文章：http://www.laruence.com/2010/05/20/1495.html 习惯性将其设置为0即可。 参考 http://nginx.org/en/docs/http/ngx_http_fastcgi_module.html http://wiki.nginx.org/PHPFcgiExample 同步发表于我的博客 ","link":"http://quansen88.cn/20191028ngx_http_fastcgi_module-de-na-xie-shi/"},{"title":"nginx配置location总结及rewrite规则写法","content":"nginx配置location总结及rewrite规则写法 参考：http://seanlook.com/2015/05/17/nginx-location-rewrite/ 1. location正则写法 一个示例： 已=开头表示精确匹配 如 A 中只匹配根目录结尾的请求，后面不能带任何字符串。 ^~ 开头表示uri以某个常规字符串开头，不是正则匹配 ~ 开头表示区分大小写的正则匹配; ~* 开头表示不区分大小写的正则匹配 / 通用匹配, 如果没有其它匹配,任何请求都会匹配到 顺序 （不是优先级）： (location =) &gt; (location 完整路径) &gt; (location ^~ 路径) &gt; (location ,* 正则顺序) &gt; (location 部分起始路径) &gt; (/) 优先级：=, ^~, ～/～\\*，不带符号； 上面的匹配结果 按照上面的location写法，以下的匹配示例成立： / -&gt; config A 精确完全匹配，即使/index.html也匹配不了 /downloads/download.html -&gt; config B 匹配B以后，往下没有任何匹配，采用B /images/1.gif -&gt; configuration D 匹配到F，往下匹配到D，停止往下 /images/abc/def -&gt; config D 最长匹配到G，往下匹配D，停止往下 你可以看到 任何以/images/开头的都会匹配到D并停止，FG写在这里是没有任何意义的，H是永远轮不到的，这里只是为了说明匹配顺序 /documents/document.html -&gt; config C 匹配到C，往下没有任何匹配，采用C /documents/1.jpg -&gt; configuration E 匹配到C，往下正则匹配到E /documents/Abc.jpg -&gt; config CC 最长匹配到C，往下正则顺序匹配到CC，不会往下到E 实际使用建议 http://tengine.taobao.org/book/chapter_02.html http://nginx.org/en/docs/http/ngx_http_rewrite_module.html 2. Rewrite规则 rewrite功能就是，使用nginx提供的全局变量或自己设置的变量，结合正则表达式和标志位实现url重写以及重定向。rewrite只能放在server{},location{},if{}中，并且只能对域名后边的除去传递的参数外的字符串起作用，例如 http://seanlook.com/a/we/index.php?id=1&amp;u=str 只对/a/we/index.php重写。语法rewrite regex replacement [flag]; 如果相对域名或参数字符串起作用，可以使用全局变量匹配，也可以使用proxy_pass反向代理。 表明看rewrite和location功能有点像，都能实现跳转，主要区别在于rewrite是在同一域名内更改获取资源的路径，而location是对一类路径做控制访问或反向代理，可以proxy_pass到其他机器。很多情况下rewrite也会写在location里，它们的执行顺序是： 执行server块的rewrite指令 执行location匹配 执行选定的location中的rewrite指令 如果其中某步URI被重写，则重新循环执行1-3，直到找到真实存在的文件；循环超过10次，则返回500 Internal Server Error错误。 2.1 flag标志位 last : 相当于Apache的[L]标记，表示完成rewrite break : 停止执行当前虚拟主机的后续rewrite指令集 redirect : 返回302临时重定向，地址栏会显示跳转后的地址 permanent : 返回301永久重定向，地址栏会显示跳转后的地址 因为301和302不能简单的只返回状态码，还必须有重定向的URL，这就是return指令无法返回301,302的原因了。这里 last 和 break 区别有点难以理解： last一般写在server和if中，而break一般使用在location中 last不终止重写后的url匹配，即新的url会再从server走一遍匹配流程，而break终止重写后的匹配 break和last都能阻止继续执行后面的rewrite指令 2.2 if指令与全局变量 if判断指令 语法为if(condition){...}，对给定的条件condition进行判断。如果为真，大括号内的rewrite指令将被执行，if条件(conditon)可以是如下任何内容： 当表达式只是一个变量时，如果值为空或任何以0开头的字符串都会当做false 直接比较变量和内容时，使用=或!= ~正则表达式匹配，~*不区分大小写的匹配，!~区分大小写的不匹配 -f和!-f用来判断是否存在文件 -d和!-d用来判断是否存在目录 -e和!-e用来判断是否存在文件或目录 -x和!-x用来判断文件是否可执行 例如： 全局变量 下面是可以用作if判断的全局变量 $args ： #这个变量等于请求行中的参数，同$query_string $content_length ： 请求头中的Content-length字段。 $content_type ： 请求头中的Content-Type字段。 $document_root ： 当前请求在root指令中指定的值。 $host ： 请求主机头字段，否则为服务器名称。 $http_user_agent ： 客户端agent信息 $http_cookie ： 客户端cookie信息 $limit_rate ： 这个变量可以限制连接速率。 $request_method ： 客户端请求的动作，通常为GET或POST。 $remote_addr ： 客户端的IP地址。 $remote_port ： 客户端的端口。 $remote_user ： 已经经过Auth Basic Module验证的用户名。 $request_filename ： 当前请求的文件路径，由root或alias指令与URI请求生成。 $scheme ： HTTP方法（如http，https）。 $server_protocol ： 请求使用的协议，通常是HTTP/1.0或HTTP/1.1。 $server_addr ： 服务器地址，在完成一次系统调用后可以确定这个值。 $server_name ： 服务器名称。 $server_port ： 请求到达服务器的端口号。 $request_uri ： 包含请求参数的原始URI，不包含主机名，如：”/foo/bar.php?arg=baz”。 $uri ： 不带请求参数的当前URI，$uri不包含主机名，如”/foo/bar.html”。 $document_uri ： 与$uri相同。 例：http://localhost:88/test1/test2/test.php host：localhosthost：localhost host：localhostserver_port：88 requesturi：http://localhost:88/test1/test2/test.phprequest_uri：http://localhost:88/test1/test2/test.php requestu​ri：http://localhost:88/test1/test2/test.phpdocument_uri：/test1/test2/test.php documentroot：/var/www/htmldocument_root：/var/www/html documentr​oot：/var/www/htmlrequest_filename：/var/www/html/test1/test2/test.php 2.3 常用正则 . ： 匹配除换行符以外的任意字符 ? ： 重复0次或1次 + ： 重复1次或更多次 * ： 重复0次或更多次 \\d ：匹配数字 ^ ： 匹配字符串的开始 $ ： 匹配字符串的介绍 {n} ： 重复n次 {n,} ： 重复n次或更多次 [c] ： 匹配单个字符c [a-z] ： 匹配a-z小写字母的任意一个 小括号()之间匹配的内容，可以在后面通过$1来引用，$2表示的是前面第二个()里的内容。正则里面容易让人困惑的是\\转义特殊字符。 2.4 rewrite实例 例1： 对形如/images/ef/uh7b3/test.png的请求，重写到/data?file=test.png，于是匹配到location /data，先看/data/images/test.png文件存不存在，如果存在则正常响应，如果不存在则重写tryfiles到新的image404 location，直接返回404状态码。 例2： 对形如/images/bla_500x400.jpg的文件请求，重写到/resizer/bla.jpg?width=500&amp;height=400地址，并会继续尝试匹配location。 例3： 见 ssl部分页面加密 。 参考 http://www.nginx.cn/216.html http://www.ttlsa.com/nginx/nginx-rewriting-rules-guide/ 老僧系列nginx之rewrite规则快速上手 http://fantefei.blog.51cto.com/2229719/919431 ","link":"http://quansen88.cn/20191028nginx-pei-zhi-location-zong-jie-ji-rewrite-gui-ze-xie-fa/"},{"title":"nginx的try_files","content":"nginx的try_files http://nginx.org/en/docs/http/ngx_http_core_module.html#try_files try_files - 说明 语法 try_files file ... uri; try_files file ... =code; 默认 —— 上下文 server、location 以指定顺序检查文件是否存在，并使用第一个找到的文件进行请求处理。处理将在当前上下文中执行。指向文件的路径根据 root 和 alias 指令从 file 参数构造。可以通过在名称末尾指定斜线来检查目录是否存在，例如，$URI/。如果找不到任何文件，则内部重定向将指向最后一个参数中指定的 uri。例如： 最后一个参数也可以指向一个命名的 location ，如以下示例。从 0.7.51 版本开始，最后一个参数也可以是一个 code： 代理 Mongrel 示例： Drupal/FastCGI 示例： 在以下示例中 try_files 指令相当于 还有一个示例 在将请求传递给 FastCGI 服务器之前，try_files 将检查 PHP 文件是否存在。 Wordpress 与 Joomla 示例： ","link":"http://quansen88.cn/20191028nginx-de-try_files/"},{"title":"制作离线docker安装源","content":"制作离线docker安装源 测试没有问题： ","link":"http://quansen88.cn/20191027-zhi-zuo-chi-xian-docker-an-zhuang-yuan/"},{"title":"dockerfile多阶段构建制作离线yum源","content":"dockerfile多阶段构建制作离线yum源 参考：https://blog.csdn.net/networken/article/details/89712130 目录结构： Dockerfile pkg.list nginx.conf index.html ","link":"http://quansen88.cn/20191027dockerfile-duo-jie-duan-gou-jian-zhi-zuo-chi-xian-yum-yuan/"},{"title":"bash特性：cat的重定向问题","content":"bash特性：cat的重定向问题 参考：https://blog.csdn.net/networken/article/details/80564824 参考：https://blog.csdn.net/networken/article/details/80564824 一、cat &gt; ./test.sh &lt;&lt;EOF 这种写法是常用的写法 二、cat &gt; ./test.sh &lt;&lt;'EOF'或者cat &gt; ./test.sh &lt;&lt;&quot;EOF&quot; 当重定向的内容中有符号时，要把符号时，要把符号时，要把符号重定向到文件中，就要对EOF加引号，或者使用反斜杠（\\）转义，但反斜杠不美观 三、&lt;&lt;-EOF 官方文档的说明可能比较模糊，但是你一定在某些脚本中看过这样的写法： &lt;&lt;-EOF可以让重定向的内容加上缩进让脚本更美观，并且tab缩进不写入文件 看起来美观，其实还是挺累的... 四、cat &lt;&lt;EOF | bash直接将EOF输出传递给命令 其他的一些bash特性 一、nginx -V |&amp; grep echo nginx -V的输出不是标准输出，所以nginx -V | grep echo无效，使用|&amp;可以对标准错误标准输出一起操作 二、管道的返回值是最后一个命令的退出状态，除非启用了pipefail ","link":"http://quansen88.cn/20191027bash-te-xing-cat-de-chong-ding-xiang-wen-ti/"},{"title":"同步与异步，阻塞与非阻塞的区别","content":"同步与异步，阻塞与非阻塞的区别 转载：https://www.cnblogs.com/chaser24/p/6112071.html 1、概念剖析 相信很多从事linux后台开发工作的都接触过同步&amp;异步、阻塞&amp;非阻塞这样的概念，也相信都曾经产生过误解，比如认为同步就是阻塞、异步就是非阻塞，下面我们先剖析下这几个概念分别是什么含义。 同步： 所谓同步，就是在发出一个功能调用时，在没有得到结果之前，该调用就不返回。也就是必须一件一件事做,等前一件做完了才能做下一件事。 例如普通B/S模式（同步）：提交请求-&gt;等待服务器处理-&gt;处理完毕返回 这个期间客户端浏览器不能干任何事 异步： 异步的概念和同步相对。当一个异步过程调用发出后，调用者不能立刻得到结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者。 例如 ajax请求（异步）: 请求通过事件触发-&gt;服务器处理（这是浏览器仍然可以作其他事情）-&gt;处理完毕 阻塞： 阻塞调用是指调用结果返回之前，当前线程会被挂起（线程进入非可执行状态，在这个状态下，cpu不会给线程分配时间片，即线程暂停运行）。函数只有在得到结果之后才会返回。 有人也许会把阻塞调用和同步调用等同起来，实际上他是不同的。对于同步调用来说，很多时候当前线程还是激活的，只是从逻辑上当前函数没有返回,它还会抢占cpu去执行其他逻辑，也会主动检测io是否准备好。 非阻塞 非阻塞和阻塞的概念相对应，指在不能立刻得到结果之前，该函数不会阻塞当前线程，而会立刻返回。 再简单点理解就是： \\1. 同步，就是我调用一个功能，该功能没有结束前，我死等结果。 \\2. 异步，就是我调用一个功能，不需要知道该功能结果，该功能有结果后通知我（回调通知） \\3. 阻塞，就是调用我（函数），我（函数）没有接收完数据或者没有得到结果之前，我不会返回。 \\4. 非阻塞，就是调用我（函数），我（函数）立即返回，通过select通知调用者 同步IO和异步IO的区别就在于：数据拷贝的时候进程是否阻塞 阻塞IO和非阻塞IO的区别就在于：应用程序的调用是否立即返回 综上可知，同步和异步,阻塞和非阻塞,有些混用,其实它们完全不是一回事,而且它们修饰的对象也不相同。 2、五种IO模型 在了解了同步与异步、阻塞与非阻塞概念后，我们来讲讲linux的五种IO模型： 1)阻塞I/O（blocking I/O） 2)非阻塞I/O （nonblocking I/O） 3) I/O复用(select 和poll) （I/O multiplexing） 4)信号驱动I/O （signal driven I/O (SIGIO)） 5)异步I/O （asynchronous I/O (the POSIX aio_functions)） 其中前4种都是同步，最后一种才是异步。 2.1、阻塞I/O 应用程序调用一个IO函数，导致应用程序阻塞，等待数据准备好。 如果数据没有准备好，一直等待….数据准备好了，从内核拷贝到用户空间,IO函数返回成功指示。 **阻塞I/O模型图：**在调用recv()/recvfrom（）函数时，发生在内核中等待数据和复制数据的过程。 当调用recv()函数时，系统首先查是否有准备好的数据。如果数据没有准备好，那么系统就处于等待状态。当数据准备好后，将数据从系统缓冲区复制到用户空间，然后该函数返回。在套接应用程序中，当调用recv()函数时，未必用户空间就已经存在数据，那么此时recv()函数就会处于等待状态。 2.2、非阻塞I/O 非阻塞IO通过进程反复调用IO函数（多次系统调用，并马上返回）；在数据拷贝的过程中，进程是阻塞的 我们把一个SOCKET接口设置为非阻塞就是告诉内核，当所请求的I/O操作无法完成时，不要将进程睡眠，而是返回一个错误。这样我们的I/O操作函数将不断的测试数据是否已经准备好，如果没有准备好，继续测试，直到数据准备好为止。在这个不断测试的过程中，会大量的占用CPU的时间。 2.3、IO复用 主要是select和epoll；对一个IO端口，两次调用，两次返回，比阻塞IO并没有什么优越性；关键是能实现同时对多个IO端口进行监听； I/O复用模型会用到select、poll、epoll函数，这几个函数也会使进程阻塞，但是和阻塞I/O所不同的的，这两个函数可以同时阻塞多个I/O操作。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时，才真正调用I/O操作函数。 2.4、信号驱动IO 首先我们允许套接口进行信号驱动I/O,并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据。 2.4、异步IO 当一个异步过程调用发出后，调用者不能立刻得到结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者的输入输出操作 最后，总结比较下五种IO模型： ","link":"http://quansen88.cn/20191025-tong-bu-yu-yi-bu-zu-sai-yu-fei-zu-sai-de-qu-bie/"},{"title":"来自opendevops的系统调优脚本","content":"来自opendevops的系统调优脚本 来自：https://github.com/opendevops-cn/opendevops/blob/master/scripts/system_init_v1.sh ","link":"http://quansen88.cn/20191023-lai-zi-opendevops-de-xi-tong-diao-you-jiao-ben/"},{"title":"编译安装php+apache环境","content":"编译安装php+apache环境 注意事项： 脚本 编译安装httpd 测试 卸载 ","link":"http://quansen88.cn/20191017-bian-yi-an-zhuang-phpapache-huan-jing/"},{"title":"一键编译安装和卸载httpd-2.4.41","content":"一键编译安装和卸载httpd-2.4.41 需要注意的地方： **1、编译apr和apr-utils：**官方的INSTALL文档说的很详细了，下载对应的包解压到srclib目录即可，不要带版本号 **2、system脚本：**yum装一个httpd，考过来改改就行了 **3、启动用户问题：**源码安装的httpd配置文件用户是daemon，装完后要改下 脚本在CentOS7测试能用 看一下现有的模块： ","link":"http://quansen88.cn/20191016-yi-jian-bian-yi-an-zhuang-he-xie-zai-httpd-2441/"},{"title":"inotify+rsync备份NFS","content":"inotify+rsync备份NFS 本文应当参考：https://www.cnblogs.com/f-ck-need-u/p/7220193.html#auto_id_1 错误一：一直连不上，原因：客户端密码文件不用写用户 缺点： 一、inotify+rsync使用方式 二、查看服务器内核是否支持inotify 三、inotify内核参数 四、安装与文档 五、inotifywait 命令常见选项 六、inotify监控示例 七、实战 下面是拓扑图，对右下角那一块的NFS备份设置 服务器名字 服务器IP 服务器系统 NFS1 192.168.38.146 CentOS7（512MB） NFS-backup 192.168.38.149 CentOS7（512MB） 方案一：NFS-BACKUP服务器rsync以daemon方式运行，NFS1服务器实时检测本地是否有改动然后推送到NFS-BACKUP NFS-BACKUP相当于是服务端,安装相关软件，配置相关软件 NFS1相当于客户端，安装软件创建目录，并写脚本 测试没有问题： 方案二、使用ssh方式来传输文件，这样backup就不用启动rsyncd服务了， ","link":"http://quansen88.cn/20191016inotifyrsync-bei-fen-nfs/"},{"title":"Logrotate日志存储","content":"Logrotate日志存储 学习：https://www.cnblogs.com/kevingrace/p/6307298.html logrotate 程序是一个日志文件管理工具。用来把旧的日志文件删除，并创建新的日志文件，称为日志转储或滚动。可以根据日志文件的大小，也可以根据其天数来转储，这个过程一般通过 cron 程序来执行 配置文件是 /etc/logrotate.conf 相关参数： 1. cron，crontab以及anacron的关系 2、logrotate是被anacron调用周期执行的，可以看anacon的配置文件 anacron配置文件中会周期型的执行三组任务，分别是每天执行，每星期执行，每月执行； run-parts命令其实是一个shell脚本，使用该脚本时后面跟一个参数，参数为目录； run-parts脚本会扫描目录中的所有文件执行一遍； 例如run-parts /etc/cron.daily，简单认为是执行 /etc/cron.daily下面所有的脚本 logrotate脚本内容： logrotate命令通过配置文件 /etc/logrotate.conf执行相应任务， /etc/logrotate.conf中又会执行子配置 比如子配置文件nginx，这个是安装nginx时就自动生成的 用于执行一组任务 手动强制切割日志： ","link":"http://quansen88.cn/20191014logrotate-ri-zhi-cun-chu/"},{"title":"将ssh日志发送到日志服务器（同样适用于其他程序）","content":"将ssh日志发送到日志服务器（同样适用于其他程序） 之前也使用过rsyslog收集过路由器的日志，路由器支持syslog功能 CentOS8和CentOS7有点不一样， 服务器用途 IP 客户端（node1） 192.168.38.136 日志服务器（CentOS8） 192.168.38.142 服务端开启rsyslog收集日志功能（CentOS8） 客户端的ssh程序设置日志发送位置（CentOS7） tail -f测试日志的发送,客户端登陆成功或失败都会发送消息过来 ","link":"http://quansen88.cn/20191011-jiang-ssh-ri-zhi-fa-song-dao-ri-zhi-fu-wu-qi-tong-yang-gua-yong-yu-qi-ta-cheng-xu/"},{"title":"CentOS7 yum部署lamp环境（wordpress,discuz,powerdns）","content":"CentOS7 yum部署lamp环境（wordpress,discuz,powerdns） 注意事项： 1、服务器内核参数等调优：生产环境必须要做 **2、httpd工作模式：**可以选择event模型，CentOS7默认prefork模型，CentOS8默认event模型（修改方法：/etc/httpd/conf.modules.d/00-mpm.conf） **3、mysql的配置文件调优：**数据库保存位置，二进制日志，禁止DNS解析，buffer缓存，缓冲区大小，最大线程数，慢查询等等，必须要改。 **4、httpd和php结合的方式：**有模块和fastcgi两种，下面使用fascgi；apache换成nginx也一样，使用fastcgi **5、php调优：**使用socket文件而不是监听端口，php-fpm线程数（不要太大，根据需要改，可以设置为‘内存/50’），php错误日志，脚本运行的最长时间，脚本使用最大内存，上传文件最大值等等（一般修改www.conf） **6、虚拟主机设置https：**安装mod_ssl并修改对应子配置文件，httpd一个IP仅支持一个https，nginx可以支持多个 7、... 安装httpd 安装mysql并修改初始密码 安装php 下载wordpress 配置虚拟主机 创建wordpress数据库账户 修改wordpress配置文件 浏览器可以访问了，屏幕打印mysql密码： 配置phpmyadmin 配置discuz 部署phpwind 部署powerdns ","link":"http://quansen88.cn/20191011centos7-yum-bu-shu-lamp-huan-jing-wordpressdiscuzpowerdns/"},{"title":"ansible知识点","content":"ansible知识点 1、通过ansible all -msetup查看主机信息 facts组件是⽤来收集被管理节点信息的，使⽤setup模块可以获取这些信息。 使⽤f ilter可以筛选指定的facts信息。例如： facts收集的信息是json格式的，其内任⼀项都可以当作变量被直接引⽤(如在playbook、jinja2模板中)引⽤。见下⽂。 playbook写一个二进制安装mysql 一、先写成单个文件，单个文件刚开始容易理解 本次实验给web组安装mysql 除了这个文件，还有个目录，存放mysql二进制压缩包,my.cnf,service启动文件 二、拆分成多个文件 使用deploy.yml作为入口文件，mysql_hosts作为主机清单 执行结果： ","link":"http://quansen88.cn/20191009ansible-zhi-shi-dian/"},{"title":"httpd知识点","content":"httpd知识点 一、隐藏apache版本号 二、修改主站点主目录 3、TCP协议的特征 4、html语言格式 5、一次完整的http请求处理过程： 6、接收请求的模型： 7、web服务器的资源路径映射方式： 8、http请求处理中的连接模式： 9、httpd的特性： 10、httpd三种工作模型简单描述 11、httpd-2.4配置文件格式 12、修改监听的IP和PORT 13、持久连接（保持连接，长连接） 14、查看httpd程序的模块列表 15、MPM配置： 16、配置指定实现模块加载 17、main server 18、站点访问控制常见机制 19、&lt;Directory&gt;中“基于源地址”实现访问控制： 20、定义站点主页面： 21、定义路径别名 22、设定默认字符集 23、日志设定 24、基于用户的访问控制 25、虚拟主机 26、status页面 27、URL 28、报文语法格式： 29、method(方法)： 30、status(状态码)： 31、curl命令 32、指定以哪个用户的身份运行httpd服务进程 33、使用mod_deflate模块压缩页面优化传输速度 34、SSL会话的简化过程 35、配置httpd支持https： 36、httpd自带的工具程序 37、httpd的压力测试工具 38、安装配置httpd-2.4 39、练习题 40、WEB资源类型： 41、请求流程 42、PHP简介 43、PHP Zend Engine 44、PHP的Opcode 45、php的加速器 46、PHP源码目录结构 47、LAMP： 48、php配置文件 49、ini配置文件 50、开启httpd持久连接功能 51、httpd配置文件 ","link":"http://quansen88.cn/20191008httpd-zhi-shi-dian/"},{"title":"getopt：命令行选项、参数处理","content":"getopt：命令行选项、参数处理 参考：https://linuxeye.com/389.html 今天在之前的脚本中看到这么一段 大致可以可以看出来是用来解析命令行选项执行相应的功能的 一、简化脚本 二、执行脚本 三、冒号用于指定选项必须得有参数 四、参数内容放在OPTARG中 五、长选项用getopt，参考https://linuxeye.com/389.html ","link":"http://quansen88.cn/20191006getoptming-ling-xing-xuan-xiang-can-shu-chu-li/"},{"title":"mysql主从复制加密","content":"mysql主从复制加密 环境： master 192.168.38.139 slave 192.168.38.140 一、初始化环境 二、yum安装mysql5.7.27 三、生成ca证书，私钥公钥 方法一：使用mysql命令 方法二：openssl手动生成 四、配置文件修改 master节点 slave节点 五、配置主从 master节点 从节点 六、测试主从 ","link":"http://quansen88.cn/20190929mysql-zhu-cong-fu-zhi-jia-mi/"},{"title":"mysql5.7.27主从复制加密实验2","content":"mysql5.7.27主从复制加密实验2 参考：https://blog.csdn.net/weixin_39845407/article/details/81708230 参考：https://www.cnblogs.com/MYSQLZOUQI/p/7089135.html 参考：https://dev.mysql.com/doc/refman/5.7/en/encrypted-connections.html 从网上的教程来看： 1、mysql5.7.27 服务器端datadir只要有证书的话默认就会开启ssl，不需要my.cnf配置，只有证书不在datadir才需要自己手动配置my.cnf，配好后重启mysqld即可 2、从网上教程来看，mysql5.7.27客户端不需要再手动安装证书连接服务端，直接连就是ssl加密的 3、如果服务端开启了ssl加密，客户端不想使用ssl加密连接，只需要连接的时候指定ssl-mode为disable即可 可以参考：https://dev.mysql.com/doc/refman/5.7/en/encrypted-connections.html 实验环境： master 192.168.38.139 slave 192.168.38.140 一、快速安装MySQL5.7.27 二、生成ssl证书和密钥 MySQL 5.7及更高版本提供了一个名为mysql_ssl_rsa_setup的实用程序,我们使用root权限生成相关的请求文件和证书对，为了能让mysql有权限去使用，命令中应该使用选项和参数--uid=mysql来指定uid 三、在MySQL服务器端开启ssl连接 现在新版本的MySQL将在服务器启动时在MySQL数据目录中查找相应的证书文件。 因此，我们实际上不需要修改MySQL配置来启用SSL，重启即可。 连接MySql，MySQL客户端将自动尝试使用SSL进行连接： 检查SSL相关变量的值： 四、修改配置文件 master节点开启binlog即可,require_secure_transport是强制开启SSL slave节点，如果没特殊需求，配置server-id 五、配置主从 master slave 看官方文档，mysql5.7.27不再需要手动安装证书，那直接试试看 六、测试 导入了一些数据库文件，从抓包来看 都是TCP包，且内容乱七八糟 ","link":"http://quansen88.cn/20190929mysql5727-zhu-cong-fu-zhi-jia-mi-shi-yan-2/"},{"title":"快速yum安装mysql5.7","content":"快速yum安装mysql5.7 2019年10月10日测试，不可用，ustc源的rpm包缺失5.26和5.27，azure也去掉了mysql源，官网正常 ","link":"http://quansen88.cn/20190926-kuai-su-yum-an-zhuang-mysql57/"},{"title":"MySQL集群结构说明","content":"完全参考：https://www.cnblogs.com/f-ck-need-u/p/9278900.html 在以前，数据库的集群配置一直很难，难点在于MySQL主从结构的高可用和读写分离。万幸的是，Galera/GR的出现，让整个集群的配置都极大程度地简化了。 以下是一个简单的MySQL集群拓扑图： 1.MySQL中间件：对MySQL Server的读写操作进行路由(即读写分离)；分库分表(sharding) (1).MySQL Router：MySQL官方提供的轻量级MySQL代理(路由)，只提供读写分离功能，前身为SQL Proxy。 (2).ProxySQL：类似于MySQL Router，轻量级MySQL代理，提供读写分离功能，也支持一些sharding功能。有percona版和官方版两个版本。 (3).MaxScale：MariaDB的中间件，和MySQL Router、ProxySQL类似。 这三者类似，都是轻量级数据库中间件。 (4).Amoeba、Cobar、MyCAT：提供很多功能，最主要的功能包括读写分离、sharding。 这三者的渊源较深，都是开源的。Amoeba后继无人，于是Cobar出来，Cobar后继无人，加上2013年出现了一次较严重的问题，于是MyCAT站在Cobar的肩膀上出来了。 2.MySQL主从复制的高可用：至少要实现主从切换或故障时选举新master节点 (1).MMM：淘汰了，在一致性和高并发稳定性等方面有些问题。 (2).MHA：有些人还在用，但也有些问题，也是趋于淘汰的MySQL主从高可用方案。 (3).Galera：引领时代的主从复制高可用技术。 (4).MariaDB Galera Cluster：MariaDB对Galera的实现。 (5).PXC：Percona XtraDB Cluster，是Percona对Galera的自我实现，用的人很多。 (6).GR：Group Replication，MySQL官方提供的组复制技术(MySQL 5.7.17引入的技术)，基于Paxos算法。 MariaDB Galera Cluster、PXC、GR是类似的，都各有优点。但GR是革命性的，基于原生复制技术，据传很多方面都优于PXC。 MariaDB Galera Cluster、PXC、GR为了安全性和性能考虑，做出了很多强制性的限制。例如基于GTID复制、只能InnoDB表，每表都必须有主键等。要使用它们提供主从复制的高可用，必须要了解它们的各项限制。 ","link":"http://quansen88.cn/20190925mysql-ji-qun-jie-gou-shuo-ming/"},{"title":"MySQL的半同步复制","content":"MySQL的半同步复制 参考：https://www.cnblogs.com/kevingrace/p/10228694.html 参考：https://www.cnblogs.com/f-ck-need-u/p/9166452.html#%E5%8D%8A%E5%90%8C%E6%AD%A5%E5%A4%8D%E5%88%B6%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6 参考：https://blog.csdn.net/qq_18312025/article/details/78681844 MySQL主从复制包括异步模式、半同步模式、GTID模式以及多源复制模式，默认是异步模式 (如之前详细介绍的mysql主从复制)。所谓异步模式指的是MySQL 主服务器上I/O thread 线程将二进制日志写入binlog文件之后就返回客户端结果，不会考虑二进制日志是否完整传输到从服务器以及是否完整存放到从服务器上的relay日志中，这种模式一旦主服务(器)宕机，数据就可能会发生丢失。 异步模式是一种基于偏移量的主从复制，实现原理是: 主库开启binlog功能并授权从库连接主库，从库通过change master得到主库的相关同步信息然后连接主库进行验证，主库IO线程根据从库slave线程的请求，从master.info开始记录的位置点向下开始取信息，同时把取到的位置点和最新的位置与binlog信息一同发给从库IO线程,从库将相关的sql语句存放在relay-log里面，最终从库的sql线程将relay-log里的sql语句应用到从库上，至此整个同步过程完成，之后将是无限重复上述过程。 mysql主从复制的步骤: 1)在主库与从库都安装mysql数据库; 2) 在主库的my.cnf配置文件中配置server-id 和log-bin; 3) 在登陆主库后创建认证用户并做授权; 4) 在从库的my.cnf配置文件中配置server-id; 5) 登陆从库后，指定master并开启同步开关。 需要注意的是server-id主从库的配置是不一样的。 server-id存在作用: mysql同步的数据中是包含server-id的，而server-id用于标识该语句最初是从哪个server写入的。因此server-id一定要有的 **server-id不能相同的原因：**每一个同步中的slave在master上都对应一个master线程，该线程就是通过slave的server-id来标识的；每个slave在master端最多有一个master线程，如果两个slave的server-id 相同，则后一个连接成功时，slave主动连接master之后，如果slave上面执行了slave stop；则连接断开，但是master上对应的线程并没有退出；当slave start之后，master不能再创建一个线程而保留原来的线程，那样同步就可能有问题； 在mysql做主主同步时，多个主需要构成一个环状，但是同步的时候又要保证一条数据不会陷入死循环，这里就是靠server-id来实现的； 半同步说白了就是用户操作主服务；然后下面的从服务器都一个个到主服务器获取binlog，去执行；执行完后分别给主服务器打小报告：我执行完了；主服务器看到只要有一个从服务器执行完成，就给用户返回：好的，你的操作执行完了！ **** 一、快速搭建实验环境 用一个虚拟机来做实验，装3个数据库来模拟实验:下面是mysql5.7.27多实例部署脚本 如果脚本报错，执行下面命令重新执行： 二、安装并启用插件 三、搭建主从数据库 这个应该放前面的，前面忘了做了，放这就放这吧 四、停止从库13308，主库13306创建数据库仍能正常操作： 五、继续停止从库13307 六、半同步复制的状态信息 半同步需要一个semi的插件 ","link":"http://quansen88.cn/20190925mysql-de-ban-tong-bu-fu-zhi/"},{"title":"error 'Can't connect to local MySQL server through socket","content":"error: 'Can't connect to local MySQL server through socket 背景：我写了个脚本一键部署mysql多实例，最后使用mysqladmin改密码发生这个错误 百度无解： 最终加了个sleep 8(sleep 5也偶尔报错)，可以了，貌似是脚本执行的有点快，mysqladmin执行之前sock文件还没创建完 如果脚本报错怎么办： 执行效果： ","link":"http://quansen88.cn/20190925error-cant-connect-to-local-mysql-server-through-socket/"},{"title":"数据库性能测试：sysbench用法详解","content":"数据库性能测试：sysbench用法详解 完全参考：https://www.cnblogs.com/f-ck-need-u/p/9279703.html 1.简介和安装 sysbench是一个很不错的数据库性能测试工具。 官方站点：https://github.com/akopytov/sysbench/ rpm包下载：https://packagecloud.io/akopytov/sysbench/packages/el/7/sysbench-1.0.15-1.el7.centos.x86_64.rpm 源码包下载：https://github.com/akopytov/sysbench/archive/1.0.17.zip 如果是编译安装，需要先安装好mysql的开发包(尽管编译错误时提示的是缺少Mysql库文件)。 本次使用yum安装 2.sysbench使用方法 以下列出了sysbench对测试mysql时常用的选项。 3.准备测试数据 首先创建sysbench所需数据库sbtest(这是sysbench默认使用的库名，必须创建测试库)。 然后，准备测试所用的表，这些测试表放在测试库sbtest中。这里使用的lua脚本为/usr/share/sysbench/oltp_common.lua。 其中--tables=10表示创建10个测试表，--table_size=100000表示每个表中插入10W行数据，prepare表示这是准备数的过程。 如果想要清除这10个表，可使用cleanup命令。 4.数据库测试和结果分析 稍微修改下之前准备数据的语句，就可以拿来测试了。 需要注意的是，之前使用的lua脚本为oltp_common.lua，它是一个通用脚本，是被其它lua脚本调用的，它不能直接拿来测试。 所以，我这里用oltp_read_write.lua脚本来做读、写测试。还有很多其它类型的测试，比如只读测试、只写测试、删除测试、大批量插入测试等等。可找到对应的lua脚本进行调用即可。 以下是测试返回的结果： 5.cpu/io/内存等测试 sysbench内置了几个测试指标。 可直接help输出测试方法。例如，fileio测试。 例如，创建5个文件，总共1G，每个文件大概200M。 然后，运行测试。 结果： 再比例cpu性能测试： ","link":"http://quansen88.cn/20190924-shu-ju-ku-xing-neng-ce-shi-sysbench-yong-fa-xiang-jie/"},{"title":"mysql5.7部署多实例踩坑记","content":"mysql5.7部署多实例踩坑记 参考：https://www.cnblogs.com/qizhelongdeyang/p/6292966.html 参考：https://blog.csdn.net/zougen/article/details/79567744 参考：https://blog.csdn.net/zhengwei125/article/details/52413835 初始化：略（） 建账号： 下载安装： 初始化数据库 导入环境变量 生成配置文件： 这个配置文件来自：https://blog.csdn.net/zougen/article/details/79567744 生成启动脚本： 启动测试 统一改密码，方便管理 修改my.cnf，加入pass字段 参考：https://www.cnblogs.com/qizhelongdeyang/p/6292966.html 测试效果 踩到的坑： 第一篇文章的作者遇到了不能关闭mysql实例的问题，我也遇到了； 不过碰巧我的mysql密码忘了，我就skip-grant-table改密码，完事后发现可以使用stop关闭mysql实例 于是在网上搜”mysqld_multi stop无效“的问题，然后搜到了这篇文章 实验中的不足： 实验后续： 在这篇文章中的作者遇到的是：它在my.cnf中写的是password字段，发现无法关闭mysql.然后用my_print_defaults打印密码是加密的，没错，我测试了下，确实如此 所以这位博主改了启动脚本： mysql5.7.27多实例部署脚本 执行效果： 如果失败或某些报错： ","link":"http://quansen88.cn/20190923mysql57-bu-shu-duo-shi-li-cai-keng-ji/"},{"title":"mariadb10.2快速部署一主一从","content":"mariadb快速部署一主一从 初始化机器： 安装 配置： 主： 从： 测试： ","link":"http://quansen88.cn/20190923mariadb102-kuai-su-bu-shu-yi-zhu-yi-cong/"},{"title":"一键自签CA证书脚本","content":"一键自签CA证书脚本 参考：https://blog.csdn.net/gengxiaoming7/article/details/78505107 参考：https://blog.csdn.net/yuyin1018/article/details/82868287 脚本： 效果： ","link":"http://quansen88.cn/20190922-yi-jian-zi-qian-ca-zheng-shu-jiao-ben/"},{"title":"mysql之慢查询","content":"mysql之慢查询 参考：http://www.zsythink.net/archives/1260 参考：https://blog.csdn.net/qq_40884473/article/details/89455740 MySQL的慢查询，全名是慢查询日志，是MySQL提供的一种日志记录，用来记录在MySQL中响应时间超过阀值的语句。 一、相关变量 slow_query_log：是否开启慢查询日志，1表示开启，0表示关闭。 log-slow-queries ：旧版（5.6以下版本）MySQL数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件host_name-slow.log slow-query-log-file：新版（5.6及以上版本）MySQL数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件host_name-slow.log long_query_time：慢查询阈值，当查询时间多于设定的阈值时，记录日志。 log_queries_not_using_indexes：未使用索引的查询也被记录到慢查询日志中（可选项）。 slow_query_log_file 慢查询日志的位置 log_output：日志存储方式。log_output='FILE'表示将日志存入文件，默认值是'FILE'。log_output='TABLE'表示将日志存入数据库。 二、开启慢查询日志 可以使用命令开启，重启mysql失效；或者写入配置文件 Name Cmd-Line Option File System Var Status Var Var Scope Dynamic Slow_queries Yes Both No slow_query_log Yes Yes Yes Global Yes slow_query_log_file Yes Yes Yes Global Yes long_query_time Yes Yes Yes Both Yes 三、设置慢查询的时间 默认的最长查询时间是10s 设置最大查询时间 四、制造一个慢查询 使用sleep函数 另一边看看 通过explain查看哪里慢了：举个例子： https://www.iteye.com/blog/uule-2434391 总结： ","link":"http://quansen88.cn/20190921mysql-zhi-man-cha-xun/"},{"title":"mysql5.7的GTID主从复制","content":"mysql5.7的GTID主从复制 参考：https://www.cnblogs.com/luckcs/articles/6295992.html 参考：https://www.cnblogs.com/kevingrace/p/5569652.html（很详细） 一、GTID复制 GTID是MySQL 5.6的新特性，其全称是Global Transaction Identifier，可简化MySQL的主从切换以及Failover。GTID用于在binlog中唯一标识一个事务。当事务提交时，MySQL Server在写binlog的时候，会先写一个特殊的Binlog Event，类型为GTID_Event，指定下一个事务的GTID，然后再写事务的Binlog。主从同步时GTID_Event和事务的Binlog都会传递到从库，从库在执行的时候也是用同样的GTID写binlog，这样主从同步以后，就可通过GTID确定从库同步到的位置了。也就是说，无论是级联情况，还是一主多从情况，都可以通过GTID自动找点儿，而无需像之前那样通过File_name和File_position找点儿了。 摘抄：https://www.cnblogs.com/zejin2008/p/7705473.html 传统的基于binlog position复制的方式有个严重的缺点：如果slave连接master时指定的binlog文件错误或者position错误，会造成遗漏或者重复， 很多时候前后数据是有依赖性的，这样就会出错而导致数据不一致。 从MYSQL5.6开始，mysql开始支持GTID复制。GTID的全称是global transaction id，表示的是全局事务ID。GTID的分配方式为uuid:trans_id，其中：uuid是每个mysql服务器都唯一的，记录在$datadir/auto.cnf中。如果复制结构中，任意两台服务器uuid重复的话(比如直接冷备份时，auto.conf中的内容是一致的)，在启动复制功能的时候会报错。这时可以删除auto.conf文件再重启mysqld。 基于GTID主从复制的优点大致有： - 保证同一个事务在某slave上绝对只执行一次，没有执行过的gtid事务总是会被执行。 - 不用像传统复制那样保证binlog的坐标准确，因为根本不需要binlog以及坐标。 - 故障转移到新的master的时候很方便，简化了很多任务。 - 很容易判断master和slave的数据是否一致。只要master上提交的事务在slave上也提交了，那么一定是一致的。 - 当然，MySQL提供了选项可以控制跳过某些gtid事务，防止slave第一次启动复制时执行master上的所有事务而导致耗时过久。 - 虽然对于row-based和statement-based的格式都能进行gtid复制，但建议采用row-based格式。 二、GTID服务器相关选项 gtid_mode gtid模式 enforce_gtid_consistency 保证GTID安全的参数 三、安装： 初始化机器 安装mysql 四、配置 主服务器 **enforce-gtid-consistency：**MySQL官方解释说当启用enforce_gtid_consistency功能的时候，MySQL只允许能够保障事务安全，并且能够被日志记录的SQL语句被执行，像create table … select 和 create temporary table语句，以及同时更新事务表和非事务表的SQL语句或事务都不允许执行： 参考：https://blog.csdn.net/qq_27371099/article/details/85339536 从服务器 五、两个yes表示OK mysql&gt; show slave status\\G 六、测试 注意事项： 1、change master to那一行那么长不要记，用help查看 2、如果master的信息填错了，不要慌 3、判断slave是否连上 4、如何跳过某些错误、 比如有实习员工误把从数据库当主数据库操作，创建数据库db1，然后主数据库又创建数据库db1 Retrieved_Gtid_Set是slave接收到的事务的信息， Executed_Gtid_Set是slave已经执行的slave的信息 所以多个一个已经执行过的事务,跳过它即可，因为执行过了，不需要再次执行 参考：https://blog.csdn.net/wll_1017/article/details/70332107 参考：https://www.cnblogs.com/luckcs/articles/6295992.html 5、如果错误太多，可以考虑重新部署slave节点， 可以在晚上访问量少的时候，将主节点数据mysqldump恢复到slave节点，再重新部署主从同步 6、主从复制的选项总结 7、相关命令 8、如何清除binlog日志 切记不要手动删，可以设置binlog的自动清理 默认应该是0，不自动清理 清除所有binlog，让binlog重新计数 清除指定二进制 mysql 5.7的帮助中，写着支持删除指定某个binlog之前的日志 或者 删除某个时间点前的binlog 9、相关概念 10、从服务器一定不要修改数据库 这个很关键 11、主主复制不推荐使用 很容易导致数据不一致 ","link":"http://quansen88.cn/20190921mysql57-de-gtid-zhu-cong-fu-zhi/"},{"title":"MYSQL事务隔离级别","content":"MYSQL事务隔离级别 完全参考：https://www.cnblogs.com/geaozhang/p/10478918.html 一、事务描述 1、事务的四个特性 ACID 1. A：原子性 = 一个事务或者都成功、或者都失败； 2. C：一致性 = 在整个事务的生命周期里面，查询到的数据是一致的； MVCC多版本并发控制：利用undo保存某一时刻数据快照，通过版本号来减少锁的争用，保证各个事务互不影响。 3. I： 隔离性 = 隔离级别； 4. D：持久性 = 只要事务commit，这个事务不会因为系统的崩溃而丢失； 持久性和原子性对于所有的支持事务的数据库都是一样的，都满足。 2、常见事务格式 start transaction; DML ( insert; delete; update; ) commit; 3、MySQL 默认每一条 DML 是一个事务 通过参数 'autocommit' 进行控制是否默认提交事务； SQL 自动提交开启，有一定的危险性(没有 rollback )。 墙裂推荐：关闭 SQL 的自动提交； 血泪教训：曾经自信过了头的一次 sitesup （其实也是有反复确认），同时疏忽了备份，命令行下一个回车敲下去，发现问题大发了……所以，备份 + 显式 Commit 很重要。 4、大事务+长事务 数据库的大事务和长事务会带来undo的持续增加、undo暴增，空间不可复用； 事务信息表：information_schema.INNODB_TRX，用来查看长事务、大事务。 5、空闲事务+锁 start transaction; update; …… // 空闲等待，时间可能不可控 …… // 空闲等待 update; commit; 1. 事务和事务锁有一定的关系：事务不提交、行锁就不会释放、事务锁就不会消失 2. 死锁：是指两个或两个以上的事务在执行过程中，因争夺锁资源而造成的一种相互等待的现象。死锁出现的概率是非常低的，因为innodb内置有死锁检查机制，当出现死锁时会自动回滚占用undo资源少的事务。 二、事务隔离级别 0、隔离性 1. MySQL 有多个隔离级别，可以调整，隔离性越弱并发性越好； 2. 每个数据库都有自己默认的隔离级别 会话级别设置：set @@session.tx_isolation=…… 1、READ-UNCOMMITED 未提交读，隔离性最弱，但并发性最好； 事务中的修改，即使没有提交，对其他事务也都是可见的，也就是说事务可以读取未提交的数据，读到脏数据(脏读，dirty read)； 2、READ-COMMITED 大部分数据库系统的默认隔离级别都是READ-COMMITED，但MySQL不是； 1. 提交读，一个事务从开始直到提交之前，所做的任何修改对其他事务都是不可见的； 2. 不可重复读，在同一个事务中，同一个SQL执行多次(该记录修改事务提交前、提交后)，得到的结果可能不同：幻读； 3、REPEATABLE-READ 可重复读，MySQL默认隔离级别； 在同一个事务中，同一个SQL执行多次，得到的结果是相同的； 1. 对于普通 select 来说，通过 MVCC 来实现，解决脏读问题、幻读问题； 2. 对于 dml、select for update，通过范围锁实现，解决幻读问题； 4、SERIALIZABLE (serializable 连载、串行化) 隔离性最高，没有并发； 对于同一个数据来说，在同一个时间段内，只能有一个会话可以访问，包括select和dml，通过执行事务串行执行，避免幻读问题； 也就是说，对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。 注意：业务有串行化的需求，但是我们不会设置数据库事务为串行化隔离级别，而是在应用端设置解决(例：U盾)。 ","link":"http://quansen88.cn/20190920mysql-shi-wu-ge-chi-ji-bie/"},{"title":"mysql 的二进制日志binlog","content":"1、切断数据库的访问，避免生成更多二进制日志 #此时最好应该先将备份的数据在测试机恢复测试，有条件的话将此时binlog日志也备份到另一台机器上： 2、设置binlog为关闭状态，避免恢复过程产生更多二进制日志(会话级关闭) mysql&gt; SET session sql_log_bin=OFF; 3、查看此时的binlog文件和位置 mysql&gt; show master status; +-------------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +-------------------------+----------+--------------+------------------+-------------------+ | mysql3308_binlog.000001 | 154 | | | | +-------------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 4、用昨天晚上备份的数据库文件进行回复 mysql&gt; source /tmp/hellodb.sql 5、查看昨天晚上最后的position或者最后备份的时间 [root@mysql tmp]# tail -1 hellodb.sql -- Dump completed on 2019-09-20 20:55:35 6、取出2019-09-20 20:55:35后指定范围内的binlog [root@mysql tmp]# mysqlbinlog --start-datetime='2019-09-20 20:55:35' --stop-datetime='2019-09-20 21:55:35' /data/mysql/3308/binlog/mysql3308_binlog.000001 -vvv &gt; /tmp/binlog.sql 7、使用binlog恢复今天的数据 mysql&gt; source /tmp/binlog.sql 8、开启binlog（或者关闭会话） mysql&gt; set @@session.sql_log_bin=1; Query OK, 0 rows affected (0.00 sec) 9、测试没有问题后开启数据库访问 ","link":"http://quansen88.cn/20190920mysql-de-er-jin-zhi-ri-zhi-binlog/"},{"title":"mysql小知识点","content":"mysql小知识点 参考：https://www.cnblogs.com/geaozhang/p/6834780.html 一、mysql选项查看，要会看这张表： https://dev.mysql.com/doc/refman/5.7/en/server-option-variable-reference.html https://mariadb.com/kb/en/library/full-list-of-mariadb-options-system-and-status-variables/ mysqld选项： 选项名称；是否可以作为命令行选项；是否可以作为为配置文件选项；是否是系统变量，是否为状态变量；变量的作用范围（有global和session两种）；是否是动态参数 以sql-mode为例，它是命令行选项，又是文件选项，又是系统变量，变量作用范围为全局，动态： sql-mode Yes Yes Yes Both Yes 1、sql-mode可以在运行mysqld时指定,下面指定seq-mode为空 2、可以作为文件选项，可以在mysql的配置文件my.cnf的mysqld段指定 3、sql-mode是系统变量，系统变量可以使用show variables查看,也可以通过set global设置 4、sql_mode不是状态变量，因此查不到 5、sql-mode该变量的范围是global和session，可以分别查看下 6、sql_mode是动态参数 二、sql_mode的含义 ​ 对其设置可以完成一些约束检查的工作,可分别进行全局的设置或当前会话的设置 ​ 参考：https://mariadb.com/kb/en/library/sql-mode/ 比如： ONLY_FULL_GROUP_BY ​ 对于GROUP BY聚合操作，如果在SELECT中的列，没有在GROUP BY中出现，那么将认为这个SQL是不合法的。 三、mysqladmin检测mysql状态 mysqladmin可以修改密码，删除，创建数据库，刷新表，刷新日志，查看状态，关闭数据库 四、mysql忘记密码 网上文章还是挺多的！！！ https://dev.mysql.com/doc/refman/5.7/en/server-option-variable-reference.html 从上面链接的表上可以看到，skip-grant-tables变量可以作为命令行选项用，也可以当配置文件选项来使用 skip-grant-tables Yes Yes 在命令行中使用： 在配置文件中使用 五、mysql的3306端口抓包实验 通过wireshark抓包，看到将mysql的数据包全部截获，并且全部是明文，mysql加密后的密码也截获到，mysql的密码加密机器简单，通过在线解密工具很容易得到其真实密码，这就是为何mysql的3306端口坚决不能暴露的原因。还有就是mysql一般监听在本地或者局域网内，公网的话如果必须要，那么一定要设置防火墙，安全组。 六、mysql怎么允许别的主机连 七、mysql备份还原注意 写好备份脚本后，一定要手动备份一次，看能否成功，并且将备份的数据库文件在测试机上做还原演练，看备份的对不对，能不能用 八、mysql的索引 索引的查看，添加，删除，以及explain查询是否使用了索引 查看表上的索引： 添加索引： 如何确认查询使用了索引： 删除索引： 九、myisam和innodb区别 我记得最深刻的一点就是myisam是表级锁，而innodb支持行级锁。好处就是不至于我改表上内容，别人完全无法修改此表 然后：Myisam不支持事务，不支持事务就比较难受了，innode支持 Myisam不支持热备，innode支持 （明天补充） 十、索引不是必须有 常用的索引类型是B tree，有助于读请求，但不利于写请求。 十一、事务的四个特性 参考：https://www.cnblogs.com/geaozhang/p/10478918.html 看到事务，让我联想到银行取钱，不会因为银行突然断电，钱取出来了钱没扣 ACID A：原子性：一个事务中的操作要么都成功，要么都失败回滚 C：一致性：在整个事务的生命周期里面，查询到的数据是一致的； I：隔离性：隔离级别； D：持久性： 只要事务commit，这个事务不会因为系统的崩溃而丢失； 十二、MySQL默认每一条SQL都是一条事务 意思是：我这个命令只要回车了，立马会执行 有DBA工程师说，关闭SQL的自动提交，避免误操作 十三、事务的隔离级别 1234 十四、mysqldump --single-transaction参数的作用 --single-transaction参数的作用，设置事务的隔离级别为可重复读，即REPEATABLE READ，这样能保证在一个事务中所有相同的查询读取到同样的数据，也就大概保证了在dump期间，如果其他innodb引擎的线程修改了表的数据并提交，对该dump线程的数据并无影响，在这期间不会锁表。 十五、my_print_defaults my_print_defaults 这个程序是用来解析my.cnf文件的，将其中的参数打印到终端。这个小程序在mysql的启动脚本中会有用到。 十六、binlog相关命令 十七、DDL，DML DDL：数据定义语言，管理数据库的对象（CREATE，DROP，ALTER，TRUNCATE） DML：数据操纵语言：SELECT，INSERT，UPDATE，DELETE，CALL，EXPLAIN 十八、从数据库如果还想再连slave数据库 十九、压力测试、优化吞吐量 参考：https://blog.csdn.net/qq_18312025/article/details/78897023 二十、事务 ","link":"http://quansen88.cn/20190918mysql-xiao-zhi-shi-dian/"},{"title":"mysql的安装","content":"mysql的安装 一、yum安装 二、通用二进制安装 下载地址： https://mirrors.huaweicloud.com/mysql/Downloads/MySQL-5.6/mysql-5.6.45-linux-glibc2.12-x86_64.tar.gz https://mirrors.huaweicloud.com/mysql/Downloads/MySQL-5.7/mysql-5.7.27-linux-glibc2.12-x86_64.tar.gz 安装到/data/mysql目录下面 初始化数据库 所以用mysqld --initialize来替代mysql_install_db 配置文件可以放到/etc，也可以放到mysql安装目录 官网说：从5.7.18开始不在二进制包中提供my-default.cnf文件。参考：https://dev.mysql.com/doc/refman/5.7/en/binary-installation.html 配置service文件，centos7还可以使用sys init文件，两种方法都行 PATH变量 启动mysql 修改密码： 三、CentOS7二进制安装mysql5.7脚本 共2个文件 my.cnf mysql-install.sh 四、mysql多实例部署 参考另一篇文章：另一篇文章完成了！ 意思就是：一个服务器上跑多个mysql数据库，每个数据库使用不一样的端口 mysql二进制安装可以发现，就那几个目录和文件： etc文件目录；mysql相关命令目录；mysql的数据目录；pid文件目录；log目录；sock文件目录；启动脚本目录 安装mysql数据 通过yum或二进制包安装，由于启动脚本不适合5.7.27，所以此处用二进制的安装程序 创建MySQL用户，刚才yum安装mysql已经创建了 安装db 生成配置文件 提供sysV服务管理脚本 yum安装的mysql，mysql命令在/usr/bin/mysql，所以basedir=/usr 上面二进制安装安装mysql命令在/usr/local/mysql/bin/mysql，所以basedir=/usr/local/mysql 脚本只需该端口和datadir目录即可 我使用的官方的mysql.service那个脚本，脚本会调用masqld_safe,为了方便，我把所有选项都写到 脚本复制到相关目录下面 启动试试 问题很大，暂时不高了 ","link":"http://quansen88.cn/20190918mysql-de-an-zhuang/"},{"title":"mysql5.7忘记密码","content":"mysql5.7忘记密码 mysql的选项表：https://dev.mysql.com/doc/refman/5.7/en/server-system-variables.html 方法一：使用命令： 命令也可以，此处不用命令了 方法二： 修改my.cnf，加两行，skip-networking意思是只允许本地可以连接，其实3306端口不可能暴露在公网中的，因为通过抓包可以看到mysql的数据包都不加密，很容易抓到mysql的密码，mysql的密码是普通加密，可以轻松破解。因此该选项防内网中的小人，防止你在改密码的时候恰好被内网中的某台服务器连上了被改密码 不能使用alter改，只能更新表update 删除my.cnf两行，重启mysql ","link":"http://quansen88.cn/20190918mysql57-wang-ji-mi-ma/"},{"title":"docker socket设置监听在本地端口","content":"docker socket设置监听在本地端口 参考：https://docs.lvrui.io/2017/02/19/docker-socket%E8%AE%BE%E7%BD%AE/ 一、改daemon.json 二、重启报错 三、根据网友所说，是因为 docker 的 socket 配置出现了冲突,改 四‘重启，好了 ","link":"http://quansen88.cn/20190917docker-socket-she-zhi-jian-ting-zai-ben-di-duan-kou/"},{"title":"DNS术语；主从DNS服务器配置；DNS综合实验","content":"DNS术语；主从DNS服务器配置；DNS综合实验 权威服务器和(非)权威应答 **权威服务器（权威者）可以理解为直接上层域的DNS服务器。**例如www.baidu.com这台主机的上层域是baidu.com，那么对www来说，它的权威服务器就是baidu.com这个域内负责解析的DNS服务器，而对于baidu.com这个主机来说，它的权威服务器是.com这个域负责解析的DNS服务器。 更具体的说，某域的权威服务器是可以直接查看该域数据(即区域数据文件)的DNS服务器，主、从DNS服务器都是权威服务器。 只有权威服务器给出的应答才是权威应答，否则就是非权威应答。为什么呢？因为一个域中所有的主机都是在DNS服务器中的区域数据文件中记录的，对于主机来说，它们的位置只有直接上层才知道在哪里。 因此如果解析www.baidu.com时要获得权威应答，应该将DNS指向baidu.com这个域内负责解析的DNS服务器。 只有权威服务器直接给出的答案才是永远正确的，通过缓存得到的答案基本都是非权威应答。当然这不是一定的，因为权威服务器给的答案也是缓存中的结果，但是这是权威答案。DNS服务器缓存解析的数据库时间长度是由权威服务器决定的。 DNS缓存 在Client和DNS服务器这些个人订制的DNS解析系统中都会使用缓存来加速解析以减少网络流量和查询压力，就算是解析不到的否定答案也会缓存。 但是要访问的主机IP可能会改变，所有使用缓存得到的答案不一定是对的，因此缓存给的答案是非权威的，只有对方主机的上一级给的答案才是权威答案。缓存给的非权威答案应该设定缓存时间，这个缓存时间的长短由权威者指定。 另外访问某个域下根本不存在的主机，这个域的DNS服务器也会给出答案，但是这是否定答案，否定答案也会缓存，并且有缓存时间。例如某个Client请求51cto.com域下的ftp主机，但是实际上51cto.com下面可能根本没有这个ftp主机，那么51cto.com就会给否定答案，为了防止Client不死心的访问ftp搞破坏，51cto.com这个域负责解析的DNS服务器有必要给Client指定否定答案的缓存时间。 主、从dns服务器 dns服务器也称为name server，每个域都必须有dns服务器负责该域相关数据的解析。但dns服务器要负责整个域的数据解析，压力相对来说是比较大的，且一旦出现问题，整个域都崩溃无法向外提供服务，这是非常严重的事。所以，无论是出于负载均衡还是域数据安全可用的考虑，两台dns服务器已经是最低要求了，多数时候应该配置多台dns服务器。 多台dns服务器之间有主次之分，主dns服务器称为master，从dns服务器称为slave。slave上的域数据都是从master上获取的，这样slave和master就都能向外提供名称解析服务。 1、主DNS服务器 测试：[root@client ~]# nslookup www.taobao.com 192.168.38.130 2、从DNS配置 测试：[root@client ~]# nslookup www.taobao.com 192.168.38.137 配置&quot;仅缓存&quot;dns服务器 清空缓存的命令：rndc flush dig和nslookup都可以指定DNS服务器查询 仅用作提供缓存的dns服务器，当有客户端请求该dns服务器帮忙解析某个地址时，它不会直接为外界主机提供dns解析，而是自己去找其他dns服务器解析，并将结果缓存在本地，并将缓存结果提供给客户端。 也就是说，仅缓存dns服务器其实扮演的角色和客户端一样，只不过它还未其他客户端提供解析查询而已。 要配置仅缓存dns服务器，只要配置3个任何时候都必要的域：根域&quot;.&quot;、&quot;localhost&quot;域和&quot;1.0.0.127.in-addr.arpa&quot;。也就是说，任何一台完整的dns服务器，至少都是&quot;缓存&quot;服务器。 所以，仅缓存dns服务器配置如下： 配置dns转发服务器 配置成了转发服务器，named.conf里所有的zone都将失效(除非配置转发区和空转发区)，也就是不会再做任何解析（包括对根的查询），收到的解析请求全都提交给转发选项里指定的机器，转发选项所指定的机器称为转发器。转发器还可以指定给上一层。 如图：192.168.38.133为转发者，192.168.38.138配置方式为： 这表示将192.168.38.133收到的所有查询请求都交给192.168.38.128这台转发器，由这台转发器帮忙查询相关请求，然后回复给转发者，由转发者回复给客户端 转发者转发给转发器的查询是递归查询，转发器必须要亲自回复转发者 同样，如果forward留空的，表示该区禁止转发 ACL 顾名思义，访问控制列表，定义一组规则，方便下面引用 此外，还有4个预定义的acl值：any、none、localhost(DNS服务器的任一IP地址)、localnets(DNS服务器任一ip地址所在网段) 递归查询 ​ dns解析器发起的查询都是递归查询，所以一般客户端配置DNS指向谁就表示找谁帮忙做递归查询。如果dns服务器接受它的递归查询请求，则它会去帮助查询，如果dns服务器不接受它的递归查询请求，则会将递归查询当成迭代查询看待，让请求者自己去查询。 ​ 另外，允许递归查询的服务器，由于要帮忙查询，所以在递归查询服务器上总是缓存了一些非权威数据，如果是非递归查询服务器，则不用缓存任何数据，只需返回其负责的域的权威数据即可，这对减轻压力的作用是非常大的。 ​ 不要将非递归查询dns服务器设置为转发器，因为转发者转发给转发器的查询是递归查询。 一、主从DNS服务器的配置 主服务器配置 1是修改/etc/named.conf 2是修改/etc/named.rfc1912.zones，添加域 3是添加正向解析域文件/var/named/jd.com.zone 不写了。如上面所示 DNS大实验 不写了。 参考：https://thson.blog.csdn.net/article/details/94427779 注意，这位同学的文章某些地方还是有些小问题的 ","link":"http://quansen88.cn/20190910dns-zhu-yu-zhu-cong-dns-fu-wu-qi-pei-zhi-dns-zong-he-shi-yan/"},{"title":"优盘全自动安装CentOS7","content":"优盘全自动安装CentOS7 https://blog.csdn.net/q919683527/article/details/78011988 https://blog.csdn.net/gui951753/article/details/81461728 https://blog.csdn.net/Eumenides_s/article/details/78040687 参考： 该脚本是可用的，测试过。。。 光盘可以刻录到优盘或创建虚拟机 ","link":"http://quansen88.cn/20190909-you-pan-quan-zi-dong-an-zhuang-centos7/"},{"title":"DNS实验一：搭建一个简单的DNS服务器","content":"DNS实验一：搭建一个简单的DNS服务器，配置正向解析与反向解析 参考：https://thson.blog.csdn.net/article/details/94427779 老生常谈：初始化机器 2、name.conf option代码段含义： 可以自行去man：man named.conf 需要修改两项： [root@server ~]# systemctl restart named 3、添加域 ​ zone关键字后面接的是域和类，域是自定义的域名，IN是internet的简称，是bind 9中的默认类，所以可以省略。type定义该域的类型是&quot;master | slave | stub | hint | forward&quot;中的哪种，file定义该域的区域数据文件，因为这里是相对路径db.taobao.com，它的相对路径是相对于/var/named的，也可以指定绝对路径/var/named/db.taobao.com。 4、配置区域文件/var/named/db.taobao.com ​ 嗯，现在我有三台虚拟机和一个dns服务器（即当前机器）。三台虚拟机分别是www（淘宝首页），miaosha（淘宝秒杀），xianyu（二手咸鱼）。 ​ 其中第一行的&quot;TTL6h&quot;表示缓存周期，即查询该域中记录时肯定答案的缓存时间长度。例如本地查询www.baidu.com时，本地将缓存baidu.com域的相关查询结果，缓存时间长度由baidu.com这个域的区域数据文件中定义的TTL 6h&quot;表示缓存周期，即查询该域中记录时肯定答案的缓存时间长度。例如本地查询www.baidu.com时，本地将缓存baidu.com域的相关查询结果，缓存时间长度由baidu.com这个域的区域数据文件中定义的TTL6h&quot;表示缓存周期，即查询该域中记录时肯定答案的缓存时间长度。例如本地查询www.baidu.com时，本地将缓存baidu.com域的相关查询结果，缓存时间长度由baidu.com这个域的区域数据文件中定义的TTL的值决定。 ​ 第二行定义的是SOA记录，每个区域文件中的第一个资源记录定义行都要是SOA记录。在该行中除了指定了master dns服务器，还指定了一些附加属性，包括序列号为1，还有各种时长等信息。第四列指定了&quot;dnsserver.taobao.com.&quot;为该域的master DNS服务器。第五列是该域的管理员邮箱地址，但注意不能使用@格式的邮箱，而是要将@符号替换为点&quot;.&quot;第六列使用括号将几个值包围起来。第一个值是区域数据文件的序列编号serial，每次修改此区域数据文件都需要修改该编号值以便让slave dns服务器同步该区域数据文件。第二个值是刷新refresh时间间隔，表示slave dns服务器找master dns服务器更新区域数据文件的时间间隔。第三个值是重试retry时间间隔，表示slave dns服务器找master dns服务器更新区域数据文件时，如果联系不上master，则等待多久再重试联系，该值一般比refresh时间短，否则该值表示的重试就失去了意义。第四个值是过期expire时间值，表示slave dns服务器上的区域数据文件多久过期。第五个值是negative ttl，表示客户端找dns服务器解析时，否定答案的缓存时间长度。这几个值可以分行写，也可以直接写在同一行中使用空格分开，所以，上面的SOA记录可以写成如下格式： ​ 第一列的@表示taobao.com. ​ 后面5行就是A记录和CNAME记录了，分别定义了{dnsserver,www,miaosha,xianyu}.taobao.com主机对应的IP地址，最后一行的CNAME就是别名了。 检查区域文件： 检查配置文件 启动服务和加载配置文件 5、dig或host或nslookup测试下 6、给www，miaosha，xianyu三台服务器配置网页 7、windows测试，windows要手动改dns 参考这个改：https://thson.blog.csdn.net/article/details/94427779 实验二、配置反向查找区域 ​ 反向查找是根据ip地址查找其对应的主机名。在/etc/named.conf中，需要定义&quot;zone .in-addr.arpa&quot;，其中&quot;&quot;是点分十进制ip的反写，可以是反写ip后的任意一段长度，例如127.0.0.1反写后是1.0.0.127，所以zone所定义的可以是&quot;1.0.0.127&quot;、&quot;0.0.127&quot;、&quot;0.127&quot;，甚至是&quot;127&quot;，长度位数不同，在区域数据文件中需要补全的数值就不同。 ​ 另外，反向查找区域的各种缓存时间可以都设置长一点，因为用的不多。 ​ 就以127.0.0.1解析为localhost为例。 ​ 在/etc/named.rfc1912.zones中已有这样一段： 其区域数据文件/var/named/named.loopback内容如下： 将/etc/named.rfc1912.zones中将1.0.0.127.in-addr.arpa区域的配置注释掉，改为如下内容： 然后书写其区域数据文件/var/named/named.loopback.test。 在上述配置中，特意将1.0的ptr记录写成了&quot;local.&quot;，这样查询1.0.0.127的主机名时，将得到local而不是localhost。 使用dig -x测试，dig的&quot;-x&quot;选项专门用于反向查找。 ​ 现在，可以配置longshuai.com中主机的反向解析区域，由于在实验过程中，该域中的主机地址都是192.168.38.0/24网段内的主机，所以只需要配置一个38.168.192.in-addr.arpa反向查找区域即可，如果域内主机跨了多个网段，例如172.16.10.0/24和192.168.100.0/24，则需要配置两个反向查找区域。 重启named，然后使用dig -x测试。 ","link":"http://quansen88.cn/20190909dns-shi-yan-yi-da-jian-yi-ge-jian-dan-de-dns-fu-wu-qi/"},{"title":"编译busybox","content":"编译busybox **一、**yum install gcc gcc-c++ glibc glibc-devel pcre pcre-devel openssl openssl-devel systemd-devel zlib-devel glibc-static ncurses-devel lbzip2 **二、**wget https://busybox.net/downloads/busybox-1.30.1.tar.bz2 **三、**tar xf busybox-1.30.1.tar.bz2 **四、**cd busybox-1.30.1/ **五、**make menuconfig ​ 按下面选择，把busybox编译也静态二进制、不用共享库 Busybox Settings --&gt;Build Options --&gt;[*] Build BusyBox as a static **六、**make &amp;&amp; make install 如果出错，执行make clean后，重新执行上面命令 **七、**mkdir /mnt/sysroot/ **八、*cp -a _install/ /mnt/sysroot/ ","link":"http://quansen88.cn/20190908-bian-yi-busybox/"},{"title":"PXE+kickstart无人值守安装centos7","content":"PXE+kickstart无人值守安装centos7 1.1 PXE说明 所谓的PXE是Preboot Execution Environment的缩写，字面上的意思是开机前的执行环境。 要达成PXE必须要有两个环节： (1)一个是客户端的网卡必须要支持PXE用户端功能，并且开机时选择从网卡启动，这样系统才会以网卡进入PXE客户端的程序； (2)一个是PXE服务器必须要提供至少含有DHCP以及TFTP的服务！ 且其中： ​ · DHCP服务必须要能够提供客户端的网络参数，还要告知客户端TFTP所在的位置； ​ · TFTP则提供客户端的boot loader及kernel file下载路径。 还要加上NFS/FTP/HTTP(选择一样即可)等提供安装文件(安装镜像的解压文件)，才算是比较完整的PXE服务器。一般TFTP和DHCP服务都由同一台服务器提供，且大多数时候还提供NFS/FTP/HTTP服务，所以PXE服务器一般是提供3合一的服务。 1.2 PXE流程 如下图：图片来源于网络，虽不易理解，但细节描述的很好。 (1).Client向PXE Server上的DHCP发送IP地址请求消息，DHCP检测Client是否合法（主要是检测Client的网卡MAC地址），如果合法则返回Client的IP地址，同时将pxe环境下的Boot loader文件pxelinux.0的位置信息传送给Client。 (2).Client向PXE Server上的TFTP请求pxelinux.0，TFTP接收到消息之后再向Client发送pxelinux.0大小信息，试探Client是否满意，当TFTP收到Client发回的同意大小信息之后，正式向Client发送pxelinux.0。 (3).Client执行接收到的pxelinux.0文件。 (4).Client向TFTP请求pxelinux.cfg文件(其实它是目录，里面放置的是是启动菜单，即grub的配置文件)，TFTP将配置文件发回Client，继而Client根据配置文件执行后续操作。 (5).Client向TFTP发送Linux内核请求信息，TFTP接收到消息之后将内核文件发送给Client。 (6).Client向TFTP发送根文件请求信息，TFTP接收到消息之后返回Linux根文件系统。 (7).Client加载Linux内核（启动参数已经在4中的配置文件中设置好了）。 (8).Client通过nfs/ftp/http下载系统安装文件进行安装。如果在4中的配置文件指定了kickstart路径，则会根据此文件自动应答安装系统。 1.3 部署环境说明 如下图，192.168.38.137是PXE服务器，提供dhcp+tftp+http服务。其他该网段内的主机为待安装系统的主机群。 1.4 部署DHCP服务 首先安装dhcp服务端程序。 DHCP主要是提供客户端网络参数与TFTP的位置，以及boot loader的文件名。同时，我们仅针对内网来告知TFTP的相关位置，所以可以编辑/etc/dhcp/dhcpd.conf在subnet的区块内加入两个参数即可。其中PXE上专门为PXE客户端下载的boot loader文件名称为pxelinux.0。 重启dhcp 1.5 部署TFTP 从流程图中可以看出，boot loader文件pxelinux.0以及内核相关的配置文件(目录pxelinux.cfg下)主要都是由TFTP来提供的！ TFTP的安装很简单，直接使用yum即可。不过要告诉客户端TFTP的根目录在哪里，这样客户端才能找到相关文件。另外要注意，TFTP是由xinetd这个super daemon所管理的，因此设定好TFTP之后，要启动的是xinetd。 默认TFTP服务的根目录是/var/lib/tftpboot/，默认就这个吧，然后disable改为no即可 启动TFTP并观察之： 接下来的文件必须要放置于/var/lib/tftpboot/目录下。 1.6 提供pxe的bootloader和相关配置文件 如果要使用PXE的开机引导的话，需要使用CentOS提供的syslinux包，从中copy两个文件到tftp的根目录/var/lib/tftpboot/下即可。整个过程如下： pxelinux.cfg是个目录，可以放置默认的开机选项，也可以针对不同的客户端主机提供不同的开机选项。一般来说，可以在pxelinux.cfg目录内建立一个名为default的文件来提供默认选项。 如果没有menu.c32或vesamenu.c32时，菜单会以纯文字模式一行一行显示。如果使用menu.c32或vesamenu.c32，就会有类似反白效果出现，此时可以使用上下键来选择选项，而不需要看着屏幕去输入数字键来选择开机选项。经过测试，使用vesamenu.c32比menu.c32更加好看些。 这部分设定完毕后，就是内核相关的设定了。 1.7 从安装镜像中获取Linux内核文件 要安装Linux系统，必须提供Linux内核文件和initrd文件，这里以64位版本的CentOS 7.2为例。 这里计划将内核相关文件放在/tftpboot/CentOS7.2/目录下。既然要从安装镜像中获取内核相关文件，首先得要挂载镜像。 其实仅需要vmlinuz和initrd.img两个文件即可，不过这里还将isolinux.cfg这个文件拷贝出来了，这个文件里提供了开机选项，可以以它作为修改开机选项和菜单的模板，这样修改起来比较容易，也更便捷！ 1.8 设置开机菜单并提供系统安装文件 以下是CentOS 7.6中syslinux包中提供的isolinux.cfg中提供的默认内容。 所以，将其稍作修改，使其适合做pxe的菜单配置文件。 其中&quot;net.ifnames=0 biosdevname=0&quot;这两个内核启动参数是为了让网卡名称为ethN，而不是默认的eno16777728这样的随机名称。 注意示例中stage2的路径是使用了网络源，最好本地搭建http，我偷懒了，当然ftp也可以 http的话直接把镜像挂载到相应目录即可 1.9 开机测试 新开一个虚拟机，进入bios界面设置从网卡启动。将首先搜索DHCP服务器，找到DHCP后搜索bootloader文件，启动菜单设置文件等，然后进入启动菜单等待选择要启动的项。如下： 因为只设置了一个启动项，所以菜单中只有一项。启动它，将加载一系列文件，直到出现安装操作界面。 然后就可以直接操作安装系统了。但这样毕竟是手动操作，无法实现批量系统安装，所以要提供一个自动应答文件，每一次的手动操作步骤都由自动应答文件中给定的项来应答，这样就能实现自动安装操作系统，也就能实现批量系统安装。 1.10 通过pxe+kickstart实现无人值守批量安装操作系统 所谓的无人值守，就是自动应答，当安装过程中需要人机交互提供某些选项的答案时（如如何分区），自动应答文件可以根据对应项自动提供答案。但是，无人值守并不完全是无人值守，至少设置bios从网卡启动是必须人为设置的，且安装完系统后设置不从网卡启动也是需要人为设置的。除此之外，其他的基本上都可以实现无人值守安装。 要配置无人值守的系统安装环境，需要提供安装过程中需要的各种答案，这些答案在kickstart的配置文件中设置，一般正常安装完Linux系统在root用户的家目录下有一个anaconda-ks.cfg **参考：**https://blog.csdn.net/yanghua1012/article/details/80426659 **参考：**http://ju.outofmemory.cn/entry/194801 **也可以使用图形化工具：**system-config-kickstart 以下是修改后该文件中的内容，将用来做kickstart应答文件。并设置由ftp服务来提供该文件，所以将kickstart文件保存到ftp的pub目录中。 设置后，修改/var/lib/tftpboot/pxelinux.cfg/default 文件，在其中的内核启动参数上加上一项kickstart文件的寻找路径。 **回归正题，**现在已经设置好/var/lib/tftpboot/pxelinux.cfg/default 和/var/www/html/ks_file/ks7_mini.cfg，所以可以进行无人值守安装Linux了。 ","link":"http://quansen88.cn/20190908pxekickstart-wu-ren-zhi-shou-an-zhuang-centos7/"},{"title":"cobber web","content":"cobber web 1、安装： yum install -y cobbler-web 2、然后就可以使用了（IP替换）： https://192.168.38.200/cobbler_web 3、错误排查 &quot;Internal Server Error...&quot; 排查参考：https://www.cnblogs.com/wang50902/p/10760404.html 先查看其日志位置： 分析日志 胡乱分析得到：django版本问题 解决： 4、cobbler web使用 参考：https://blog.csdn.net/liang_operations/article/details/80640428 创建用户密码： ","link":"http://quansen88.cn/20190908cobber-web/"},{"title":" cobbler无人值守批量安装Linux系统","content":"cobbler无人值守批量安装Linux系统 1.1 pxe安装系统 pxe的大致过程如下图。 ​ 其中pxelinux.0为bootloader。pxelinux.cfg目录下的文件(一般使用默认的default文件)定义了安装操作系统前的菜单项，如kernel和Initrd的路径，kickstart的路径等。 ​ 首先客户端请求pxe服务器上的dhcp，dhcp上指定了next-server和filename，它们分别是tftpd的地址和pxelinux.0的路径；然后客户端请求tftpd获取pxelinux.0，执行pxelinux.0后将引导进入安装界面，随后获取pxelinux.cfg目录下的文件并读取其中的配置，从中获取kernel和initrd的路径所在，如果有定义kickstart项则还会去获取kickstart文件并读取配置；再然后客户端请求获取kernel和initrd文件，以展开内核并进入到根文件系统；最后客户端获取完成系统安装所需的其他文件，这些文件可以是在pxe的本地，也可以是互联网上等能获取到的地方。 1.2 cobbler基本介绍 ​ 百度百科：Cobbler 可以用来快速建立 Linux 网络安装环境，它已将 Linux 网络安装的技术门槛，从大专以上文化水平，成功降低到初中以下，连补鞋匠都能学会。 ​ cobbler可以看作是一个更多功能的pxe，它实现系统安装和pxe也差不多，需要的文件和过程大致都一样。 ​ cobbler能自动管理dns/tftp/dhcp/rsync这四个服务(但似乎对tftp的管理有点bug，需要手动启动tftp)，且cobbler依赖于httpd(pxe支持http/nfs/ftp)。 ​ 基本的系统安装，cobbler只需生成一个distro和一个profile即可。 ​ distro相当于一个镜像，它提供安装系统过程中所需的一切文件，如vmlinuz,initrd以及rpm包等。 ​ profile的作用是为了自动修改pxelinux.cfg/default文件，每生成或修改一次profile，都会在default文件中修改或追加对应的label。 ​ 除了distro/profile之外，cobbler还管理system/images/repositories等，但是用的很少。 1.3 安装和配置cobbler 本实验环境网络为NAT，当然这不重要，桥接仅主机都行 关闭NAT的dhcp功能：让dhcp服务器给新机器分配IP 1.3.0 机器初始化 https://blog.51cto.com/14012942/2427695 1.3.1 安装cobbler cobbler在epel源中提供。由于还依赖于httpd、dhcp，所以httpd和dhcp也应该装上。 ​ 其中cobbler-web是提供web管理界面的，pykicstart是检查kicstart文件语法错误的，debmirror是维护debian源的工具，此处用不上但有依赖关系，所以装上。 ​ 安装后，在/etc/cobbler生成以下文件。 先启动httpd，再启动cobblerd。 ​ 启动之后，首先执行cobbler check检查配置是否正确。根据提示修改相关的配置项。 ​ 第一和第二个问题： ​ 第三个问题：/etc/xinetd.d/tftp，改下 ​ 第四个问题：获取pxelinux.0和menu.c32文件(对于centos来说只需这两个文件)，可以像pxe一样从syslinux包中手动复制到/var/lib/cobbler/loaders目录下，也可以执行cobbler get-loaders自动下载，但要求联网。 ​ 第五个问题：有可能该问题不是如此的，而是说要将rsyncd.service使用给start且enable，只需systemctl enable rsyncd，systemctl start rsyncd(网上抄的，重启rsync服务就对了)。 [root@xuexi cobbler]# vim /etc/xinetd.d/rsync disable=no [root@xuexi cobbler]# service xinetd start ​ 第6、7个问题，注释掉/etc/debmirror.conf中相关项即可。 ​ 第8个问题： ​ 第九个问题和电源管理有关，不用管了。直接重启cobbler，然后cobbler sync。 1.3.2 配置dhcp和tftp ​ 如果在/etc/cobbler/setting中设置了manage_dhcp:1，表示由cobbler管理dhcp(默认为0即人为手动管理)，则cobbler管理的dhcp的配置模板/etc/cobbler/dhcp.template会覆盖/etc/dhcp/dhcpd.conf中配置，所以应该修改dhcp.template。 此处采用默认的不由cobbler管理dhcp。 ​ 关于tftp，在/etc/cobbler/settings中默认启用了由cobbler管理tftp，所以此处无需配置它。只要知道它的根目录为/var/lib/tftpboot即可。但是如果后面装系统的时候如果找不到tftp(应该是cobbler管理tftp的bug)，则手动启动tftp即可。 1.4 cobbler从本地光盘安装系统 1.4.1 生成distro ​ 生成distro的方法有多种，可以从本地镜像导入生成，也可以根据网络上的资源生成。显然，从本地生成的效率是最好的。 ​ 从本地导入的过程实际上是将系统镜像中的文件复制到/var/www/cobbler/目录(默认)下。 等待导入完成，则表示distro生成完成。 确保url路径http://192.168.38.140/cobbler/ks_mirror/CentOS7.6/是有效的。 1.4.2 提供kickstart文件 ​ 以下是CentOS7的Kickstart内容。如果要改为适合CentOS6的内容，只需将keyboard项设置为&quot;keyboard us&quot;，并修改下分区方式(如有必要的话)以及%post脚本段的内容即可。 如何写kickstat： 1.可以参考家目录的anaconda-ks.cfg 2.使用图形化工具：system-config-kickstart（需要桌面环境） 3.参考/var/lib/cobbler/kickstarts/下面的模板 参考：http://ju.outofmemory.cn/entry/194801 参考：https://www.cnblogs.com/f-ck-need-u/p/7342022.html kickstat中密码生成方法： ksvalidator 命令可以验证ks文件语法有没有问题 ksvalidator /var/lib/cobbler/kickstarts/CentOS7.6.ks 上面的url也可以写成url --url=&quot;http://192.168.38.140/cobbler/ks_mirror/CentOS7.6/&quot;。 1.4.3 提供profile 在导入镜像生成distro的过程中，会自动生成一个profile。 该profile默认使用的kickstart是/var/lib/cobbler/kickstarts/sample_end.ks，所以需要修改此项。 对于centos7系列，则加上内核启动参数net.ifnames和biosdevname使得网卡名使用ethN系列而不使用enoXXXXXXX这样的随机名称。这个写在ks的文件中开机执行脚本那一段，修改/etc/default/grub也可以的 当然，不使用自生成的profile，自己添加一个profile也可以，同时还可以设置profile选项，如&quot;--kickstart&quot;项。如下：其中&quot;--distro&quot;指定该profile是添加到哪个distro下的。 实际上，每添加一个profile都是在向/var/lib/tftpboot/pxelinux.cfg/default中添加一个label。 也就是说，其实可以不用生成profile，自己手动编辑label也可以。 默认使用的菜单背景图片是menu.c32，此处我改为vesamenu.c32，该背景图片是从syslinux包中提取的，背景图片而已，看个人喜好了。另外默认菜单等待时间是2秒，在自动安装的环境中，可以将其设置的短些。并且进入菜单默认停留在local，即从本地启动系统，但是此时系统还没装，所以要实现自动化，建议修改此项。 以下是修改后的项。 在开始安装之前，要确保该ks路径是有效的且kickstart内容是正确的。有时候提供的Kickstart内容错误了，在制作成profile的时候不会报错，但实际上浏览器访问该ks路径的内容提示错误。例如，访问CentOS7.2.1-x86_64这个LABEL的kickstart文件，将其ks文件url地址http://172.16.10.10/cblr/svc/op/ks/profile/CentOS7.2.1-x86_64输入浏览器中。如果得到如下结果，则表示出错了，很大的可能是cobbler不支持kickstart中的某指令，这个需要慢慢检查。 查看下错误日志 解决：参考：https://blog.csdn.net/qq_34284638/article/details/86493535 发现是ks文件中有些中文的注释，删掉后，重新cobber sync即可 修改kickstart文件后，需要重新编译profile加载新的kickstart文件。只需使用cobbler profile edit --name=XXXXX --kickstart=YYYYY即可重新编译XXXXX这个profile，或者执行cobbler sync命令。直到浏览器中能获取到kickstart的内容时才算成功。 或者，使用cobbler profile getks --name=XXXXX命令获取名为XXXXX的profile的ks内容。 总之，必须要保证能正确获取到ks内容。 同理，加上CentOS6到cobbler里面： 1.4.4 开始安装 准备一个新的机器开机就会自动进入菜单，2-3秒超时后自动进行安装，安装完成后自动重启，重启时自动从本地启动。 所以，除了对新机器进行开机，其他的一切完完全全是全自动的。 建议在真正开始安装前，将dhcpd/rsyncd/tftp/cobbler等给重启一遍，防止中间改过哪些地方忘记重启而导致装机时出错。 1.5 比pxe+kickstart好的地方 仅就cobbler基本功能而言，它跟pxe的能力基本是一样的，只是提供了更多花哨的功能。 但cobbler能够使用变量，能够通过几个命令自动完成文件复制，修改等繁琐的动作，另外它提供了api接口，常用的是它的图形界面。在这一点上，它还是不错的。 1.6 让新机器自动执行脚本 有些时候新机器上要进行很多配置，在kickstart的%post段也可以配置，但是这里能进行的配置是有限的。 可以在cobbler服务端写好要执行的脚本，然后在新机器上将脚本使用scp复制过去，但是scp复制需要确认和输入密码，所以需要在kickstart的选包部分指定安装expect包，然后使用expect进行非交互scp。 最后在%post段直接执行此脚本即可。 出问题的地方总结： 1、要关掉NAT的dhcp 2、ks文件中别有中文注释 3、开始安装前重启下httpd，tftp，dhcpd，cobblerd 4、ks文件中的url别写url --url=$tree，写成http连接：url --url=&quot;http://192.168.38.140/cobbler/ks_mirror/CentOS7.6/&quot; 5、CentOS7机器的内存为1G时安装失败 6、安装CentOS7 mini安装包步骤都找不到，所以全部放到post里，安装后yum装包 7、ks文件中的rootpw可以通过shadow文件来获取 8、如果无特殊情况，一定要将/var/lib/tftpboot/pxelinux.cfg/default 默认启动项设置为local 9、CentOS6也出现了上图的问题：you have specified that the group base should be installed，解决方法：参考：https://www.fangc.xyz/detail/pxean-zhuang-you-have-specifie/ ,但是，这个报了个小错误 最后测试下ubuntu 附件 CentOS7.6.ks kickstart模版： https://www.lanzous.com/i6293oj 密码:20mx CentOS6.10-mini.ks ","link":"http://quansen88.cn/20190906-cobbler-wu-ren-zhi-shou-pi-liang-an-zhuang-linux-xi-tong/"},{"title":" 加密，gpg加密，ssh三种转发，openssl，pam","content":"加密，gpg加密，ssh三种转发，openssl，pam 一、仅开放本机两个IP地址中的一个地址172.16.0.X上绑定的sshd和vsftpd服务给172.16.0.0/16网络中除了 172.16.0.0/24网络中的主机之外的所有主机，但允许172.16.0.200访问,每次的用户访问都要记录于日志文件 中，注：其中X为学号 2、编写脚本/root/bin/checkip.sh，每5分钟检查一次，如果发现通过ssh登录失败次数超过10次，自动将此远 程IP放入Tcp Wrapper的黑名单中予以禁止防问 3、gpg加密解密： 交互式加密：会弹出一个框 交互式解密： 非交互式： 查看gpg版本：gpg -h CentOS7的gpg是2.0.22，Ubuntu18.04的gpg是2.2.4 4、非交互式生成密钥 5、ssh_config 6、ssh命令选项 ProxyCommand ssh当跳板机： 7、本地端口转发： 通过这条神奇的命令，现在就可以通过访问192.168.10.135:2222来访问192.168.38.154:80了 其中&quot;-L&quot;选项表示本地端口转发，其工作方式为：host3主机监听2222端口；host3将192.168.38.154:80映射为本地2222；当有人访问192.168.10.135:2222时，本地ssh将此端口的数据包转发给192.168.10.134；192.168.10.134将数据包转发给192.168.38.154:80 再来一个：ssh -L 2222:127.0.0.1:80 127.0.0.1 -fNg 该命令执行后，就把本机2222端口的流量转发给本机80端口了 可以发现，该命令执行后访问的还是本地IP的某一端口，所以叫本地转发 8、远程端口转发 远程端口转发表示的是将远程端口的数据转发到本地。 这个就牛逼了！将远程端口转发到本地，那我岂不是连接远程的端口就可以连接到本地服务器了！ 看下面，远程端口转发使用的是-R，注意公网服务器要开启GatewayPorts **其工作方式为：**192.168.38.140请求47.75.136.95上的ssh，在47.75.136.95上建立一个套接字监听2222端口，该端口是192.168.38.154:22的映射；当有主机连接47.75.136.95:2222时，此连接中的数据全部通过通过安全隧道转发给192.168.38.154:22 可以通过此方法，将内网搭建的博客网站映射出去，然后就可以通过公网访问了 再来一个：ssh -R 12345:127.0.0.1:22 47.75.136.95 -fNg 将请求转发给自己，该命令执行后，就可以通过47.75.136.95:12345来访问本地的192.168.38.140了 9、动态端口转发（SOCKS代理） ssh -D [bind_addr:]port remote ssh支持动态端口转发，由ssh来判断发起请求的工具使用的是什么应用层协议，然后根据判断出的协议结果决定目标端口 可以实现：让内网不能上网的服务器上网： 然后192.168.10.135机器将火狐浏览器设置代理到socket代理：192.168.10.134 1080 about:config将network.proxy.socks_remote_dns设置为true，开启远程DNS **工作方式：**我是192.168.38.140，我在本地监听1080，所有人都可以把数据转发到我的1080端口，我再把数据通过ssh隧道动态转发出去 10、ssh_config常改选项，优化 ssh_config的使用，将常用主机写到ssh_config或者~/.ssh/config里面,例如 ssh-agent管理密钥 ​ 生产环境中经常对密钥加密，每次连接都需要输入密码，很麻烦，而且多个私钥时，也不用自己去指定ssh-agent全部管理了 启动ssh-agent ssh-agent 添加私钥交给ssh-agent管理 ssh-add ~/.ssh/id_rsa 列出ssh-agent管理的密钥 ssh-add -L 注意 ​ 使用ssh-add失败，提示Could not open a connection to your authentication agent. 执行：ssh-agent bash 再试 ​ 还有一种情况下比如，主机A需要通过主机B才能访问主机C的情况下，我们可能需要在B上保存私钥才可以，但是如果使用ssh-agent的agent forwarding功能后，就可以使用主机A登陆B和C了，而不用在B上保存私钥 11、pam模块-google验证器 比如google身份验证就是通过pam模块实现的 如何使用：epel源安装google-authenticator apk：https://www.lanzous.com/i5yl8ad 密码:6666 家目录那个隐藏文件里面放着几个临时密码，防止手机丢了，可以自行在里面加几个密码，一次有效， 参考：https://www.jianshu.com/p/9226b5d006bb 12、pam模块学习 以pam_limits模块为例 先man看帮助 ​ 可以看到，不管哪个用户，哪怕root都受到此限制的影响，且默认情况下，限制文件未/etc/security/limits.conf及/etc/security/limits.conf.d/*.conf 使用limit -a查看当前所有资源限制情况 默认文件打开数太小，不够，生产中必须修改，ubuntu18.04现在默认都改大了，如下： 关于fork炸弹的避免措施其一就是显示每个用户的进程数,比如 ulimit -n 2000只会临时生效，建议写文件 13、自签证书和CA生成 查看证书到期时间： ","link":"http://quansen88.cn/jia-mi-gpg-jia-mi-ssh-san-chong-zhuan-fa-opensslpam/"},{"title":"ntp和chronyd 时间同步服务","content":"ntp和chronyd 立即同步时间的坏处，影响某些计划任务执行 一、立即同步时间 方法一： 方法二：重启ntp服务 方法三：重启chrony服务 二、查看ntp和chrony状态 三、ntp做服务端的设置 四、chrony服务端配置 设置项比ntp多 五、自动同步时间两种方式 1、ntpdate ntp.aliyun.com写入计划任务，每小时同步一次 2、所有服务器chrony都开启，其中一台做时间服务器，其他服务器的server都指向它 六、设置时区 ","link":"http://quansen88.cn/20190905ntp-he-chronyd-shi-jian-tong-bu-fu-wu/"},{"title":"编译安装httpd2.4.25并编写systemd脚本","content":"编译安装httpd2.4.25并编写systemd脚本 一、官方的httpd安装脚本 二、httpd的systemd文件 参考：http://www.jinbuguo.com/systemd/systemd.kill.html 分为3部分：[Unit]、[Service]和[Install] 三、一键安装脚本 参考：https://blog.51cto.com/14012942/2427694 四、最终自己写的system文件 效果： ","link":"http://quansen88.cn/20190904-bian-yi-an-zhuang-httpd2425-bing-bian-xie-systemd-jiao-ben/"},{"title":"tcp_wrapper过滤","content":"tcp_wrapper过滤 1.1 wrap简介 wrap工作在内核空间和应用程序中间的库层次中。在内核接受到数据包准备传送到用户空间时都会经过库层次，对于部分（只是部分）应用程序会在经过库层次时会被wrap库文件阻挡下来检查一番，如果允许通过则交给应用程序。 1.2 查看是否支持wrapper wrap只会检查tcp数据包，所以称为tcpwrapper。但还不是检查所有类型的tcp数据包，例如httpd就不支持。是否支持，可以通过查看应用程序是否依赖于libwrap.so库文件。(路径/lib64/libwrap.so) 说明sshd和vsftpd都支持wrap机制，而apache的httpd不支持。 当然上面grep不出结果只能说明不支持这样的动态链接的方式，有些应用程序可能静态编译进程序中了，如旧版本的rpc应用程序portmap。 是否将wrap功能静态编译到应用程序中，可以通过以下方式查看。 如果筛选出的结果中有hosts_access或者/etc/hosts.allow和/etc/hosts.deny这两个文件，则说明是支持的。后两个文件正是wrap访问控制的文件。 要注意的是，如果超级守护进程xinetd被wrap控制了，则其下的瞬时守护进程都受wrap控制。 1.3 配置文件格式 hosts.allow和hosts.deny两个文件的语法格式是一样的，如下： daemon_list: client_list [:options] 【&quot;daemon_list:&quot;的表示方法】：程序名必须是which查出来同名的名称，例如此处的in.telnetd 最后一项daemon@host指定连接IP地址，针对多个IP的情况。如本机有192.168.100.8和172.16.100.1两个地址，但是只想控制从其中一个ip连接的vsftpd服务，可以写&quot;vsftpd@192.168.100.8:&quot;。 【&quot;client_list&quot;的表示方法】 ALL表示所有主机；LOCAL表示和主机在同一网段的主机；(UN)KNOWN表示DNS是否可以解析成功的；PARANOID表示正解反解不匹配的；EXCEPT表示“除了”。 它们的语法可以man hosts_access。 tcpwrapper的检查顺序：hosts.allow --&gt; hosts.deny --&gt; 允许(默认规则) 例如sshd仅允许172.16网段主机访问。 telnet服务不允许172.16网段访问但允许172.16.100.200访问。有几种表达方式： 表达方式一： 表达方式二： 此法不能写入hosts.allow：&quot;in.telnetd: 172.16.100.200 EXCEPT 172.16.&quot; 表达方式三： EXCEPT的最形象描述是“在其前面的范围内挖一个洞，在洞范围内的都不匹配”。所以hosts.allow中，ALL内有一个172.16的洞是不被allow的，在172.16中又有小洞172.16.100.200是被排除在172.16洞外的，所以172.16.100.200是被allow的。 注意：被EXCEPT匹配到的表示不经过此条规则的检查，而不是反意。例如在allows中指明一个EXCEPT，当有except中的主机被匹配到，表示的不是该主机被拒绝。而是跳过allow检测进入deny的检测。 【:options的表达方式】 ALLOW和DENY可以分别写入deny文件和allow文件，表示在allow文件中拒绝在deny文件中接受。如allow文件中： spawn表示启动某程序的意思(/etc/inittab中的respawn表示重启指定程序)。例如启动一个echo程序。 ","link":"http://quansen88.cn/20190904tcp_wrapper-guo-lu/"},{"title":"inotify+rsync","content":"inotify+rsync ​ 之前公司多台web服务器在拉代码时，是在web1上拉好代码，rsync加入定时任务，每5分钟同步一次代码到其他web机器上，但定时任务的同步时间粒度并不能达到实时同步的要求，有时候开发嫌慢。那么就可以考虑通过rsync+inotify实现实时同步 ​ inotify实现工具有几款：inotify本身、sersync、lsyncd。其中sersync是金山的周洋开发的工具，克服了inotify的缺陷，且提供了几个插件作为可选工具。此处先介绍inotify的用法以及它的缺陷，通过其缺陷引出sersync，并介绍其用法。 一、安装inotify-tools ​ 请确保内核版本高于2.6.13，且在/proc/sys/fs/inotify目录下有以下三项，这表示系统支持inotify监控，关于这3项的意义，下文会简单解释。 ​ 安装就从epel源安装即可 ​ inotify-tools工具只提供了两个命令 ​ 其中inotifywait命令用于等待文件发生变化，所以可以可以实现监控(watch)的功能，该命令是inotify的核心命令。inotifywatch用于收集文件系统的统计数据，例如发生了多少次inotify事件，某文件被访问了多少次等等，一般用不上. ​ 以下是inotify相关的内核参数 二、inotifywait命令以及事件分析 inotifywait命令的选项： inotifywait -e可监控的事件： 三、玩一下inotifywait 1、首先创建一个目录，并使用inotifywait进行前台监控 2、新开终端，进入目录 没有触发任何事件 3、创建文件a.txt，触发了如下事件 /wang/ CREATE a.log /wang/ OPEN a.log /wang/ ATTRIB a.log /wang/ CLOSE_WRITE,CLOSE a.log 4、创建目录,触发实践 /wang/ CREATE,ISDIR b 5、ls命令，触发如下事件 /wang/ OPEN,ISDIR /wang/ CLOSE_NOWRITE,CLOSE,ISDIR 6、修改文件属性 /wang/ ATTRIB a.log 7、cat查看文件，触发open、access、close_nowrite和close事件 8、向文件中追加或写入或清除数据，触发open、modify、close_write和close事件 9、vim打开文件并修改文件，中间涉及到临时文件，所以有非常多的事件 10、向目录中拷入一个文件，触发create、open、modify和close_write、close事件。其实和新建文件基本类似 11、删除一个文件，触发delete事件 综合以上考虑，建议对监控对象的close_write、moved_to、moved_from、delete和isdir(主要是create,isdir，但无法定义这两个事件的整体，所以仅监控isdir)事件定义对应的操作，因为它们互不重复。如有需要，可以将它们分开定义，再添加需要监控的其他事件。 大佬推荐写法 四、不足： 1、会消耗一部分CPU资源，在测试的时候明显能感觉到 2、日志量挺大 ","link":"http://quansen88.cn/20190903inotifyrsync/"},{"title":"加密和安全（ssh等）","content":"加密和安全 selinux 1、ssh非交互生成密钥 2、ssh -X 支持x11转发，比如某些图形化东西，比如xclock 3、xstart xshell的工具，可以连接虚拟机的图形化，比如桌面，firefox，xclock等，具体百度 用xstart打开centos7图形化界面 xmanager 打开centos7图形化窗口 4、xmanager 自行百度 5、ssh各种文件分布 sshd_config中文手册 6、一键shell脚本 7、ssh-agent 管理密钥登陆还要手动输密码的问题 8、scp自动应答 9、ssh-copy-id自动应答脚本 10、ssh连接速度慢的几个原因和解决办法 11、ssh安全隧道一（本地端口转发） 12、pssh批量管理 **13、pscp.pssh命令 ** pscp.pssh功能是将本地文件批量复制到远程主机 14、pslurp将远端文件复制到本地 15、SSH端口本地转发 16、SSH做跳板机 现在就可以通过172.18.144.228的2222端口连接到192.168.38.155:22了 缺点：中间机器172.18.146.117使用的22端口 17、SSH端口远程转发(有点像VPN，在家里连自己公网服务器的指定端口，就链接到公司内部网络了) 将远程端口的数据转发到本地 但这条命令只是这样还不够，还达不到目的。会发现33333端口监听在127.0.0.1上，而不是0.0.0.0上，此处需要： 然后就监听在所有地址上了 然后连接67.230.174.208:33333 理论上是可以的，我这里卡住了,明天高 今天第二天，搞了个香港的服务器试试： 首先lanserver是本地的一个虚拟机，IP：172.18.146.224 testbox是本地另一个虚拟机，IP：172.18.146.230 香港服务器IP为47.75.165.238 在lanserver上操作 输入香港服务器密码，此时香港服务器已经监听12345端口了 此时连接香港服务器的12345端口，会将流量转发到本地的172.18.146.230:22（testbox）上，直接输入172.18.146.230（testbox）服务器密码即可 18、ssh安全隧道(三)：动态端口转发(SOCKS代理) 有点像科学上网的意思 首先lanserver是本地的一个虚拟机，IP：172.18.146.224 testbox是本地另一个虚拟机，IP：172.18.146.230 香港服务器IP为47.75.165.238 在lanserver上操作 执行完上面的命令，lanserver将在本地开启SOCKS4或SOCKS5服务来监听2222端口。只要客户端程序工具(隐含了使用的应用层协议类型)将其自身的代理设置为lanserver:2222，则该程序所有产生的数据都将转发到lanserver:2222，再由lanserver:2222将数据通过隧道转发给香港服务器，最后由lanserver和互联网或lanserver上对应客户端工具的应用层协议的端口进行通信。 现在设置浏览器代理为172.18.146.224:2222（lanserver）然后访问google试试 19、只在在香港服务器上配置，实现科学上网（失败了成功了） 经过不懈努力，终于成功了，不能访问google的原因是DNS问题，国内DNS被污染了，需要改个小东西 参考：https://blog.csdn.net/mergerly/article/details/50908128 上面命令意思：在本地监听1723端口，将1723端口的请求转发给本机127.0.0.1:22端口 应该是成功了，但是不能访问google 总结：科学上网的步骤： 1、香港服务器开启转发：ssh -fND 127.0.0.1 -g 2、火狐浏览器设置代理，SOcket代理 3、火狐浏览器打开about:config将network.proxy.socks_remote_dns改为true，打开远程DNS功能 20、sshd_config 21、ssh_config配置 22、curl命令的选项--socks5 23、ssh服务的最佳实战 24、脚本：每天晚上对登陆日志分析，将失败IP大于5的放到防火墙 25、rsync同步文件 --exclude排除原则 --exclude选项指定排除规则，排除那些不需要传输的文件 ​ 上例中只排除了anaconda目录中的log文件，但是audit目录中的log文件是正常传输的。 ​ 注意，一个&quot;--exclude&quot;只能指定一条规则，要指定多条排除规则，需要使用多个&quot;--exclude&quot;选项，或者将排除规则写入到文件中，然后使用&quot;--exclude-from&quot;选项读取该规则文件。 ​ 另外，除了&quot;--exclude&quot;排除规则，还有&quot;--include&quot;包含规则，顾名思义，它就是筛选出要进行传输的文件，所以include规则也称为传输规则。它的使用方法和&quot;--exclude&quot;一样。如果一个文件即能匹配排除规则，又能匹配包含规则，则先匹配到的立即生效，生效后就不再进行任何匹配。 ​ 最后，关于规则，最重要的一点是它的作用时间。**当发送端敲出rsync命令后，rsync将立即扫描命令行中给定的文件和目录(扫描过程中还会按照目录进行排序，将同一个目录的文件放在相邻的位置)，这称为拷贝树(copy tree)，扫描完成后将待传输的文件或目录记录到文件列表中，然后将文件列表传输给接收端。而筛选规则的作用时刻是在扫描拷贝树时，所以会根据规则来匹配并决定文件是否记录到文件列表中(严格地说是会记录到文件列表中的，只不过排除的文件会被标记为hide隐藏起来)，只有记录到了文件列表中的文件或目录才是真正需要传输的内容。换句话说，筛选规则的生效时间在rsync整个同步过程中是非常靠前的，它会影响很多选项的操作对象，最典型的如&quot;--delete&quot;。**也许，你看完这一整篇文章都没感觉到这一点的重要性，但如果你阅读rsync的man文档或者学习rsync的原理，你一定会深有体会。 ​ 实际上，排除规则和包含规则都只是&quot;--filter&quot;筛选规则的两种特殊规则。&quot;--filter&quot;比较复杂，它有自己的规则语法和匹配模式，由于篇幅有限，以及考虑到本文的难度定位，&quot;--filter&quot;规则不便在此多做解释，仅简单说明下规则类，帮助理解下文的&quot;--delete&quot;。 ​ 以下是rsync中的规则种类，不解之处请结合下文的&quot;--delete&quot;分析： ​ (1).exclude规则：即排除规则，只作用于发送端，被排除的文件不会进入文件列表(实际上是加上隐藏规则进行隐藏)。 ​ (2).include规则：即包含规则，也称为传输规则，只作用于发送端，被包含的文件将明确记录到文件列表中。 ​ (3).hide规则：即隐藏规则，只作用于发送端，隐藏后的文件对于接收端来说是看不见的，也就是说接收端会认为它不存在于源端。 ​ (4).show规则：即显示规则，只作用于发送端，是隐藏规则的反向规则。 ​ (5).protect规则：即保护规则，该规则只作用于接收端，被保护的文件不会被删除掉。 ​ (6).risk规则：即取消保护规则。是protect的反向规则。 ​ 除此之外，还有一种规则是&quot;clear规则&quot;，作用是删除include/exclude规则列表。 26、rsync如何一次写对exclude规则 ​ 很多人写不来规则，总发现写出来后没有生效，要写成功一次规则得要不断地进行调试、调试、调试，令人无比心烦。 ​ 其实很多工具的规则写法是类似的，比如tar也一样。规则写好后不生效的原因一般有两种：绝对路径和相对路径的问题、尾随斜线的问题。 ​ 一般来说，操作的路径是绝对路径，那么规则里必须也写绝对路径，而且必须写完整的绝对路径。操作的路径是相对路径，那么规则里必须写相对路径，从哪里开始相对可能和工具有关。比如要操作路径&quot;/abc/def&quot;，想要筛选def下的所有txt文件，必须写成&quot;/abc/def/*.txt&quot;，如果操作路径是&quot;abc/def&quot;，那么要筛选这个目录下的所有txt文件，可能需要写成&quot;abc/def/*.txt&quot;，也有可能写成&quot;*.txt&quot;，甚至写成&quot;def/*.txt&quot;，写成哪种形式依赖于这个软件如何解析相对路径。 ​ 对于rsync来说，要更复杂一些，因为除了bash的相对路径外，它自身还提供了一个相对路径的解析规则，而且尾随斜线也会影响规则的写法。这就是为什么写rsync规则非常麻烦的原因。 ​ 我这里提供一个判断规则写法的方式，纯属我个人的经验总结：使用&quot;-n&quot;选项是dry run模式，也就是只测试不传输，&quot;-i&quot;选项是输出要传输文件的路径。&quot;-i&quot;只是一个便捷性选项，可以替换成其它选项来自定义输出格式，有时候通过这些信息来做一些判断是非常有用的，具体的可以翻man手册。 这里已经显示了传输文件的路径&quot;anaconda/*&quot;，也就是说包括了目录anaconda，且是相对路径的。所以要写规则时，需要加上这个anaconda路径，比如下面的排除规则。 如果上面的传输路径anaconda加上尾随斜线，再看-i的输出路径信息，发现已经改变了： 所以这时的排除规则中不应该包含anaconda目录前缀： 27、rsync的--delete解释 使用&quot;--delete&quot;选项，这时会将目标端多出的文件给删除掉，然后进行同步。 ​ 这样的行为实现了远程删除的功能，对于作用于本地的rsync，也就实现了rm的本地删除功能。而且，如果使用空目录作为源目录，则它的作用是清空目录上的整个目录。 ​ 如果将&quot;--delete&quot;选项和&quot;--exclude&quot;选项一起使用，则被排除的文件不会被删除。例如： ​ 结果发现只删除了&quot;anaconda/fstab&quot;文件，被&quot;--exclude&quot;规则匹配的anaconda/*.log文件都没有被删除。也就是网上所说的言论：exclude排除的文件不会被删除。 ​ 结论是没错的，但我想很多人不知道为何会如此，也可能从来没想过为何会如此，所以我简单地做个说明。 ​ **在发送端将文件列表发送给接收端后，接收端的generator(要是不知道，你认为是某个就好了)进程会扫描每个文件列表中的信息，然后对列表中的每个信息条目都计算数据块校验码，最后将数据库校验码发给发送端，发送端通过校验码来匹配哪些数据块是需要传输的，这样就实现了增量传输的功能——只传输改变的部分，不会传输整个文件。而delete删除的时间点是generator进程处理每个文件列表时、生成校验码之前进行的，**先将目标上存在但源上不存在的多余文件删除，这样就无需为多余的文件生成校验码。 ​ 所以，delete动作是比&quot;--exclude&quot;规则更晚执行的，被&quot;--exclude&quot;规则排除的文件不会进入文件列表中，在执行了delete时会认为该文件不存在于源端，从而导致目标端将这些文件删除。但这是想当然的，尽管理论上确实是这样的，但是rsync为了防止众多误删除情况，提供了两种规则：保护规则(protect)和取消保护规则(risk)。默认情况下，&quot;--delete&quot;和&quot;--exclude&quot;一起使用时，虽然发送端的exclude规则将文件标记为隐藏，使得接收端认为这些被排除文件在源端不存在，但rsync会将这些隐藏文件标记为保护文件，使得它们不受delete行为的影响，这样delete就删除不了这些被排除的文件。如果还是想要强行删除被exclude排除的文件，可以使用&quot;--delete-excluded&quot;选项强制取消保护，这样即使被排除的文件也会被删除。 ​ 那么现在，是否理解了网上的言论&quot;exclude排除的文件不会被删除&quot;？ ​ 除了&quot;--delete&quot;，相关的选项还有&quot;--delete-before&quot;、&quot;--delete-during&quot;、&quot;--delete-delay&quot;等，它们都隐含了&quot;--delete&quot;选项，它们分别表示generator处理各个文件列表之前一次性全部删除待删除文件、处理文件列表时处理到哪个文件列表就删除该文件列表中的待删除文件，以及同步完所有数据后一次性删除所有待删除文件。 ​ 举个例子，假如源端要传输3个目录a、b、c，在目标端a目录中有a1、a2、a3共3个文件需要被删除，b目录中有b1、b2、b3需要删除，同理c目录也一样c1、c2、c3需要被删除。 ​ 如果是&quot;--delete-before&quot;，则在目标端rsync刚启动时，就会把a1-a3、b1-b3、c1-c3一次性删除，然后才会处理文件列表中的a目录，处理完a后处理b，再是c。 如果是&quot;--delete-during&quot;，则在目标端rsync刚启动时，先处理文件列表中的a目录，处理a目录时发现此目录中有待删除文件a1-a3，顺手就删除它们，然后完成a目录的相关操作，再处理文件列表中的b目录，发现也有待删除文件b1-b3，顺手删除它们，同理c1-c3也如此。 ​ 如果是&quot;--delete-delay&quot;，则同步完文件列表中的a/b/c目录后，最后一次性删除a1-a3、b1-b3、c1-c3。 ​ 其实&quot;--delete&quot;选项大多数情况下默认采用的就是&quot;--delete-during&quot;。 28、dropbear使用 和ssh一类的 29、aide（linux的入侵检测软件） ","link":"http://quansen88.cn/20190902-jia-mi-he-an-quan-ssh-deng/"},{"title":"谷歌身份验证器使用","content":"谷歌身份验证器使用 参考：https://www.jianshu.com/p/9226b5d006bb ubuntu18.04 1、谷歌身份验证器apk https://www.lanzous.com/i5yl8ad 密码:6666 备用下载：https://www.wandoujia.com/apps/32913 2、ubuntu安装libpam-google-authenticator 3、设置Google Authenticator 会出来一个连接，然后很大的二维码 二维码不管，网址在浏览器打开，谷歌身份验证器扫一下 然后下面的问题全部yes回答即可 4、接下来将Google Authenticator验证配置到SSH登录中 编辑/etc/pam.d/sshd文件，添加下行保存 编辑/etc/ssh/sshd_config找到下行 5、用另一台linux登陆 注意事项1：刚才用root用户执行的google-authenticator，所以只有root可以登陆；其他用户现在也必须执行google-authenticator并扫码，才可以登陆 注意事项2：不能直接用xshell登陆,如果要用xshell登陆，要建立会话，并设置登陆方式，如下图;只能从linux登陆或者gitbash那种方式可以登陆 CentOS7 如上面所示安装apk 参考：https://blog.csdn.net/ldyboy1314/article/details/82787766 CentOS7一定要注意，关闭selinux和firewalld，一定一定,时间也校准一下 1、安装epel源 2、安装Qrencode等 3、编译安装 4、拷贝google的身份验证器pam模块到系统下 5、配置sshd的pam认证，写在auth include password-auth 基于密码认证的上面一行,先基于google验证码认证 6、修改SSH服务配置/etc/ssh/sshd_config 7、设置Google Authenticator 然后就和上面ubuntu设置一样了：复制链接到网页，app扫码，以下问题全部yes 8、登陆也同上面ubuntu一样，试试 关于上面的紧急验证码： 可以自行添加数字到里面，一样可以用，一次性的，用完就会从文件中删掉 ","link":"http://quansen88.cn/20190902-gu-ge-shen-fen-yan-zheng-qi-shi-yong/"},{"title":"openssl speed和openssl rand","content":"openssl speed和openssl rand openssl speed 测试加密算法的性能。 支持的算法有： 不过为什么没有base64算法呢？ 测试速度好几秒一个指标，很慢。如果不指定参数将测试所有支持的算法，所以会花很久时间，我的虚拟机上花了十多分钟才测试完所有的算法性能。 例如测试下，dsa512、rsa512和rsa2048加密速度如何。 在10秒时间内，rsa512的私钥处理156944单位，而rsa2048仅处理11763单位，慢了13倍。 再看签名性能，dsa算法只支持签名不支持加密，而rsa支持加密也支持签名。从上面的结果中可以看到rsa512的签名速度为每秒15710.1，而dsa512的速度为11412.1，速度相差不大。 openssl rand 生成随机数 可以看到，不指定-base64或-hex时生成的随机数是乱码随机数（其实是2进制），且没有\\n符号。 ","link":"http://quansen88.cn/20190901openssl-speed-he-openssl-rand/"},{"title":"openssl rsautl和openssl pkeyutl(文件的非对称加密)","content":"20190901openssl rsautl和openssl pkeyutl(文件的非对称加密) openssl rsautl和openssl pkeyutl(文件的非对称加密 rsautl是rsa的工具，相当于rsa、dgst的部分功能集合，可用于生成数字签名、验证数字签名、加密和解密文件。 pkeyutl是非对称加密的通用工具，大体上和rsautl的用法差不多，所以此处只解释rsautl。 rsautl命令的用法和rsa、dgst不太一样。首先，它的前提是已经有非对称密钥，所有的命令操作都用到公钥或私钥来处理；再者，该命令使用-in选项来指定输入文件，而不像dgst一样可以把输入文件放在命令的结尾；最后，该命令使用的密钥文件、签名文件、证书文件都通过-inkey选项指定，再通过各功能的选项搭配来实现对应的功能。 注意rsautl和pkeyutl的缺陷是默认只能对短小的文件进行操作，否则将报类似如下的错误信息。font&gt; 因为这两个工具签名和验证签名的功能和openssl dgst命令差不多，且自身又有缺陷，所以就不举例说明。此处仅给出对短小文件的非对称加密和解密示例。 1、使用公钥加密b.txt文件，注意待加密文件b.txt必须是短小文件，且不建议使用-hexdump输出，否则解密时可能超出文件的长度。 查看非对称加密后的文件b_crypt.txt。 2、使用私钥解密b_crypt.txt文件 ","link":"http://quansen88.cn/openssl-rsautl-he-openssl-pkeyutlwen-jian-de-fei-dui-cheng-jia-mi/"},{"title":"openssl req（生成证书请求和自建CA）2","content":"openssl req（生成证书请求和自建CA） 伪命令req大致有3个功能：生成证书请求文件、验证证书请求文件和创建根CA。由于openssl req命令选项较多，所以先各举几个例子，再集中给出openssl req的选项说明。若已熟悉openssl req和证书请求相关知识，可直接跳至后文查看openssl req选项整理，若不熟悉，建议从前向后一步一步阅读。 首先说明下生成证书请求需要什么：申请者需要将自己的信息及其公钥放入证书请求中。但在实际操作过程中，所需要提供的是私钥而非公钥，因为它会自动从私钥中提取公钥。另外，还需要将提供的数据进行数字签名(使用单向加密)，保证该证书请求文件的完整性和一致性，防止他人盗取后进行篡改，例如黑客将为www.baidu.com所申请的证书请求文件中的公司名改成对方的公司名称，如果能够篡改成功，则签署该证书请求时，所颁发的证书信息中将变成他人信息。 所以第一步就是先创建出私钥pri_key.pem。其实私钥文件是非必需的，因为openssl req在需要它的时候会自动创建在特定的路径下，此处为了举例说明，所以创建它。 ** 1、根据私钥pri_key.pem生成一个新的证书请求文件。其中&quot;-new&quot;表示新生成一个新的证书请求文件，&quot;-key&quot;指定私钥文件，&quot;-out&quot;指定输出文件，此处输出文件即为证书请求文件 在敲下回车键后，默认会进入交互模式让你提供你个人的信息，需要注意的是，如果某些信息不想填可以选择使用默认值，也可以选择留空不填，直接回车将选择使用默认值，输入点&quot;.&quot;将表示该信息项留空。但某些项是必填项，否则未来证书签署时将失败。如&quot;Common Name&quot;，它表示的是为哪个域名、子域名或哪个主机申请证书，未来证书请求被签署后将只能应用于&quot;Common Name&quot;所指定的地址。具体哪些必填项还需要看所使用的配置文件(默认的配置文件为/etc/pki/tls/openssl.cnf)中的定义，此处暂且不讨论配置相关内容，仅提供Common Name即可。 除了&quot;-new&quot;选项，使用&quot;-newkey&quot;选项也能创建证书请求文件，此处暂不举例说明&quot;-newkey&quot;的用法，后文会有示例。 2、查看证书请求文件内容。 现在已经生成了一个新的证书请求文件req1.csr。查看下该证书请求文件的内容 更具体的可以使用openssl req命令查看。命令如下，其中&quot;-in&quot;选项指定的是证书请求文件。 查看请求文件时，可以结合其他几个选项输出特定的内容。&quot;-text&quot;选项表示以文本格式输出证书请求文件的内容 将&quot;-text&quot;和&quot;-noout&quot;结合使用，则只输出证书请求的文件头部分。 还可以只输出subject部分的内容。 也可以使用&quot;-pubkey&quot;输出证书请求文件中的公钥内容。如果从申请证书请求时所提供的私钥中提取出公钥，这两段公钥的内容是完全一致的。 3、指定证书请求文件中的签名算法。 注意到证书请求文件的头部分有一项是&quot;Signature Algorithm&quot;，它表示使用的是哪种数字签名算法。默认使用的是sha1，还支持md5、sha512等，更多可支持的签名算法见&quot;openssl dgst --help&quot;中所列出内容。例如此处指定md5算法。 4、验证请求文件的数字签名,这样可以验证出证书请求文件是否被篡改过。下面的命令中&quot;-verify&quot;选项表示验证证书请求文件的数字签名 5、自签署证书，可用于自建根CA时 由于openssl req命令的主要功能是创建和管理证书请求文件，所以没有提供对证书文件的管理能力，暂时也就只能通过cat来查看证书文件CA1.crt了。 实际上，&quot;-x509&quot;选项和&quot;-new&quot;或&quot;-newkey&quot;配合使用时，可以不指定证书请求文件，它在自签署过程中将在内存中自动创建证书请求文件，当然，既然要创建证书请求文件，就需要人为输入申请者的信息了。例如 其实，使用&quot;-x509&quot;选项后，&quot;-new&quot;或&quot;-newkey&quot;将表示创建一个证书文件而不是一个证书请求文件。 6、让openssl req自动创建所需的私钥文件 在前面的所有例子中，在需要私钥的时候都明确使用了&quot;-key&quot;选项提供私钥。其实如果不提供，openssl req会在任何需要私钥的地方自动创建私钥，并保存在特定的位置，默认的保存位置为当前目录，文件名为privkey.pem，具体保存的位置和文件名由配置文件(默认为/etc/pki/tls/openssl.cnf)决定，此处不讨论该文件。当然，openssl req命令的&quot;-keyout&quot;选项可以指定私钥保存位置。 但是，openssl req在自动创建私钥时，将总是加密该私钥文件，并提示输入加密的密码。可以使用&quot;-nodes&quot;选项禁止加密私钥文件。 指定自动创建私钥时，私钥文件的保存位置和文件名。使用&quot;-keyout&quot;选项。 使用&quot;-newkey&quot;选项。 &quot;-newkey&quot;选项和&quot;-new&quot;选项类似，只不过&quot;-newkey&quot;选项可以直接指定私钥的算法和长度，所以它主要用在openssl req自动创建私钥时。 它的使用格式为&quot;-newkey arg&quot;，其中arg的格式为&quot;rsa:numbits&quot;，rsa表示创建rsa私钥，numbits表示私钥的长度，如果不给定长度(即&quot;-newkey rsa&quot;)则默认从配置文件中读取长度值。其实不止支持rsa私钥，只不过现在基本都是用rsa私钥，所以默认就使用rsa。 通过上面一系类的举例说明后，想必openssl req的各基本选项的用法都通了。从上面的示例中也发现了，openssl req经常会依赖于配置文件(默认为/etc/pki/tls/openssl.cnf)中的值。所以，先将openssl req的命令用法总结下，再简单说明下配置文件中和req有关的内容。 以下是默认的配置文件格式及值。关于配置文件的详细分析见&quot;配置文件&quot;部分。 ","link":"http://quansen88.cn/20190901openssl-reqsheng-cheng-zheng-shu-qing-qiu-he-zi-jian-ca2/"},{"title":"openssl rsapkey","content":"openssl rsa/pkey openssl rsa和openssl pkey分别是RSA密钥的处理工具和通用非对称密钥处理工具，它们用法基本一致，所以只举例说明openssl rsa。 它们的用法很简单，基本上就是输入和输出私钥或公钥的作用。 1、创建一个rsa私钥文件genrsa.pri，然后从中提取rsa公钥到rsa.pub文件中。 2、创建一个加密的rsa私钥文件genrsaK.pri，然后从此文件输出公钥至文件rsaK.pub。 此时将提示输入密码才能读取该私钥文件 可以使用&quot;-passin&quot;传递解密的密码。 3、移除私钥文件或公钥文件的密码。只需直接输出到新文件即可。以已加密的私钥文件genrsaK.pri为例 4、check检测私钥文件的一致性，查看私钥文件被修改过 现在随便修改下私钥文件，再检测。 ","link":"http://quansen88.cn/20190901openssl-reqsheng-cheng-zheng-shu-qing-qiu-he-zi-jian-ca/"},{"title":"openssl passwd","content":"openssl passwd 该伪命令用于生成加密的密码。 直接man passwd会得到修改用户密码的passwd命令帮助，而不是openssl passwd的帮助，所以man sslpasswd。 使用openssl passwd支持3种加密算法方式：不指定算法时，默认使用-crypt 在命令行中直接输入要加密的密码password或者使用-salt时，将不需要交互确认，否则会交互确认密码 由上面的测试可知，使用默认的-crypt加密的密码是随机的。但是加入盐后，如果密码一样，盐一样，那么加密结果一样。 同时也看到了-crypt加密算法只取盐的前两位。 如果盐的前两位和密码任意一个不一样，加密结果都不一样。 注意，默认的-crypt只取盐的前两位字符，所以只要盐的前两位一样，即使第三位不同，结果也是一样的。 测试下MD5格式的加密算法。 可见，结果比-crypt的算法更长了，且不加盐时，密码生成是随机的。 可以看出，加了盐虽然复杂度增加了，但是也受到了&quot;盐相同，密码相同，则加密结果相同&quot;的限制。另外，盐的长度也不再限于2位了。 再为apache或nginx生成访问网页时身份验证的密码，即basic authentication验证方式的密码。 同样，加了盐就受到&quot;盐相同，密码相同则加密结果相同&quot;的限制。 关于openssl passwd文件，它生成的密码可以直接复制到/etc/shadow文件中，但openssl passwd因为不支持sha512，所以密码强度不够。如果要生成sha512的密码，可以使用grub-crypt生成，它是一个python脚本，只不过很不幸CentOS 7只有grub2，grub-crypt命令已经没有了。 可以使用语句简单地代替grub-crypt。 grub-crypt和上述python语句都是交互式的。如果要非交互式，稍稍修改下python语句： ","link":"http://quansen88.cn/20190901openssl-passwd/"},{"title":"openssl genrsa","content":"openssl genrsa genrsa用于生成RSA私钥，不会生成公钥，因为公钥提取自私钥,如果需要生成公钥或查看公钥，可以使用openssl rsa命令 man genrsa查看用法 1、生成512位的rsa密钥，显示到屏幕 2、生成512位的rsa密钥，输出到genrsa.txt 3、加密私钥文件，密码123456 ","link":"http://quansen88.cn/20190901openssl-genrsa/"},{"title":"openssl enc对称加密","content":"openssl enc对称加密 对称加密工具。了解对称加密的原理后就很简单了，原理部分见下文。 支持的单向加密算法有： 支持的对称加密算法有： 在给出openssl enc命令用法示例之前，先解释下对称加密和解密的原理和过程。 对称加解密时，它们使用的密码是完全相同的，例如&quot;123456&quot;，但这是密码，且是明文密码，非常不安全，所以应该对此简单密码进行复杂化。最直接的方法是使用单向加密计算出明文密码的hash值，单向加密后新生成的密码已经比较安全(称之为密钥比较好)，可以作为对称加密时的对称密钥。另外，由于同一单向加密算法对相同明文密码的计算结果是完全一致的，这样解密时使用相同的单向加密算法就能计算出完全相同的密钥，也就是解密时的对称密钥。如果想要更安全，还可以在对称加密后对加密文件进行重新编码，如使用&quot;base64&quot;、二进制或hex编码方式进行编码，但对应的在解密前就需要先解码，解码后才能解密。 所以，将对称加、解密的机制简单概括如下： 对称加密机制：根据指定的单向加密算法，对输入的明文密码进行单向加密(默认是md5)，得到固定长度的加密密钥，即对称密钥，再根据指定的对称加密算法，使用对称密钥加密文件，最后重新编码加密后的文件。即单向加密明文密码结果作为对称密钥、使用对称密钥加密文件、对文件重新编码。 对称解密机制：先解码文件，再根据单向加密算法对解密时输入的明文密码计算得到对称密钥，依此对称密钥对称解密解码后的文件。 **因此，解密过程中使用的解码方式、单向加密和对称加密算法都必须一致，且输入的密码必须是正确密码。**但需要注意的一点是，解密时可以不指定salt，因为加密时使用的salt会记录下来，解密时可以读取该salt。 1、首先测试openssl enc的编码功能。由于未指定密码选项&quot;-k&quot;或&quot;-pass&quot;，所以仅仅只进行编码而不进行加密，因此也不会提示输入密码 再以base64格式进行解码。 2、测试使用des3对称加密算法加密test.txt文件 解密文件test.1 3、加密时带上点盐salt。其实不写时默认就已经加入了，只不过是加入随机盐值。使用-S可以指定明确要使用的盐的值。但是盐的值只能是16进制范围内字符的组合，即&quot;0-9a-fA-F&quot;的任意一个或多个组合 解密。解密时不用指定salt值，即使指定了也不会影响解密结果 4、在测试下&quot;-p&quot;和&quot;-P&quot;选项的输出功能。小写字母p不仅输出密钥算法结果，还输出加解密的内容，而大写字母P则只输出密钥算法结果 加密时的情况。 其中key就是单向加密明文密码后得到的对称密钥，iv是密码运算时使用的向量值。 再看解密时的情况，此处加上了salt。 若解密时不指定salt，或者随意指定salt，结果如下 可见，解密时，只要指定和加密时相同编码格式和单向加密算法，密钥的结果就是一样的，且解密时明确指定salt是无意义的，因为它可以读取到加密时使用的salt。 甚至，解密时指定不同的对称加密算法，密钥结果也是一样的。 由此，能推理出对称加密时使用的对称密钥和对称算法是毫无关系的。 ","link":"http://quansen88.cn/20190901openssl-enc-dui-cheng-jia-mi/"},{"title":"openssl dhparam","content":"openssl dhparam openssl dhparam用于生成和管理dh文件。dh(Diffie-Hellman)是著名的密钥交换协议，或称为密钥协商协议，它可以保证通信双方安全地交换密钥。但注意，它不是加密算法，所以不提供加密功能，仅仅只是保护密钥交换的过程。在openvpn中就使用了该交换协议。关于dh算法的整个过程，见下文。 openssl dhparam命令集合了老版本的openssl dh和openssl gendh，后两者可能已经失效了，即使存在也仅表示未来另有用途。 注意，dh协议文件生成速度随长度增长而急剧增长，使用随机数种子可以加快生成速度。 例如：生成1024长度的交换协议文件，其消耗的时间如下：一次比一次块。 但是生成2048位长度的交换协议文件，其消耗时间如下 而使用了64位随机数种子的同样命令如下： openssl命令实现的是各种算法和加密功能，它的cpu的使用率会非常高，再结合dhparam，可以使得openssl dhparam作为一个不错的cpu压力测试工具，并且可以长时间飙高cpu使用率。 DH密钥协商过程： 密钥交换协议(DH)的大概过程是这样的(了解即可，可网上搜索完整详细的过程)： (1).双方协商一个较大的质数并共享，这个质数是种子数。 (2).双方都协商好一个加密生成器(一般是AES)。 (3).双方各自提出另一个质数，这次双方提出的质数是互相保密的。这个质数被认为是私钥(不是非对称加密的私钥)。 (4).双方使用自己的私钥(即各自保密的质数)、加密生成器以及种子数(即共享的质数)派生出一个公钥(由上面的私钥派生而来，不是非对称加密的公钥)。 (5).双方交换派生出的公钥。 (6).接收方使用自己的私钥(各自保密的质数)、种子数(共享的质数)以及接收到的对方公钥计算出共享密钥(session key)。尽管双方的session key是使用对方的公钥以及自己的私钥计算的，但因为使用的算法，能保证双方计算出的session key相同。 (7).这个session key将用于加密后续通信。例如，ssh连接过程中，使用host key对session key进行签名，然后验证指纹来完成主机认证的过程(见https://www.cnblogs.com/f-ck-need-u/p/7129122.html#blog131)。 在此可见，在计算session key过程中，双方使用的公钥、私钥是相反的。但因为DH算法的原因，它能保证双方生成的session key是一致的。而且因为双方在整个过程中是完全平等的，没有任何一方能掌控协商的命脉，再者session key没有在网络上进行传输，使得使用session key做对称加密的数据传输是安全的。 ","link":"http://quansen88.cn/20190901openssl-dhparam/"},{"title":"openssl dgst(生成和验证数字签名)","content":"openssl dgst(生成和验证数字签名) 该伪命令是单向加密工具，用于生成文件的摘要信息，也可以进行数字签名，验证数字签名。 首先要明白的是，数字签名的过程是计算出数字摘要，然后使用私钥对数字摘要进行签名，而摘要是使用md5、sha512等算法计算得出的，理解了这一点，openssl dgst命令的用法就完全掌握了。 支持如下几种单向加密算法，即签名时使用的hash算法。 注意：openssl dgst -md5和openssl md5的作用是一样的，其他单向加密算法也一样，例如openssl dgst -sha等价于openssl sha。 1、随机生成一段摘要信息 2、对/root/OpenArkCompiler-0.2.tar.gz文件生成MD5和sha512摘要信息 3、生成一个私钥genrsa.pri，然后使用该私钥对/root/OpenArkCompiler-0.2.tar.gz文件签名。使用-hex选项，否则默认输出格式为二进制会乱码 如果要验证签名，那么这个生成的签名要保存到一个文件中，且一定不能使用&quot;-hex&quot;选项，否则验证签名必失败。以下分别生成使用和不使用hex格式的签名文件以待验证签名测试 4、验证签名。验证签名的过程实际上是对待验证文件新生成签名，然后与已有签名文件进行比对，如果比对结果相同，则验证通过。所以，在验证签名时不仅要给定待验证的签名文件，也要给定相同的算法，相同的私钥或公钥文件以及待签名文件以生成新签名信息。 以下先测试以私钥来验证数字签名文件。 首先对未使用hex格式的签名文件md5_nohex.sign进行验证。由于生成md5_nohex.sign时使用的是md5算法，所以这里必须也要指定md5算法。 再对使用了hex格式的签名文件md5_hex.sign进行验证，不论在验证时是否使用了hex选项，结果都是验证失败。 再测试使用公钥来验证数字签名。 ","link":"http://quansen88.cn/20190901openssl-dgstsheng-cheng-he-yan-zheng-shu-zi-qian-ming/"},{"title":"openssl ca(签署和自建CA)","content":"openssl ca(签署和自建CA) 自建CA总结： 然后使用该CA给老王颁发证书总结 证书请求文件使用CA的私钥签署之后就是证书，签署之后将证书发给申请者就是颁发证书。在签署时，为了保证证书的完整性和一致性，还应该对签署的证书生成数字摘要，即使用单向加密算法。 在配置文件中指定了签署证书时所需文件的结构，默认openssl.cnf中的结构要求如下 其中目录/etc/pki/CA/{certs,newcerts,private}在安装openssl后就默认存在，所以无需独立创建，但证书的database文件index.txt和序列文件serial必须创建好，且序列号文件中得先给定一个序号，如&quot;01&quot; 创建数据库索引文件和序列文件 创建私钥 另外，要签署证书请求，需要CA自己的私钥文件以及CA自己的证书，先创建好CA的私钥，存放位置为配置文件中private_key所指定的值，默认为/etc/pki/CA/private/cakey.pem。 使用openssl ca自建CA 要提供CA自己的证书，测试环境下CA只能自签署，使用&quot;openssl req -x509&quot;、&quot;openssl x509&quot;和&quot;openssl ca&quot;都可以自签署证书请求文件，此处仅介绍openssl ca命令自身自签署的方法。 先创建CA的证书请求文件，建议使用CA的私钥文件/etc/pki/CA/private/cakey.pem来创建待自签署的证书请求文件，虽非必须，但方便管理。创建请求文件时，其中Country Name、State or Province Name、Organization Name和Common Name默认是必须提供的。 创建CA的证书请求文件 然后使用openssl ca命令自签署该证书请求文件。 如果有两次交互式询问则表示自签署将成功，如果失败，则考虑数据库文件index.txt是否创建、序列号文件serial是否存在且有序号值、私钥文件cakey.pem是否路径正确、创建证书请求文件时是否该提供的没有提供等情况。 自签署成功后，在/etc/pki/CA目录下将生成一系列文件。 其中newcerts目录下的01.pem即为刚才自签署的证书文件，因为它是CA自身的证书，所以根据配置文件中的&quot;certificate=$dir/cacert.pem&quot;项，应该将其放入/etc/pki/CA目录下，且命名为cacert.pem，只有这样以后才能签署其它证书请求。 将自签证书放到/etc/pki/CA/目录下面 至此，自建CA就完成了， 查看下数据库索引文件和序列号文件。 那么，下次签署证书请求时，序列号将是&quot;02&quot;。 自签CA命令总结 以上过程是完全读取默认配置文件创建的，其实很多过程是没有那么严格的，openssl ca命令自身可以指定很多选项覆盖配置文件中的项，但既然提供了默认的配置文件及目录结构，为了方便管理，仍然建议完全采用配置文件中的项。 给老王颁发个证书 1、老王生成自己的私钥 2、老王生成证书请求文件 其中Country Name、State or Province Name、Organization Name和Common Name必须提供，且前三者必须和CA的subject中的对应项完全相同。这些是由配置文件中的匹配策略决定的。 &quot;match&quot;表示openssl ca要签署的证书请求文件中的项要和CA证书中的项匹配，即要相同，&quot;supplied&quot;表示必须要提供的项，&quot;optional&quot;表示可选项，所以可以留空。 3、laowang将请求文件发给CA 4、CA帮忙签 5、签署完成，查看下目录结构 6、其中&quot;02.pem&quot;就是刚才签署成功的证书，将此证书发送给申请者即表示颁发完成。 7、再看下数据库索引文件和序列号文件 给老王颁发证书总结 ","link":"http://quansen88.cn/20190901openssl-caqian-shu-he-zi-jian-ca/"},{"title":"制作一个最小的CentOS6系统","content":"制作一个最小的CentOS6系统 首先要明确一下CentOS6启动的过程 POST -&gt; BootSequence(BIOS) -&gt; Bootloader(MBR) -&gt; Kernel(ramdisk) -&gt; rootfs -&gt; switchroot -&gt; /sbin/init -&gt; (/etc/inittab,/etc/init/*.conf) -&gt; 设置默认运行级别 -&gt; 系统初始化脚本 -&gt;关闭或启动对应级别下的服务 -&gt; 启动终端 1、POST不用管，硬件的事 2、BootSequence，手动选择某个硬盘启动即可 3、Bootloader即stage1.0阶段，使用grub-install生成 stage1.5阶段也用grub-install生成 4、stage2.0阶段即内核文件vmlinuz和ramdisk镜像从源系统复制一份 然后需要grub文件，CentOS6就手动写一份吧，格式如下： 5、复制几个命令，开启也别启动/sbin/init，直接启动/bin/bash行了 脚本：copycmd-拷贝命令及其依赖库 开始搞 一、CentOS6虚拟机加一个硬盘 二、分区挂到临时目录下 swap分区可以不要，刚开始启动不起来，我还以为是缺少swap分区，后来发现，是因为selinux问题，grub.conf里面kernel哪一行加上selinux=0即可 三、生成grubstage1.0-stage2.0文件 四、复制内核文件vmlinuz和ramfs镜像 手写grub.conf,照着/boot/grub/grub.conf 注意：selinux=0不启用selinux，init=/bin/bash表示开机使用/bin/bash，不使用/sbin/init 五、创建目录，复制命令 脚本：copycmd-拷贝命令及其依赖库 切根试试： 顺便复制个网卡驱动 六、关机，新建虚拟机使用该磁盘启动 自定义创建虚拟机 神奇的grub界面： 进去之后，加载网卡，配IP，ping一下别的虚拟机 LFS：构建最小Linux文档：https://lctt.github.io/LFS-BOOK/ ","link":"http://quansen88.cn/20190831-zhi-zuo-yi-ge-zui-xiao-de-centos6-xi-tong/"},{"title":"CentOS删vmlinuz玩","content":"CentOS7删vmlinuz玩 /boot/vmlinuz-xxx应该是属于stage2的内容 一、删ta 二、启动不起来，很好 三、光盘救援模式 参考：https://blog.51cto.com/14012942/2434054 四、修复 方法一：这个文件上次删boot玩过了，重新安装内核可以修复的，直接重装内核即可 参考：https://blog.51cto.com/14012942/2434055 方法二：直接从光盘中拷贝一个算了 ","link":"http://quansen88.cn/20190830centos-shan-vmlinuz-wan/"},{"title":"CentOS7删boot目录玩","content":"CentOS7删boot目录玩 grub2-install 可以恢复stage1-stage2阶段 一、删了/boot [root@localhost ~]# rm /boot -rf 二、起不来了 grub，启动的img镜像都没了 三、光盘救援 参考：https://blog.51cto.com/14012942/2426097 看一下 kernel-3.10.0-957.el7.x86_64.rpm在boot目录生成的文件 ","link":"http://quansen88.cn/20190830centos7-shan-boot-mu-lu-wan/"},{"title":"CentOS7删bootloader玩","content":"CentOS7没事删bootloader和stage1.5阶段玩 众所周知bootloader位于磁盘前446字节，属于stage1.0阶段 磁盘512字节后有一段空间是stage1.5阶段，用于找到启动的img和vmlinuz 众所周知，stage1.0-stage2.0都可以用grub2-install（CentOS6是grub-install） 参考：http://s4.51cto.com/wyfs02/M02/87/20/wKiom1fVBELjXsvaAAUkuL83t2Q304.jpg 一、先删bootlater 1、dd删磁盘前446字节 2、果然启动不起来了😠 3、光盘修复 参考：https://blog.51cto.com/14012942/2434054 众所周知。stage1.0-stage2.0都用万能的grub2-install（CentOS6的grub太久，只能grub-install） 二、删stage1.5阶段的东西 1、stage1.5阶段的东西位于磁盘的mbr后面的分区，用来加载stage2 stage2.0就是内核镜像，initramfs，删这两个就用万能的重新安装内核即可，参考（没事别乱删）： CentOS7删除/boot/initramfsxxx.img并尝试光盘救援模式修复 CentOS7删vmlinuz玩 CentOS7删boot目录玩 现在破坏磁盘512字节后的内容： 启动后连grub界面都看不到 2、救援模式救援 使用stage阶段修复的万能法宝：grub2-install 参考别人的博客看看：https://www.cnblogs.com/mydba-j/p/10119498.html ","link":"http://quansen88.cn/20190830centos7-shan-bootloader-wan/"},{"title":"centos7内核升级","content":"两种方式升级内核 一、yum升级内核 参考：https://blog.csdn.net/kikajack/article/details/79396793 不多废话了，直接操作，原理看别的文章 1、uname -r 2、备份数据 3、按照官方导入epel仓库 参考：http://elrepo.org/tiki/tiki-index.php 4、安装long term版本吧 参考：http://elrepo.org/tiki/kernel-lt 5、查看已有的内核 6、命令设置grub 7、也可以修改/etc/default/grub,修改完记得重新生成配置文件 8、重启即可 9、清理旧内核（可选） 能不清理旧别清理吧，centos允许多内核共存 二、源码编译内核 1、安装必要的包 2、解压包 3、cp一个配置文件稍作修改 加一个NTFS文件系统支持： 4、开始编译 5、安装模块 6、安装内核 7、关机，加个NTFS优盘，使用新内核启动，发现可以识别了 如果只是需要ntfs，只需安装ntfs-3g 8、更改启动优先级 9、手动删掉编译的内核 ","link":"http://quansen88.cn/centos7-nei-he-sheng-ji/"},{"title":"CentOS修改grub的背景图","content":"先上CentOS6 1、默认grub的背景图，黑黑的一片 2、grub背景图和/boot/grub/splash.xpm.gz这个文件有关 打开文件发现分辨率是640*480的 3、百度下载个相同分辨率的文件 4、对图片格式转换 5、重启看看，很强悍 二、CentOS7更换grub背景 参考：http://blog.sina.com.cn/s/blog_15cf82eb50102xew1.html 1、百度一个图片 2、通过这个网址将图片转换为TGA格式 choose size选640*480 https://image.online-convert.com/convert-to-tga 3、图片放到/boot/grub/目录下面 4、修改/etc/default/grub 5、重新生成grub 6、效果： ","link":"http://quansen88.cn/20190828centos-xiu-gai-grub-de-bei-jing-tu/"},{"title":" CentOS删除fstab的恢复","content":"CentOS删除fstab的恢复 需要光盘进入救援模式 CentOS6怎么进入救援模式：https://blog.51cto.com/14012942/2433449 一、先拿CentOS6开刀 由于这个CentOS6使用了逻辑卷，所以进去之后要先激活逻辑卷，不懂的百度“救援模式 逻辑卷” 然后查看lvs，lvdisplay 这样就知道我的root分区设备在/dev/VolGroup/lv_root 我的swap分区在/dev/VolGroup/lv_swap 然后就可以挂载root到某个临时目录下 然后就可以chroot切根了 然后就可以手动编写fstab文件就可以了 比较简单，fstab误删了就这么来吧，，可以参考这篇大哥的文章： https://blog.51cto.com/11886307/2377515 CentOS7误删fstab 重复性的操作不写了 同样参考：https://blog.51cto.com/11886307/2377515 ","link":"http://quansen88.cn/centos-shan-chu-fstab-de-hui-fu/"},{"title":"CentOS7忘记密码与防密码破解","content":"CentOS7忘记密码与防密码破解 方法一 1、进入单用户模式： **将光标移动linux16开始的行，添加内核参数rd.break ** **按ctrl-x启动 ** 然后CTRL-D重启 方法二： 1、按e进入编辑模式 将光标移动linux16开始的行，改为rw init=/sysroot/bin/sh （原有的操作系统被挂载到了/sysroot） 2、然后和上面方案一差不多 CentOS7防密码被破解 即防别人通过进入单用户模式来改密码 当然，此方法防君子不妨小人，光盘救援模式照样改你密码 解决办法：给grub加上密码即可，进入单用户磨石前先验证grub密码 效果： 发现我按下e后要输入密码 其他方法请百度 grub2-setpassword 删除密码方法 删除/boot/grub2/user.cfg 即可 当然，此方法防君子不妨小人，光盘救援模式照样改你密码 ","link":"http://quansen88.cn/20190828centos7-wang-ji-mi-ma-yu-fang-mi-ma-po-jie/"},{"title":"shell脚本之信号的捕捉","content":"shell脚本之信号的捕捉 ​ trap，翻译过来就是陷阱的意思，shell脚本中的陷阱是专门用来捕捉信号的。啥信号呢？比如经常使用的kill -9，kill -15，CTRL+C等都属于信号 1、查看所有可用的信号 trap -l或kill -l即可 2、常见的信号如下： 真正的信号名字不是SIGXXX，而是去除SIG后的单词，每个信号还有对应的代号 比如向PID为12345的进程发起1信号 3、trap的选项 trap -l列出当前系统支持的信号列表，上面已经使用过，根kill -l一样 trap -p等价于trap，查看shell已经布置好的陷阱 可以看到shell默认有三个陷阱，表示忽略20,21,22信号 4、陷阱捕捉到信号后干嘛 忽略信号 捕捉到信号后做相应的处理。主要是清理一些脚本创建的临时文件，然后退出。 5、设置一个可以忽略CTRL+C和15信号的陷阱 CTRL信号对应的是SIGINT 15信号对应的是SIGTERM 这样，当前shell就不能被kill -15杀死 6、设置一个陷阱，捕捉到-15信号时，就打印“我抓到你啦~” 效果，当我对当前bash发起kill -15信号时就打印出来了 7、在脚本中设置一个能忽略CTRL+C和CTRL+Z信号的脚本 CTRL+C是2信号，即SIGINT CTRL+Z是20信号，即SIGTSTP 脚本： 脚本沉睡10s，然后打印success，脚本忽略INT和TSTP信号 效果： CTRL+C也不能阻止我睡觉 8、布置一个当脚本被终端时能清理垃圾并立即退出脚本的陷阱 脚本如下： 这样，脚本除了SIGKILL信号（kill -9），总能清理掉临时垃圾 效果 刚开始一直不能终止，后来执行了下trap发现前面shell自己设置了一个忽略CTRL+C的陷阱,退出shell重进即可 9、陷阱的守护对象 陷阱的守护对象是shell进程本身，不会守护shell环境内的子进程。但如果是信号忽略型陷阱，则会守护整个shell进程组使其忽略给定信号。 ​ 可以发现，kill执行完后，屏幕没有立即打印trap_handle，而是等sleep 10运行完后才打印的。sleep进程都被忽略型trap守护了 ​ 只要是向shell进程发送的信号，都会等待当前正在运行的命令结束后才处理信号，然后继续脚本向下运行。(实际上，只有当shell脚本中正在执行的操作是信号安全的系统调用时，才会出现信号无法中断进程的情况，而在shell下的各种命令，我们是没法直接知道哪些命令中正在执行的系统调用是系统调用的)。 但sleep命令发起的sleep()调用，是一个信号安全的，所以上面脚本中执行sleep的过程中，信号不会直接中断它们的运行，而是等待它运行完之后再执行信号处理命令。 10、如果shell中针对某信号设置了陷阱，则该shell进程接收到该信号时，会等待其内正在运行的命令结束才开始处理陷阱 11、CTRL+C和SIGINT不是等价的。当某一时刻按下CTRL+C，它是在向整个当前运行的进程组发送SIGINT信号。对shell脚本来说，SIGINT不仅发送给shell脚本进程，还发送给脚本中当前正在运行的进程 可以发现，CTRL+C后，不仅trap进行处理了，sleep也立马结束了；说明CTRL+C不仅让脚本进程收到了SIGINT信号，也让当前进程收到了SIGINT信号 有点难理解，以后再来看 ","link":"http://quansen88.cn/20190827shell-jiao-ben-zhi-xin-hao-de-bu-zhuo/"},{"title":"shell脚本进阶之字符串处理","content":"字符串处理 1、获取字符串长度 2、字符串切片 格式： parameter:offset{parameter:offset} parameter:offset{parameter:offset:length} 截取从 offset 个字符开始，向后 length 个字符。 3、替换字符串 格式：${parameter/pattern/string} 4、字符串截取 格式： 示例： 好记一点：#删左边，所以*放分隔符左边 %删右边，所有*放分隔符右边 5、变量状态赋值 6、变量颜色 字体颜色 字体背景颜色 显示方式 30：黑31：红32：绿33：黄34：蓝色35：紫色36：深绿37：白色 40：黑41：深红42：绿43：黄色44：蓝色45：紫色46：深绿47：白色 0：终端默认设置1：高亮显示4：下划线5：闪烁7：反白显示8：隐藏 格式： 7、字符大小写转换 ","link":"http://quansen88.cn/shell-jiao-ben-jin-jie-zhi-zi-fu-chuan-chu-li/"},{"title":"SHELL脚本--shell数组基础","content":"SHELL脚本--shell数组基础 ​ 数组和变量的区别：变量在内存中占用的空间是离散的，数组在内粗中开辟一段连续的大内存空间，随后数组中的每个元素都放入数组内存中。数组元素使用index标识。 ​ bash里有两种数组普通数组和关联数组。普通数组只能使用整形数值作为数组索引，关联数组可以使用字符串作为索引。关联数组的另外三种称呼：字典（dict），hash结构和映射（map），是一种key和value一一对应的关系。 一、普通数组 1.1定义普通数组 方法一： 方法二：自定义索引位 1.2打印数组所有值 1.3查看数组索引号 1.4统计数组中元素的个数（只统计值不为空的元素） 1.5统计数组下标为1的变量的长度 二、关联数组 2.1声明关联数组 2.2数组赋值 分开赋值 2.3查看数组所有值 2.3查看数组索引号 2.4统计数组长度 三、数组元素截取、替换 和变量的截取和替换是类似的 从左匹配删除和从又匹配删除 四、for循环遍历数组 第一种写法： 第二种写法： 第三种写法：c语言风格 ","link":"http://quansen88.cn/shell-jiao-ben-shell-shu-zu-ji-chu/"},{"title":" testsrv脚本（SysV脚本）","content":"testsrv脚本（SysV脚本） 一、说明： ​ CentOS7已经使用Systemd来管理服务，推荐使用Systemd来管理服务。ubuntu18.04现在也是Systemd管理服务。 ​ init.d是CentOS6时候常用的，不过现在，CentOS6，CentOS7，ubuntu16.04，ubuntu18.04照样可以用。 ​ 该脚本一般都放在/etc/rc.d/init.d目录下 ​ 该脚本可以接收start，stop，status，reload，restart等参数来管理服务 ​ 基本上都会加载/etc/rc.d/init.d/functions，这个文件中有一些比较好用的函数 ​ #chkconfig和#describe这两行都要写上，describe这个现在貌似可以不用写了。 ​ #chkconfig:2345 96 07——必须写明，2345代表在这些模式下，开启testsrv功能，96代表开启编号为96 07代表关闭时的编号，相当于创建了一个软连接，这个不要和已有的编号重复，/etc/rc.d/rc5.d/看已有的编号 ​ 再说明一下，CentOS7现在不使用init0-6来管理用户模式，也用systemd管理 二、题目 编写服务脚本/root/bin/testsrv.sh，完成如下要求 (1) 脚本可接受参数：start, stop, restart, status (2) 如果参数非此四者之一，提示使用格式后报错退出 (3) 如是start:则创建/var/lock/subsys/SCRIPT_NAME, 并显示“启动成功” 考虑：如果事先已经启动过一次，该如何处理？ (4) 如是stop:则删除/var/lock/subsys/SCRIPT_NAME, 并显示“停止完成” 考虑：如果事先已然停止过了，该如何处理？ (5) 如是restart，则先stop, 再start 考虑：如果本来没有start，如何处理？ (6) 如是status, 则如果/var/lock/subsys/SCRIPT_NAME文件存在，则显示“SCRIPT_NAME is running...”，如果/var/lock/subsys/SCRIPT_NAME文件不存在，则显示“SCRIPT_NAME is stopped...” (7)在所有模式下禁止启动该服务，可用chkconfig 和 service命令管理 说明：SCRIPT_NAME为当前脚本名 三、脚本 四、操作 CentOS7操作 启动关闭玩玩 五、脚本详解 ​ 再说一下，CentOS7推荐systemd来管理服务，不建议用SysV管理 ​ chkconfig 2345 10 90表示服务在2345四个模式下开启testsrv功能，10表示开启编号为96，07表示关闭的编号。 ​ 这个编号要注意下，不能和其他重复了，init 1是单用户模式，该模式下绝大部分服务都是开机关闭的（K打头），/etc/rc.d/rc1.d/下面自己看看吧，选一个没用的开启编号。init 5是桌面图形化模式，很多服务是启动的，可以看看/etc/rc.d/rc5.d/下面哪些开启编号（S打头）占用了，选择一个关闭的编号 ​ 如果不想该服务在任何模式下启动，那么把2345变成- ​ 同时再说明一下：CentOS7不采用init0-6来管理启动模式，使用Systemd管理 六、chkconfig用法 这个现在也就是CentOS6用了，CentOS7虽然命令还在，但已经不用来管理服务了 查看所有服务的开机启动情况 查看atd服务的开启启动情况 禁止atd服务2 3 4 5 模式下启动 新写了个testsrv，加入SysV 删除应该是del 七、CentOS6的ntsysV命令 修改程序启动开机启动 ","link":"http://quansen88.cn/testsrv-jiao-ben-sysv-jiao-ben/"},{"title":" SHELL脚本PPT脚本","content":"SHELL脚本PPT脚本 在能用的前提上再往好里写 **1、判断/var/目录下所有文件的类型 ** 2、九九乘法表 3、判断网络中的主机状态 耗费CPU 4、国际象棋棋盘 用到了背景色 **5、后续六个字符串：efbaf275cd、4be9c40b8b、44b2395c46、 f8c8873ce0、b902c16c8b、ad865d2f63是通过对随机数变量RANDOM随机 执行命令： echo $RANDOM|md5sum|cut –c1-10 后的结果，请破解这些 字符串对应的RANDOM值 ** 6、打印绿色OK和和红色Failed 7、判断当前什么操作系统 ","link":"http://quansen88.cn/shell-jiao-ben-ppt-jiao-ben/"},{"title":"copycmd-拷贝命令及其依赖库","content":"copycmd-拷贝命令及其依赖库 题目： ","link":"http://quansen88.cn/copycmd-kao-bei-ming-ling-ji-qi-yi-lai-ku/"},{"title":" 脚本进阶一","content":"脚本进阶一 一、for循环的第二种写法： 众所周知，for有两种写法 第一种：for i in k8s-node{1..3};do setenforce 0;done 第二种写法：C语言风格 直接写怎么用： 二、while循环 我喜欢这样写,一直循环然后用break退出 while的高级用法：读取标准输入的内容实现循环 并且看网友的资料说，上面写法中wile使用重定向机制，fstab文件内容被重定向给了整个while语句，这个特性要注意下 **while的注意事项1：**管道传递内容：echo &quot;abc xyz&quot; | while read line ；do {};done 众所周知管道会开启子shell，子shell内的数组，变量，函数在函数外部均不生效 三、until循环 四、continue特殊用法 continue [N]:提前结束第N层的本轮循环，最内层为第一层 默认N为1，只退一层循环。比如复杂的代码套了好几层的话，continue 2可以直接提前结束两层的循环，直接进入下一轮判断，continue候面的代码不执行了 五、break用法 break [N]：提前结束第N层循环，最内层为第1层 注意：这个直接结束第N层所有循环了，而continue只是结束第N层的本轮循环 六、shift命令 shift [n] 很重要，脚本中经常用到。将参数列表左移n次 七、select循环与菜单 select经常与case一起用；还有就是PS3作为提示符；还有就是要配合break或exit退出循环 效果 八、函数 载入函数： . filename source filename 九、删除函数 可以使用unset删除 比如：一个简单的函数,执行没有问题 中间加一行unset,就报错了，因为函数被删除了 还可以通过定义空函数实现，这是我在系统中的脚本中发现的 十、函数变量的生存时间 环境变量：当前shell和子shell有效 本地变量：只在当前shell进程中有效，包括脚本函数 局部变量：函数的生命周期，函数结束时变量销毁 局部变量的定义：local AGE=20 十一、函数的递归 联想到fork炸弹 脚本实现 十二、信号的捕捉trap 看另一篇文章 十四、数组 声明数组（两者不可相互转换）： declare -a ARRAY_NAME 索引数组 declare -A ARRAY_NAME 关联数组 数组元素赋值： ARRAY_NAME=(&quot;VAL1&quot; &quot;VAL2&quot; &quot;VAL3&quot; ...) read -a ARRAY 交互式赋值 显示所有普通数组 declare -a 引用数组 引用数组元素 引用数组所有元素 获取数组的长度 删除数组中某个元素。 删除整个数组 关联数组必须先声明后调用 数组这一块看另一篇文章吧 十三、字符串处理 看另一篇文章吧 十四、eval命令 ​ eval命令将会首先扫描命令行进行所有的置换，然后再执行该命令。该命令 适用于那些一次扫描无法实现其功能的变量.该命令对变量进行两次扫描 十五、创建临时文件或目录 十六、install命令 该命令很强大，相当于多个命令的组合：cp，chmod，chown，mkdir等 可以自行看帮助，make install用的就是这个install ","link":"http://quansen88.cn/jiao-ben-jin-jie-yi/"},{"title":" 计划任务注意事项","content":"计划任务注意事项 1、at 这个是一次性的计划任务，应该很少用 2、crontab 周期性计划任务 计划任务没有执行的原因可以通过mail邮件分析 计划任务可以实现让指定用户执行某条命令 注意事项： 1、最好在计划任务前面写上PATH=...指定PATH路径，否则经常报错找不到命令，只能绝对路径 2、带有特殊字符的计划任务，比如含有百分号，最好放入shell脚本中，再写入计划任务 3、crontab使用vim作为默认编辑器。见下面 良好的习惯： crontab使用vim作为默认的编辑器： 系统的计划任务： run-parts命令，可以扫描某目录，执行下面所有可以执行的文件。vim /usr/bin/run-parts 使用脚本写入计划任务： 实际写入的是/var/spool/cron/root，ubuntu是/var/spool/cron/crontabs/root 查看指定用户的计划任务： crontab -u qqq -l 一次查看所有用户的计划任务： 如何实现秒级计划任务： 参考：https://blog.csdn.net/weixin_37998647/article/details/78669940 参考：https://www.cnblogs.com/yangxunwu1992/p/6054907.html 生产环境中的计划任务都必须经过测试 ","link":"http://quansen88.cn/ji-hua-ren-wu-zhu-yi-shi-xiang/"},{"title":"进程管理","content":"进程管理 重点： 一、pkill用于杀死一类进程，比如下面强杀wang的进程 pkill -9 -U wang 二、killall也可以杀一类进程（默认可能没有），比如杀nginx进程 killall nginx 三、kill -0和kill -1要知道啥意思 kill -0 pid一般用来检测某进程是否存货，不过pid不确定，一般用killall -0 name；脚本中经常用这个检查某个进程在不在 killall -1 name用于让程序重读配置文件，比如修改了某程序的配置文件，可以用此法重读配置文件 四、有时候需要获取所有进程中占用内存或CPU最高的一个： ps aux k %mem 或者 ps aux k %cpu最后一个便是 五、关于管道的特点 管道很重要的一个特点就是会开启一个子shell，可以想想子shell可以继承父shell哪些属性，fork炸弹等 六、PS1，PS2，PS3，PS4 PS1是命令提示符 PS2是多行输入比如cat tee重定向前面的提示符，默认是&gt; PS3是shell脚本中select的提示符 PS4很少用，别记了 七、进程管理工具要熟练掌握几个： lsof iftop等 八、程序并行执行 &amp;符号，&amp;可以开启一个子进程 比如使用ping命令扫局域网可以ping通的机器 九、screen不间断会话 除了screen还可以用nohub command &amp;来实现，可以看之前的笔记 还有吗？后续补充 1、ps aux 比较常用 a 选项包括所有终端中的进程 x 选项包括不链接终端的进程 u 选项显示进程所有者的信息 2、ps -ef 查看所有进程，父进程，子进程，比较常用 3、 ps axo pid,cmd,psr,ni,pri,%mem,%cpu 指定显示哪些东西，可以使用ps L查看支持哪些内容的显示 4、还可以排序：k选项 按CPU排序 [root@linux1 ~]# ps axo pid,cmd,psr,ni,pri,%mem,%cpu k %cpu 5、kill 12345 温柔的杀死12345进程（正常结束进程），使用-15信号，不写默认就是-15， 6、kill -9 12345 强杀，某些顽固进程就得强杀 7、killall httpd 杀某一类进程，比如httpd启动后就有好几个进程，killall httpd就可以杀死所有httpd进程 8、pidof tail 查看正在执行的tail命令的pid kill pidof tail 9、僵尸进程一般杀父进程解决，如果，父进程不能杀，就只能重启系统了 10、CPU与IO密集 买云服务器经常看到 CPU密集型是对cpu占用率高的进程 IO密集型是等待IO时间长的进程 11、pgrep检索指定类型进程，一般都是ps -ef | grep pgrep -U root 12、kill -0 检测进程是否存活，脚本中有用 killall -0 httpd执行后使用$?判断httpd是否在运行，面试可能会问 13、kill -1 重读配置文件 killall -1 httpd 修改httpd配置文件后使用此命令重读配置文件 14、pkill 杀一类进程，比如httpd所有进程，wang用户的所有进程 15、程序后台运行 CTRL +Z程序在后台不会继续执行 screen可以实现不间断会话 nuhub command &amp; &gt;/dev/null也可以实现不间断会话（不重定向标准输出会打印到屏幕上） 16、管道 子shell 参考：https://blog.csdn.net/m0_37556444/article/details/83090602 https://www.cnblogs.com/python2687806834/p/9957050.html 17、程序并发执行 &amp;开启子shell让程序后台执行 18、进程优先级 nice可以修改程序优先级 19、ps命令的o选项可k选项 o选项可以指定输出某列（-L查看可以输出哪些列）k选项指定按哪一列排序，实在记不住就ps aux | sort -n -k吧 20、ss，netstat看连接数，看哪个IP连的多 21、nslookup，dig，traceroute DNS解析和路由追踪 22、上下文是啥，高的话有啥后果 23、程序与进程与线程 参考：https://www.cnblogs.com/aquarius-bear/p/3939939.html **24、**还有吗？后续补充 ","link":"http://quansen88.cn/jin-cheng-guan-li/"},{"title":" nmcli命令","content":"nmcli命令 可以参考这个：https://mp.weixin.qq.com/s/y64vMJqfbtDGXcTDz6R-mQ nmcli可以自动补全，还是比较容易的 只敲nmcli显示所有网卡信息： nmcli一级选项 查看所有网络接口信息 查看指定接口信息 显示所有活动链接 删除一个网卡连接 手动给ens37配个IP，这个是永久的，会生成配置文件 修改IP或某些网络参数 增加IP、删除IP 重启网路 ","link":"http://quansen88.cn/nmcli-ming-ling/"},{"title":" 实验：主机间跨网络通信","content":"实验：主机间跨网络通信 实验拓扑图： 第一步：创建四个虚拟机 第二步：配置vmnet6和vmnet8网段 vmnet6:10.0.0.0/8 vmnet8:192.168.38.0/24 vmnet0:172.18.0.0/24 三、如上图所示，配置好每个虚拟机的网卡类型 四、配置IP 第一个虚拟机 第二个虚拟机 第三个虚拟机 第四个虚拟机 五、配置路由规则 现在B还ping不通A A的默认网关应该是192.168.38.200（或者给A加一条路由，让A知道172.18网段是要通过192.168.38.200出去的，不然数据包全发到192.168.38.2去了） R1走172.18网段通过10.0.0.201 R2走192.168.38网段通过10.0.0.200 B的默认网关应该是172.18.28.201 六、第二三个虚拟机开启路由转发 第二个和第三个虚拟机都要执行 七、接下来就是见证奇迹的时刻 B ping A A ping B (第一次实验做完后NAT就可以直接ping到桥接了，不知道什么原因) A到B怎么走的： B到A怎么走的 现在虚拟机不知道怎么了默认NAT就能ping到桥接的虚拟机，现在tracepath看一下(这是新的一台虚拟机) 持久化路由表 思路:可以把添加路由的命令写入开机启动文件 方法一： 写入rc.local文件 方法二（推荐）： 实验：主机间跨网络通信 实验拓扑图： 第一步：创建四个虚拟机 第二步：配置vmnet6和vmnet8网段 vmnet6:10.0.0.0/8 vmnet8:192.168.38.0/24 vmnet0:172.18.0.0/24 三、如上图所示，配置好每个虚拟机的网卡类型 四、配置IP 第一个虚拟机 第二个虚拟机 第三个虚拟机 第四个虚拟机 五、配置路由规则 现在B还ping不通A A的默认网关应该是192.168.38.200（或者给A加一条路由，让A知道172.18网段是要通过192.168.38.200出去的，不然数据包全发到192.168.38.2去了） R1走172.18网段通过10.0.0.201 R2走192.168.38网段通过10.0.0.200 B的默认网关应该是172.18.28.201 六、第二三个虚拟机开启路由转发 第二个和第三个虚拟机都要执行 七、接下来就是见证奇迹的时刻 B ping A A ping B (第一次实验做完后NAT就可以直接ping到桥接了，不知道什么原因) A到B怎么走的： B到A怎么走的 现在虚拟机不知道怎么了默认NAT就能ping到桥接的虚拟机，现在tracepath看一下(这是新的一台虚拟机) 持久化路由表 思路:可以把添加路由的命令写入开机启动文件 方法一： 写入rc.local文件 方法二（推荐）： ","link":"http://quansen88.cn/shi-yan-zhu-ji-jian-kua-wang-luo-tong-xin/"},{"title":" 配置实现网桥","content":"配置实现网桥 就是通过一个虚拟机充当交换机，连通两个网络 实验一：连通vmnet0和vmnet8 实验中只要是linux机器即可 第一台机器：CentOS7；连接vmnet8网络； 第二台机器：ubuntu19.04；连接桥接网络 现在给ubuntu19.04配个临时192.168.38.46/24的IP，这样的话ubuntu和CentOS7都有192.168.38的IP了 （根据上一遍文章，连通不同网络需要路由器，同一网络的话交换机即可完成） 当然，现在ubuntu19.04不可能ping通CentOS7的，因为网络隔离 接下来，第三台机器出现：该机器有两块网卡：一个NAT，一个桥接。IP无所谓，不需要，它用来做二层交换机，要什么IP，重点是它有两个网卡，一个NAT，一个桥接 然后开始接下来的厉害操作 这样，这个交换机就做好了，现在见证奇迹,ping通了 然后将该机器关机，ping又不通了 ","link":"http://quansen88.cn/pei-zhi-shi-xian-wang-qiao/"},{"title":" ubuntu18.04网络配置","content":"ubuntu18.04网络配置 YAML文件格式：常量值，对象，数组 https://www.jianshu.com/p/97222440cd08 官方文档： https://help.ubuntu.com/lts/serverguide/network-configuration.html dhcp自动获取： 静态IP(单个IP)： 静态IP（多个IP），采用数组格式 DNS查看 ","link":"http://quansen88.cn/ubuntu1804-wang-luo-pei-zhi/"},{"title":" bash环境配置文件加载顺序","content":"bash环境配置文件加载顺序 一、测试方法： 二、通过xshell登录（交互式、登录式） /etc/profile.d/test.sh -&gt; /etc/profile -&gt; /etc/bashrc -&gt; ~/.bashrc -&gt; ~/.bash_profil 三、su root（交互式、非登录式;su - root就是登录式了） -表示--login，加上后为登录式，并且切换环境变量 /etc/profile.d/test.sh -&gt; /etc/bashrc -&gt; ~/.bashrc 四、bash（交互式，非登录式） 执行bash进入子shell，为交互式，非登录式，和上面一样 五、总结： 交互式登录式： 交互式非登录式 非交互、非登录式：几乎执行所有的shell脚本都不会特意带上&quot;--login&quot;选项，因此shell脚本不会加载任何bash环境配置文件，除非手动配置了变量BASH_ENV 特殊：远程shell方式启动的bash，它虽然属于非交互、非登录式，但会加载~/.bashrc，所以还会加载/etc/bashrc，由于是非登录式，所以最终还会加载/etc/profile.d/*.sh，只不过因为是非交互式而使得执行的结果全部重定向到了/dev/null中 搞不懂系列 ","link":"http://quansen88.cn/bash-huan-jing-pei-zhi-wen-jian-jia-zai-shun-xu/"},{"title":"LVM","content":"LVM 创建逻辑卷，逻辑卷扩容，vg扩容，vg中移除pv，缩容，vg，lv重命名，xfs与ext4快照还原 一、LVM相关概念和机制： ​ LVM（Logical Volume Manager）可以让分区变得弹性，可以随时随地地扩大和缩小分区，前提是该分区是LVM格式的 ​ LVM需要软件包LVM2，一般CentOS发行版都预装了 PV（Physical Volume）即物理卷 ​ 硬盘分区后（还未格式化为文件系统）使用pvcreate可以将分区创建为pv，要求分区的system ID为8e，即为LVM格式的系统标识符 VG（Volume Group）即卷组 ​ 将多个PVz组合起来，使用vgcreate创建成卷组，这样卷组包含了多个PV就比较大了，相当于重新整合了多个分区后得到的磁盘。虽然VG是整合多个PV的，但是创建VG时会将VG所有的空间根据指定PE大小划分为多个PE，在LVM模式下的存储都以PE为单元，类似于文件系统的block。 PE（Physical Extend） ​ PE是VG中的存储单元。但实际存储的数据都存储在里面 LV（Logical Volume） ​ VG相当于整合过的磁盘，那么LV就相当于分区，只不过该分区是通过VG来划分的。VG中有很多PE单元，可以指定多少个PE划分给一个LV，也可以指定大小（如多少兆）来划分。划分LV后就相当于划分了分区，只需再对LV格式化即可变为普通的文件系统。 ​ 通俗地讲，非LVM管理的分区步骤是将硬盘分区，然后将分区格式化为文件系统。而使用LVM，则是在硬盘分区为特定的LVM标识的分区后将其z转变为LVM可管理的PV，其实PV仍然类似于分区，然后再将几个PV整合为类似于磁盘的VG，最后VG划分为LV，此时LV就变成了LVM可以管理的分区，再对其格式化即可成为文件系统。 LE（Logical Extend） ​ PE是物理存储单元，而LE则是逻辑存储单元，即lv中的存储单元，和PE的大小是一样的。从vg中划分lv，实际是从vg中划分vg中的pe，只不过划分lv后不再称为pe，而称为le ​ LVM之所以能够伸缩容量，其实现方法就是j将LV里空闲的PE移出，或向LV中添加空闲的PE。 二、LVM写入机制 ​ 线性模式：先写完来自同一个PV的PE，再写来自下一个PV的PE ​ 条带模式：一份数据拆成多份，分别写入该LV对应的每个PV中，所以读写性能较好，类似于RAID 0 默认为线性模式，也推荐此模式，LVM的重点在于弹性容量而不是性能。 三、创建逻辑卷 实验采用两块硬盘进行操作 3.1、VMware开机状态下插入两块硬盘 3.2、触发硬盘扫描机制 3.3 lsblk查看 3.4、pvcreate创建pv 使用pvs简单查看 3.5、vgcreate创建vg 使用vgs简单查看，vg是有名字的 vgcreate可以使用-s指定pe大小，可以姑且认为pe就是block 3.6、lvcreate创建lv lvcreate可以使用-L 5G指定lv为5g；或者-l 20指定20个pe，一个pe是16m，20个就是320M 3.7、格式化lv为文件系统 3.8、挂载 四、逻辑卷的扩容： 逻辑卷一般格式化为ext4格式，如果格式化为xfs，个别步骤会有一点小区别 下面扩容lv_mysqldata从5G到6G 4.1、首先查看下vg还有没有空间 4.2、lvextend扩容 -r选项有点意思，-r表示resizefs，扩容完了直接同步文件系统，免去手动执行resize2fs xfs文件系统和ext4系统的区别就在同步文件系统：xfs文件系统要使用xfs_growfs命令。 不想使用-r就得手动执行resize2fs 另外：lvresize也可以实现，和lvextend一样，如下 五、逻辑卷中加入新硬盘（vg的扩容） 4.1、VMware开机状态下插入新硬盘 4.2、手动触发磁盘扫描 4.3、lsblk查看 sdd 4.4、将sdd创建为pv 并用pvs查看 4.5、此时可以创建新的vg，也可以将sdd加入已有的vg 将sdd加入vg_mysql 六、删除PV(vg中移除pv等) 从vg中移出某块磁盘 6.1、pvs查看pv详情 sdb，sdc，sdd三块硬盘都在vg_mysql上，sdd显示PFree为19.88，没有使用，可以直接移除 6.2、先从vg_mysql中移出sdd 6.3、移出pv 6.4、拔出硬盘 七、缩容逻辑卷 一般比较少用，操作前要备份数据。 注意：xfs文件系统不支持缩容 7.1、备份数据 7.2、查看lv_mysql-lv_mysqldata当前总大小以及剩余空间 所以打算收缩2G，目标5G 7.3、先卸载相应的lv 7.4、首先卸载设备并使用resize2fs收缩文件系统的容量为目标大小 按照提示，先运行e2fsck，主要是为了检查是否修改后的大小会影响数据 然后再执行resize2fs 7.5、再收缩lv，可以-L指定收缩容量或者-l指定收缩PE数量 7.5、此时重新挂载即可 八、vg和lv重命名 九、xfs与ext4逻辑卷的快照与还原 ","link":"http://quansen88.cn/lvm/"},{"title":" 20190811 RAID","content":"20190811 RAID 一、什么是RAID ​ RAID独立磁盘冗余阵列(Redundant Array of Independent Disks) ​ 多个磁盘合成一个“阵列”来提供更好的性能、冗余，或者两者都提供。 ​ 常见RAID组合方案：RAID0、RAID1、RAID5、RAID10和RAID01 1.1 RAID 0 最少需要两块硬盘 读写性能均提升 无冗余能力，任意一块硬盘挂掉数据就丢失 磁盘利用率：100% 评价：数据无要求，只顾性能，企业中不可能用到；个人玩家可以搞着玩 1.2 RAID 1 最少需要两块硬盘 读性能提升，写性能下降（同样的数据要写两次） 有冗余能力 磁盘利用率：1/n （两块硬盘组阵列就是50%） 评价：数据有一定保障，但性能一般，没钱还想保证数据安全的方法 1.3 RAID 5 最少需要3块硬盘 读写性能均提升 有容错能力 磁盘利用率：(n-1)/n 评价：RAID 0和RAID 1的妥协产物，兼顾成本，数据，性能，但还有很大缺陷 1.3 RAID 10 最少需要4块硬盘 读写性能均提升 有有冗余能力（理论只要坏的不是同一组硬盘，可以最多损坏50%的硬盘而不丢失数据） 磁盘利用率：50% 原理：先组RAID 0，再组RAID 1 评价：数据无价，能用钱解决的都不是问题。读写速度，数据保障均超过RAID5 1.4 RAID 01 最少需要4块硬盘 原理：先组RAID 0，再组RAID1 评价：安全性很差，损坏一块硬盘后，该RAID 0组整个失效，所有磁盘读写压力立马全部转移至另一组RAID 0，很容易导致另一组RAID 0也挂掉。总之，基本无人用 二、RAID的冗余和性能计算 来自：https://en.wikipedia.org/wiki/Standard_RAID_levels 三、你的数据有多安全？关于RAID你了解多少？ https://zhuanlan.zhihu.com/p/31944934 ","link":"http://quansen88.cn/20190811-raid/"},{"title":"文件系统管理","content":" 文件系统管理： 机械硬盘与固态的区别；磁盘的构造；mbr分区表；gpt分区表；热拔插硬盘；fdisk分区；非交互式分区；查看文件系统信息；挂载与卸载；自动挂载；swap管理 为什么fdisk分区是从2048扇区开始的 https://blog.csdn.net/han156/article/details/77431512 MBR分区表的备份与还原 https://blog.51cto.com/14012942/2427746 一、机械硬盘与固态硬盘 1.1、区别： 1、性能：固态硬盘速度快，比机械硬盘快好多倍 2、抗震：固态硬盘相比机械硬盘更抗震 3、噪音：固态硬盘相比机械硬盘噪音更小 4、散热：机械硬盘因其物理特性，功耗比固态大，相对比固态发热严重 5、重量：固态硬盘更轻，体积也更小 6、数据恢复：固态硬盘数据误删，恢复的概率很小，机械硬盘恢复概率较高 7、价格：有得必有失，固态硬盘价格较贵，机械相对便宜，但能用钱解决的问题都不算问题 1.2、专业术语： **1、磁道（Track）：**一块机械硬盘有 好几个盘片，每个盘片正反面都有两个磁头，在盘片旋转时磁头扫过的一圈称为磁道，所有磁道都是同心圆，从盘片外圈开始向内数，磁道号从0开始逐数递加 2、扇区（Sector）：每个磁道以512字节等分为多个弧段，一个弧段就是一个扇区。因为外圈大，所以外圈扇区多内圈扇区少。 **3、簇：**每个扇区512字节，是磁盘控制器 最小读写单元。Windows以“簇”为存储单元，一个簇是多个扇区（2,4,8,...）,一般windows分区都会指定4k对齐，及4096字节（8个扇区） **4、柱面（cylinders）：**将所有盘片相同磁道数的磁道划分为柱面。和磁道号的标记方式一样，从外向内从0开始逐数增加。 **5、分区：**分区是为了在逻辑上将某些柱面隔开形成边界。它是以柱面为单位来划分的，首先划分外圈柱面，然后不断向内划分。 2、为什么要划分柱面？ ​ 之所以划分柱面，是因为所有磁盘同步旋转，所有磁头同步移动，所有的磁头在任意一个时刻总是会出在同一个磁道同一个扇区上。读写数据时，任意一段数据总是按柱面来读写的。所以盘片数越多，读写所扫的扇区数就越少，所需的时间相对就越少，性能就越好。 ​ 盘片同步旋转，转动一个角度，外圈比内圈的线速度更快，磁头能够扫过的扇区数更多，因此读写越外圈磁道中的数据比越内圈更快。C盘速度也比后面的分区快 ​ 向磁盘写数据是从外圈柱面向内圈柱面写的，只有写完一个柱面才写下一个柱面。因此磁盘用过一段时间后存储东西的速度会有所减慢就是因为外圈柱面已经用掉了。 1.3、磁盘或分区容量计算 磁盘大小=磁头数(heads)×每磁道上的扇区数(sectors)×512×柱面数(cylinders) 二、分区 2.1、分区方法：MBR与GPT ​ MBR：在该扇区中第446字节之后的64字节是分区表，每个分区占用16字节，所以限制了一块磁盘最多只能有4个主分区(Primary,P)，如果多于4个区，只能将主分区少于4个，通过建立扩展分区(Extend,E)，然后在扩展分区建立逻辑分区(Logical,L)的方式来突破4个分区的限制。 ​ 在Linux中，MBR格式的磁盘主分区号从1-4，扩展分区号从2-4，逻辑分区号从5-15，也就是最大限制是15个分区。 ​ 例如，一块盘想分成6个分区，可以： 1P+5L：sda1+sda5+sda6+sda7+sda8+sda9 2P+4L：sda1+sda2+sda5+sda6+sda7+sda8 3P+3L：sda1+sda2+sda3+sda5+sda6+sda7 ​ 而GPT格式突破了MBR的限制，它不再限制只能存储4个分区表条目，而是使用了类似MBR扩展分区表条目的格式，它允许有128个主分区，这也使得它可以对超过2TB的磁盘进行分区。 2.2、分区表信息 ​ 在MBR磁盘上，分区和启动信息是保存在一起的，如果这部分数据被覆盖或破坏，只能重建MBR ​ GPT在整个磁盘上保存多个这部分信息的副本，因此它更为健壮，并可以恢复被破坏的这部分信息。GPT还为这些信息保存了循环冗余校验码(CRC)以保证其完整和正确，如果数据被破坏，GPT会发现这些破坏，并从磁盘上的其他地方进行恢复。 2.3、热拔插添加磁盘 ​ 正常情况下，插入新的硬盘后，要重启才能识别 查看scsi设备信息： 查看主机scsi总线号 重新扫描scsi总线以热插拔方式添加新设备。 2.4、使用fdisk工具 ​ fdisk工具用来分MBR磁盘上的区。要分GPT磁盘上的区，可以使用gdisk。parted工具对这两种格式的磁盘分区都支持。 创建主分区： [root@centos7 ~]# fdisk /dev/sdc # sdb后没加数字 Welcome to fdisk (util-linux 2.23.2). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Device does not contain a recognized partition table Building a new DOS disklabel with disk identifier 0x314f0161. Command (m for help): n # 添加分区 Partition type: p primary (0 primary, 0 extended, 4 free) e extended Select (default p): p # 输入p来创建第一个主分区 Partition number (1-4, default 1): 1 # 输入分区号，从1开始 First sector (2048-41943039, default 2048): Using default value 2048 Last sector, +sectors or +size{K,M,G} (2048-41943039, default 41943039): +1G 给第一个主分区/dev/sdc1分1G，也可以使用柱面号来指定大小 Partition 1 of type Linux and of size 1 GiB is set Command (m for help): p # 第一个分区结束，p查看下已分区信息 Disk /dev/sdc: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x314f0161 Device Boot Start End Blocks Id System /dev/sdc1 2048 2099199 1048576 83 Linux 新建拓展分区： Command (m for help): n # 再建一个分区 Partition type: p primary (1 primary, 0 extended, 3 free) e extended Select (default p): e # 创建扩展分区 Partition number (2-4, default 2): 2 # 扩展分区号为2 First sector (2099200-41943039, default 2099200): Last sector, +sectors or +size{K,M,G} (2099200-41943039, default 41943039): # 剩余空间全部给扩展分区 Using default value 41943039 Partition 2 of type Extended and of size 19 GiB is set Command (m for help): p p查看下已分区信息 Disk /dev/sdc: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x314f0161 Device Boot Start End Blocks Id System /dev/sdc1 2048 2099199 1048576 83 Linux /dev/sdc2 2099200 41943039 19921920 5 Extended 新建拓展分区： Command (m for help): n # 新建逻辑分区 Partition type: p primary (1 primary, 1 extended, 2 free) l logical (numbered from 5) Select (default p): l # 新建逻辑分区,如果已有3个主分区，这里连p都没有 Adding logical partition 5 First sector (2101248-41943039, default 2101248): Using default value 2101248 Last sector, +sectors or +size{K,M,G} (2101248-41943039, default 41943039): +3G Partition 5 of type Linux and of size 3 GiB is set Command (m for help): p Disk /dev/sdc: 21.5 GB, 21474836480 bytes, 41943040 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x1551c479 Device Boot Start End Blocks Id System /dev/sdc1 2048 2099199 1048576 83 Linux /dev/sdc2 2099200 41943039 19921920 5 Extended /dev/sdc5 2101248 8392703 3145728 83 Linux 分区结束，保存，不保存按q Command (m for help): w The partition table has been altered! Calling ioctl() to re-read partition table. Syncing disks. 分区的过程，实质上是划分柱面以及修改分区表。 ​ 上面的fdisk操作全部是在内存中执行的，必须保存生效。保存后，内核还未识别该分区，可以查看/proc/partition目录下存在的文件，这些文件是能被内核识别的分区。运行partprobe或partx命令重新读取分区表让内核识别新的分区，内核识别后才可以格式化。而且分区结束时按w保存分区表有时候会失败，提示重启，这时候运行partprobe命令可以代替重启就生效。 使用脚本进行分区（实现非交互式分区）： \\n表示回车 2.5、gdisk分区 2.6、parted分区 ​ parted支持mbr格式和gpt格式的磁盘分区。它的强大在于可以一步到位而不需要不断的交互式输入(也可以交互式)。 ​ parted分区工具是实时的，所以每一步操作都是直接写入磁盘而不是写进内存，它不像fdisk/gdisk还需要w命令将内存中的结果保存到磁盘中。 parted实现非交互 2.7、格式化分区 2.7.1 mkfs 2.7.2 tune2fs修改ext文件系统属性 比如默认CentOS6手动创建的分区没有acl功能，需要手动添加 CentOS7默认创建的有 2.8、查看文件系统状态信息： 2.8.1 lsblk -f会显示出分区的类型，有时候面试会问怎么看分区的类型，df -T也可以 2.8.2 blkid 常用来查看设备UUID 2.8.3 parted /dev/sdc p 2.8.4 fdisk -l 2.8.5 file -s /dev/sdc 2.8.6 du 2.8.7 df 2.8.8 dumpe2fs ​ 有局限性，只能看ext类文件系统 2.9、挂载和卸载文件系统 2.9.1、mount mount # 将显示当前已挂载信息 mount [-t 欲挂载文件系统类型 ] [-o 特殊选项] 设备名 挂载目录选项说明： -a 将/etc/fstab文件里指定的挂载选项重新挂载一遍。 -t 支持ext2/ext3/ext4/vfat/fat/iso9660(光盘默认格式)。 不用-t时默认会调用blkid来获取文件系统类型。 -n 不把挂载记录写在/etc/mtab文件中，一般挂载会在/proc/mounts中记录下挂载信息，然后同步到/etc/mtab，指定-n表示不同步该挂载信息。 -o 指定挂载特殊选项。下面是两个比较常用的： loop 挂载镜像文件，如iso文件 ro 只读挂载 rw 读写挂载 auto 相当于mount -a dev 如果挂载的文件系统中有设备访问入口则启用它，使其可以作为设备访问入口 default rw,suid,dev,exec,auto,nouser,async,and relatime async 异步挂载，只写到内存 sync 同步挂载，通过挂载位置写入对方硬盘 atime 修改访问时间，每次访问都修改atime会导致性能降低，所以默认是noatime noatime 不修改访问时间，高并发时使用这个选项可以减少磁盘IO nodiratime 不修改文件夹访问时间，高并发时使用这个选项可以减少磁盘IO exec/noexec 挂载后的文件系统里的可执行程序是否可执行，默认是可以执行exec， 优先级高于权限的限定 remount 重新挂载，此时可以不用指定挂载点。 suid/nosuid 对挂载的文件系统启用或禁用suid，对于外来设备最好禁用suid _netdev 需要网络挂载时默认将停留在挂载界面直到加载网络了。使用_netdev可以忽略网络正常挂载。如NFS开机挂载。 user 允许普通用户进行挂载该目录，但只允许挂载者进行卸载该目录 users 允许所有用户挂载和卸载该目录 nouser 禁止普通用户挂载和卸载该目录，这是默认的，默认情况下一个目录不指定user/users时，将只有root能挂载 2.9.2、挂载光盘 2.9.3、重新挂载 2.9.4、挂载windows的共享目录 ​ win上共享文件的文件系统是cifs类型，要在Linux上挂载，必须得有mount.cifs命令，如果没有则安装cifs-utils包。 ​ 新版本的win10注意事项。smb是2.0版本，要指定一下： ​ 旧版本就这样执行吧 2.9.5、基于ssh挂载远程目录。 参考：https://www.cnblogs.com/f-ck-need-u/p/9104950.html 2.9.6、查看某个是否是挂载点mountpoint 文件系统需要驱动支持：没有驱动系统也无法挂载 2.9.7、直接挂载镜像文件 2.9.8、卸载 umount /mnt ​ 如果用户正在访问某个目录或文件，使得卸载一直显示Busy，使用fuser -v DIR可以知道谁正在访问该目录或文件。 ​ 使用-k选项kill掉正在使用目录或文件的进程，使用-km选项kill掉文件系统上的所有进程，然后再umount。 2.9.9、写入/etc/fstab实现开机自动挂 一定要执行mount -a测试fstab有没有问题 ​ 其中最后两列，它们分别表示备份文件系统和开机自检，一般都可以设置为0。 ​ 由于能用的备份工具众多，没人会在这里设置备份，所以备份列设置为0。 ​ 最后一列是开机自检设置列，开机自检调用的是fsck程序，所有有些ext类文件系统作为&quot;/&quot;时，可能会设置为1，但是fsck是不支持xfs文件系统的，所以对于xfs文件系统而言，该项必须设置为0。 其实无需考虑那么多，直接将这两列设置为0就可以了。 2.9.10、修复错误的/etc/fstab 单用户模式重新挂根 2.9.11、按需自动挂 安装autofs 使用autofs实现需要挂载时就挂载，不需要挂载时5分钟后自动卸载。但是在实际环境中基本不会使用按需挂载。 autofs是一个服务程序，需要让其运行在后台，可以用来挂NFS，也可挂本地的文件系统。 默认不装autofs，需要自己装。 autofs实现按需挂载的方式是指定监控目录，可在其配置文件/etc/auto.master中指定。 /etc/auto.master里面只有两列：第一列是监控目录；第二列是记录挂载选项的文件，该文件可以随便取名。 上述监控的/share目录，其实这是监控的父目录，在此目录下的目录如/share/data目录可以作为挂载点，当访问到/share/data时就被监控到，然后会按照挂载选项将挂载设备挂载到/share/data上。 上述配置中配置的挂载选项文件是/etc/auto.mount，所以建立此文件，写入挂载选项。 该文件有3列： 第一列指定的是在/etc/auto.master指定的/share下的目录/share/data，它是真正的被监控路径，也是挂载点。可使用相对路径data表示/share/data。 第二列是mount的选项，前面使用一个&quot;-&quot;表示，该列可有可无。 第三列是待挂载设备，可以是NFS服务端的共享目录，也可以本地设备。 上面的配置表示当访问到/share/data时，自动使用参数(rw,bg,soft,rsize=32768,wsize=32768)挂载远端192.168.100.61的/data目录到/share/data上。 剩下的步骤就是启动autofs服务。 2.10 swap分区 查看swap free -h 或swapon -s CentOS7的swap的管理 https://blog.51cto.com/14012942/2428343 ","link":"http://quansen88.cn/wen-jian-xi-tong-guan-li/"},{"title":" sed基本用法","content":"sed基本用法 sed面试题：https://blog.51cto.com/14012942/2427099 1、sed介绍 这是sed的一个循环的过程： 读取输入流的一行到模式空间。 对模式空间中的内容进行匹配和处理。 自动输出模式空间内容。 清空模式空间内容。 读取输入流的下一行到模式空间。 (注：(如看不懂，请跳过)如果是读取文件数据，则会每次需要的时候一次性加载一定量(比如多行)的数据到os buffer，然后sed从os buffer中一行一行读取，并不是要读一行就从磁盘文件中加载一行。另外，如果是管道或其它输入流，则直接从对应的缓存中一行一行读取。验证命令：sed ‘p;s/.*/:&gt;filename/e;d’ filename) ​ 上述整个循环过程中，第2步是我们写sed命令所修改的地方，其余的几个步骤，通过命令行无法改变。但是，sed有几个命令和选项能改变第3、4步的行为，使其输出总是输出空内容或无法清空模式空间。 如果使用编程结构来描述，则大致过程如下： ​ 其中while循环执行的正是SCRIPT中的所有命令，只不过一般情况下，while循环只执行一轮就退出并进入外层的for循环。于是，外层的for循环称之为&quot;sed循环&quot;，内层的while循环称之为&quot;SCRIPT&quot;循环。所以，for循环只包含了两个动作：读取下一行和执行SCRIPT循环。 ​ 其实while循环中是有continue、break甚至是exit的，分别表示回到SCRIPT的顶端(即进入下一个SCRIPT循环)、退出当前SCRIPT循环回到外层sed循环以及退出整个sed循环。显然，这不是&quot;花拳绣腿&quot;的内容。 ​ 最后，说明下sed命令行如何书写，其实就是写SCRIPT部分，这部分的写法比较灵活，大致有以下几种： ​ 如果是写在文件中，即sed脚本，以文件名为a.sed为例。 ​ 其中cmd部分还可以进行模式匹配，也即类似于&quot;Address{{pattern1}cmd1;{pattern2}cmd2}&quot;的写法。例如， /^abc/{2d;p} 。 ​ 有了以上基本的大纲性知识，理解和深入sed机制就简单多了。 2、sed选项 sed选项不算多，能用到的更没几个。 可能用到的几个选项： '-n' 默认情况下，sed将在每轮script循环结束时自动输出模式空间中的内容。使用该选项后可以使得这次自动输出动作输出空内容，而不是当前模式空间中的内容。注意，&quot;-n&quot;是输出空内容而不是禁用输出动作，虽然两者的结果都是不输出任何内容，但在有些依赖于输出动作和输出流的地方，它们的区别是很大的，前者有输出流，只是输出空流，后者则没有输出流。 '-e SCRIPT' 前文说了，SCRIPT中包含的是命令的集合，&quot;-e&quot;选项就是向SCRIPT中添加命令的。可以省略&quot;-e&quot;选项，但如果命令行容易产生歧义，则使用&quot;-e&quot;选项可明确说明这部分是SCRIPT中的命令。另外，如果一个&quot;-e&quot;选项不方便描述所需命令集合时，可以指定多个&quot;-e&quot;选项。 '-f SCRIPT-FILE' 指定包含命令集合的SCRIPT文件，让sed根据SCRIPT文件中的命令集处理输入流。 '-i[SUFFIX]' 该选项指定要将sed的输出结果保存(覆盖的方式)到当前编辑的文件中。GNU sed是通过创建一个临时文件并将输入写入到该临时文件，然后重命名为源文件来实现的。 当当前输入流处理结束后，临时文件被重命名为源文件的名称。如果还提供了SUFFIX，则在重命名临时文件之前，先使用该SUFFIX修改源文件名，从而生成一个源文件的备份文件。 临时文件总是会被重命名为源文件名称，也就是说输入流处理结束后，仍使用源文件名的文件是sed修改后的文件。文件名中包含了SUFFIX的文件则是最原始文件的备份。例如源文件为a.txt，sed -i'.log' SCRIPT a.txt将生成两个文件：a.txt和a.txt.log，前者是sed修改后的文件，a.txt.log是源a.txt的备份文件。 重命名的规则如下：如果扩展名不包含符号&quot;&quot;，将SUFFIX添加到原文件名的后面当作文件后缀；如果SUFFIX中包含了一个或多个字符&quot;&quot;，则每个&quot;*&quot;都替换为原文件名。这使得你可以为备份文件添加一个前缀，而不是后缀。如果没有提供SUFFIX，源文件被覆盖，且不会生成备份文件。 该选项隐含了&quot;-s&quot;选项。 '-r' 使用扩展正则表达式，而不是使用默认的基础正则表达式。sed所支持的扩展正则表达式和egrep一样。使用扩展正则表达式显得更简洁，因为有些元字符不用再使用反斜线&quot;&quot;。正则表达式见grep命令中文手册。 '-s' 默认情况下，如果为sed指定了多个输入文件，如sed OPTIONS SCRIPT file1 file2 file3，则多个文件会被sed当作一个长的输入流，也就是说所有文件被当成一个大文件。指定该选项后，sed将认为命令行中给定的每个文件都是独立的输入流。 既然是独立的输入流，范围定址(如/abc/,/def/)就无法跨越多个文件进行匹配，行号也会在处理每个文件时重置，&quot;$&quot;代表的也将是每个文件的最后一行。这也意味着，如果不使用该选项，则这几个行为都是可以完成的。 示例：以sed命令&quot;p&quot;和&quot;=&quot;为例，其中&quot;p&quot;命令用于强制输出当前模式空间中的内容，&quot;=&quot;命令用于输出sed行号计数器当前的值，即刚被读入到模式空间中的行是输入流中的第几行。 (1).只输出a.txt中的第5行。 这里使用了&quot;-n&quot;选项，使得读取到模式空间的每一行都无法被输出，只有明确使用了&quot;p&quot;选项才能被&quot;p&quot;动作输出。由于只有读入的第5行内容能匹配&quot;5&quot;，才能被&quot;p&quot;输出。 其实上面的命令和sed -n -e '5p' a.txt是完全一样的，因为&quot;5p&quot;在sed解析命令行时不会产生歧义，所以可以省略&quot;-e&quot;选项。 (2).输出a.txt，并输出每行的行号。 由于要输出a.txt的内容，所以不使用&quot;-n&quot;选项，同时&quot;=&quot;命令会输出每行行号。 (3).分别输出a.txt和b.txt的第5行，并分别保存到&quot;.bak&quot;后缀的文件中。 此处必须使用&quot;-s&quot;选项，否则将只会输出&quot;a.txt+b.txt&quot;结合后的第5行。但&quot;-i&quot;隐含了&quot;-s&quot;选项。这会生成4个文件：a.txt、b.txt和a.txt.bak、b.txt.bak。前两个是第5行内容，后两个是源文件的备份文件。 (4).使用扩展正则表达式，输出a.txt和b.txt中能包含3个以上字母&quot;a&quot;的行。 3、定址表达式 当sed将输入流中的行读取到模式空间后，就需要对模式空间中的内容进行匹配，如果能匹配就能执行对应的命令，如果不能匹配就直接输出、清空模式空间并进入下一个sed循环读取下一行。 匹配的过程称为定址。定址表达式有多种，但总的来说，其格式为[ADDR1][,ADDR2]。这可以分为3种方式： ADDR1和ADDR2都省略时，表示所有行都能被匹配上。 省略ADDR2时，表示只有被ADDR1表达式匹配上的行才符合条件。 不省略ADDR2时，是范围地址。表示从ADDR1匹配成功的行开始，到ADDR2匹配成功的行结束。 无论是ADDR1还是ADDR2，都可以使用两种方式进行匹配：行号和正则表达式。如下： 'N' 指定一个行号，sed将只匹配该行。(需要注意，除非使用了&quot;-s&quot;或&quot;-i&quot;选项，sed将对所有输入文件的行连续计数。) 'FIRST~STEP' 表示从第FIRST行开始，每隔STEP行就再取一次。也就是取行号满足FIRST+(N*STEP) (其中N&gt;=0)的行。因此，要选择所有奇数行，使用&quot;12&quot;；要从第2行开始每隔3行取一次，使用&quot;23&quot;；要从第10行开始每隔5行取一次，使用&quot;105&quot;；而&quot;500&quot;则表示只取第50行。 '$' 默认该符号匹配的是最后一个文件的最后一行，如果指定了&quot;-i&quot;或&quot;-s&quot;，则匹配的是每个文件的最后一行。总之，&quot;$&quot;匹配的是每个输入流的最后一行。 需要注意的是，**sed采用行号计数器来临时记录当前行的行号，因此sed在读取到最后一行前即使是倒数第二行的时候，完全不知道最后一行是第几行，所以代表最后一行的&quot;&quot;无法进行任何数学运算∗∗，例如倒数第二行使用&quot;&quot;无法进行任何数学运算**，例如倒数第二行使用&quot;&quot;无法进行任何数学运算∗∗，例如倒数第二行使用&quot;-1&quot;表示是错误的。而且，&quot;&quot;只是一个额外的标记符号，当sed读取到输入流的最后一行时，发现这就是最后一行，于是为此行打上&quot;&quot;只是一个额外的标记符号，当sed读取到输入流的最后一行时，发现这就是最后一行，于是为此行打上&quot;&quot;只是一个额外的标记符号，当sed读取到输入流的最后一行时，发现这就是最后一行，于是为此行打上&quot;&quot;记号，并读取到模式空间中。 '/REGEXP/' 将选择能被正则表达式REGEXP匹配的所有行。如果REGEXP中自身包含了字符&quot;/&quot;，则必须使用反斜线转义，即&quot;\\/&quot;。 '/REGEXP/I' 和&quot;/REGEXP/&quot;是一样的，只不过匹配的时候不区分大小写。 '\\%REGEXP%' ('%'可以使用其他任意单个字符替换。) 这和上一个定址表达式的作用是一样的，只不过是使用符号&quot;%&quot;替换了符号&quot;/&quot;。当REGEXP中包含&quot;/&quot;符号时，使用该定址表达式就无需对&quot;/&quot;使用反斜线&quot;&quot;转义。但如果此时REGEXP中包含了&quot;%&quot;符号时，该符号需要使用&quot;&quot;转义。 总之，定址表达式中使用的分隔符在REGEXP中出现时，都需要使用反斜线转义。 'ADDR1,+N' 匹配ADDR1和其后的N行。 'ADDR1,~N' 匹配ADDR1和其后的行直到出现N的倍数行。倍数可为随意整数倍，只要N的倍数是最接近且大于ADDR1的即可。 如ADDR1=1,N=3匹配1-3行，ADDR1=5,N=4匹配5-8行。而&quot;1,+3&quot;匹配的是第一行和其后的3行即1-4行。 另外，在定址表达式的后面加&quot;!&quot;符号表示反转匹配的含义。也就是说那些匹配的行将不被选择，而是不匹配的行被选择。 例如，以下几个定址的示例： 4.sed常用命令 sed命令很多，本文的只简单介绍几个最常见的。 此处不以命令的用法为重，而是通过这几个命令，引出sed最重要的原理和执行机制(还包括本文的第一节内容)，并为阅读下一篇文章sed武功心法：info sed打下基础。而且理解了这些原理，再使用sed做任何操作都有理可循，遇到疑难之处也知道如何进行分析。而这，是任何书籍(包括广为推崇的sed &amp;&amp; awk)、教学视频和网络文章中都没有的内容(至少我从未见过，这些内容也是我花费大量精力经过大量实验推演出来)。 (1).强制输出命令&quot;p&quot;。 该命令能强制输出当前模式空间的内容。即使使用了&quot;-n&quot;选项。 事实上，它们本就不冲突，因为循环过程如下： 在sed处理的过程中，&quot;p&quot;和&quot;auto_print&quot;是两个输出动作，都是输出当前模式空间的内容，只不过auto_print是隐含动作。使用了&quot;-n&quot;选项，其所影响的动作仅是&quot;auto_print&quot;，使其输出空内容。也因此，当没有使用&quot;-n&quot;选项时，模式空间的内容会被输出两次。 例如，仅输出标准输入的第2行内容。 不加&quot;-n&quot;选项，在&quot;p&quot;输出之后，SCRIPT循环的结尾处还会被auto_print输出一次。 (2).删除命令&quot;d&quot;。 命令&quot;d&quot;用于删除整个模式空间中的内容，并立即退出当前SCRIPT循环，进入下一个sed循环，即读取下一行。 循环大致格式如下: 唯一需要注意的一点是立即退出当前SCRIPT循环，这意味着如果&quot;d&quot;命令后面还有其他的命令，则这些命令都不会执行。 例如：删除a.txt中的第5行，并保存到原文件中。 这里不能使用重定向的方式保存，因为重定向是在sed命令执行前被shell执行的，所以会截断a.txt，使得sed读取的输入流为空，或者结果出乎意料之外。而&quot;-i&quot;选项则不会操作原文件，而是生成临时文件并在结束时重命名为原文件名。 删除a.sh中包含&quot;#&quot;开头的注释行，但第一行的#!/bin/bash不删除。 如果&quot;d&quot;后面还有命令，在删除模式空间后，这些命令不会执行，因为会立即退出当前SCRIPT循环。例如： 其中&quot;=&quot;这个命令用于输出行号，但是结果并没有输出被&quot;abc&quot;匹配的行的行号。 (3).退出sed程序命令&quot;q&quot;和&quot;Q&quot;。 使用&quot;q&quot;和&quot;Q&quot;命令的作用是立即退出当前sed程序，使其不再执行后面的命令，也不再读取后面的行。因此，在处理大文件或大量文件时，使用&quot;q&quot;或&quot;Q&quot;命令能提高很大效率。它们之间的不同之处在于&quot;q&quot;命令被执行后还会使用自动输出动作输出模式空间的内容，除非使用了&quot;-n&quot;选项。而&quot;Q&quot;命令则会立即退出，不会输出模式空间内容。另外，可以为它们指定退出状态码，例如&quot;q 1&quot;。 使用了&quot;q&quot;和&quot;Q&quot;的sed循环结构大致如下： 例如，搜索脚本a.sh，当搜索到使用了&quot;.&quot;或&quot;source&quot;命令加载环境配置脚本时就输出并立即退出。 (4).输出行号命令&quot;=&quot;。 &quot;=&quot;命令用于输出最近被读取行的行号。在sed内部，使用行号计数器进行行号计数，每读取一行，行号计数器加1。计数器的值存储在内存中，在要求输出行号时，直接插入在输出流中的指定位置。由于值是存在于内存中，而非模式空间中，因此不受&quot;-n&quot;选项的影响。 这是一个依赖于输出流的命令，只要有输出动作就会追加在该输出流的尾部。 例如，搜索出httpd.conf中&quot;DocumentRoot&quot;开头的行的行号，允许有前导空白字符。 如果&quot;=&quot;命令前没有&quot;p&quot;输出命令，且没有使用&quot;-n&quot;选项，则是输出在Document所在行的前一行，因为SCRIPT最后的自动输出动作也有输出流。 (5).字符一一对应替换命令&quot;y&quot;。 该命令和&quot;tr&quot;命令的映射功能一样，都是将字符进行一一替换。 例如，将a.txt中包含大写字母的YES、Yes等替换成小写的yes。 (6).手动读取下一行命令&quot;n&quot;。 在sed的循环过程中，每个sed循环的第一步都是读取输入流的下一行到模式空间中，这是我们无法控制的动作。但sed有读取下一行的命令&quot;n&quot;。 由于是读取下一行，所以它会触发自动输出的动作，于是就有了输出流。不仅如此，还应该记住的是：只要有读取下一行的行为，在其真正开始读取之前一定有隐式自动输出的行为。 但需注意，当没有下一行可供&quot;n&quot;读取时(例如文件的最后一行已经被读取过了)，将输出模式空间内容后直接退出sed程序，使得&quot;n&quot;命令后的所有命令都不会执行，即使是那两个隐含动作。 相应的循环结构如下： 注意，是先判断是否有下一行可读取，再输出和清空pattern space中的内容，所以then和else语句中都有这两个动作。 也许感觉上似乎更应该像下面这样的优化形式： 但事实证明并非如此，证明过程在本文结尾。此处暂不讨论这些复杂的东西，先看看&quot;n&quot;命令的示例。 例如，搜索a.txt中包含&quot;redirect&quot;字符串的行以及其下一行，并输出。 再例如下面的命令。 从结果中可以分析出，&quot;n&quot;读取下一行前输出了&quot;abc&quot;，然后立即读入了下一行，所以输出的行号是2而不是1，因为这时候行号计数器已经读取了下一行，随后命令&quot;p&quot;输出了该模式空间的内容，输出后还有一次自动输出的隐含动作，所以&quot;def&quot;被输出了两次。 (7).替换命令&quot;s&quot;。 这是sed用的最多的命令。两个字就能概括其功能：替换。将匹配到的内容替换成指定的内容。 &quot;s&quot;命令的语法格式为：其中&quot;/&quot;可以替换成任意其他单个字符。 它使用REGEXP去匹配行，将匹配到的那部分字符替换成REPLACEMENT。FLAGS是&quot;s&quot;命令的修饰符，常见的有&quot;g&quot;、&quot;p&quot;和&quot;i&quot;或&quot;I&quot;。 &quot;g&quot;：表示替换行中所有能被REGEXP匹配的部分。不使用g时，默认只替换行中的第一个匹配内容。此外，&quot;g&quot;还可以替换成一个数值N，表示只替换行中第N个被匹配的内容。 &quot;p&quot;：输出替换后模式空间中的内容。 &quot;i&quot;或&quot;I&quot;：REGEXP匹配时不区分大小写。 REPLACEMENT中可以使用&quot;\\N&quot;(N是从1到9的整数)进行后向引用，所代表的是REGEXP第N个括号(...)中匹配的内容。另外，REPLACEMENT中可以包含未转义的&quot;&amp;&quot;符号，这表示引用pattern space中被匹配的整个内容。需要注意，&quot;&amp;&quot;是引用pattern space中的所有匹配，不仅仅只是括号的分组匹配。 例如，删除a.sh中所有&quot;#&quot;开头(可以包括前导空白)的注释符号&quot;#&quot;，但第一行&quot;#!/bin/bash&quot;不处理。 为a.sh文件中的第5行到最后一行的行首加上注释符号&quot;#&quot;。 将a.sh中所有的&quot;int&quot;单词替换成&quot;SIGINT&quot;。 将a.sh中&quot;cmd1 &amp;&amp; cmd2 || cmd3&quot;的cmd2和cmd3命令对调个位置。 这里使用了&quot;%&quot;代替&quot;/&quot;，且在REPLACEMENT部分对&quot;&amp;&quot;进行了转义，因为该符号在REPLACEMENT中时表示的是引用REGEXP所匹配的所有内容。 (8).追加、插入和修改命令&quot;a&quot;、&quot;i&quot;、&quot;c&quot;。 这3个命令的格式是&quot;[a|i|c] TEXT&quot;，表示将TEXT内容队列化到内存中，当有输出流或者说有输出动作的时候，半路追上输出流，分别追加、插入和替换到该输出流然后输出。追加是指追加在输出流的尾部，插入是指插入在输出流的首部，替换是指将整个输出流替换掉。&quot;c&quot;命令和&quot;a&quot;、&quot;i&quot;命令有一丝不同，它替换结束后立即退出当前SCRIPT循环，并进入下一个sed循环，因此&quot;c&quot;命令后的命令都不会被执行。 例如： 其实&quot;a&quot;、&quot;i&quot;和&quot;c&quot;命令的TEXT部分写法是比较复杂的，如果TEXT只是几个简单字符，如上即可。但如果要TEXT是分行文本，或者包含了引号，或者这几个命令是写在&quot;{}&quot;中的，则上面的写法就无法实现。需要使用符号&quot;&quot;来转义行尾符号，这表示开启一个新行，此后输入的内容都是TEXT，直到遇到引号或者&quot;;&quot;开头的行时。 例如，在a.sh的#!/bin/bash行后添加一个注释行&quot;# Script filename: a.sh&quot;以及一个空行。由于是追加在尾部，所以使用&quot;a&quot;命令。 &quot;a&quot;命令后的第一个反斜线用于标记TEXT的开始，&quot;\\n&quot;用于添加空白行。如果分行写，或者&quot;a&quot;命令写在大括号&quot;{}&quot;中，则格式如下： 最后需要说的是，这3个命令的TEXT是存放在内存中的，不会进入模式空间，因此不受&quot;-n&quot;选项或某些命令的影响。此外，这3个命令依赖于输出流，只要有输出动作，不管是空输出流还是非空的输出流，只要有输出，这几个命令就会半路&quot;劫杀&quot;。如果不理解这两句话，这3个命令的结果有时可能会比较疑惑。 例如，&quot;a&quot;命令是追加在当前匹配行行尾的，但为什么下面的&quot;haha&quot;却插入到匹配行&quot;def&quot;的前面去了呢？ 阅读了下面的&quot;N&quot;命令之后，再回头看这个示例，应该能知道为什么。在sed修炼系列(四)：sed中的疑难杂症中给出了解释。 (9).多行模式命令&quot;N&quot;、&quot;D&quot;、&quot;P&quot;简单说明。 在前面已经解释了&quot;n&quot;、&quot;d&quot;和&quot;p&quot;命令，sed还支持它们的大写命令&quot;N&quot;、&quot;D&quot;和&quot;P&quot;。 &quot;N&quot;命令：读取下一行内容追加到模式空间的尾部。其和&quot;n&quot;命令不同之处在于：&quot;n&quot;命令会输出模式空间的内容(除非使用了&quot;-n&quot;选项)并清空模式空间，然后才读取下一行到模式空间，也就是说&quot;n&quot;命令虽然读取了下一行到模式空间，但模式空间仍然是单行数据。而&quot;N&quot;命令在读取下一行前，虽然也有自动输出和清空模式空间的动作，但该命令会把当前模式空间的内容锁住，使得自动输出的内容为空，也无法清空模式空间，然后读取下一行追加到当前模式空间中的尾部。追加时，原有内容和新读取内容使用换行符&quot;\\n&quot;分隔，这样在模式空间中就实现了多行数据。即所谓的&quot;多行模式&quot;。 另外，当无法读取到下一行时(到了文件尾部)，将直接退出sed程序，使得&quot;N&quot;命令后的命令不会再执行，这和&quot;n&quot;命令是一样的。 &quot;D&quot;命令：删除模式空间中第一个换行符&quot;\\n&quot;之前的内容，然后立即回到SCRIPT循环的顶端，即进入下一个SCRIPT循环。如果&quot;D&quot;删除后，模式空间中已经没有内容了，则SCRIPT循环自动退出进入下一个sed循环；如果模式空间还有剩余内容，则继续从头执行SCRIPT循环。也就是说，&quot;D&quot;命令后的命令不会被执行。 &quot;P&quot;命令：输出模式空间中第一个换行符&quot;\\n&quot;之前的内容。 &quot;N&quot;、&quot;D&quot;和&quot;P&quot;命令作用非常大，它们是绝佳的组合命令，因为借助它们能实现&quot;窗口滑动&quot;技术，这对于复杂的文本行操作来说大有裨益。但显然，这不是本文的内容，在sed修炼系列(三)：sed高级应用之实现窗口滑动技术中详细说明了这3个命令的功能。 此处按照惯例，还是给出它们的大致循环结构：其中&quot;N&quot;命令的if判断和前文的&quot;n&quot;一样，在本文结尾证明。 (10).buffer空间数据交换命令&quot;h&quot;、&quot;H&quot;、&quot;g&quot;、&quot;G&quot;、&quot;x&quot;简单说明。 sed除了维护模式空间(pattern space)，还维护另一个buffer空间：保持空间(hold space)。这两个空间初始状态都是空的。 绝大多数时候，sed仅依靠模式空间就能达到目的，但有些复杂的数据操作则只能借助保持空间来实现。之所以称之为保持空间，是因为它是暂存数据用的，除了仅有的这几个命令外，没有任何其他命令可以操作该空间，因此借助它能实现数据的持久性。 保持空间的作用很大，它和模式空间之间的数据交换能实现很多看上去不能实现的功能，是实现sed高级功能所必须的，例如&quot;窗口滑动&quot;。同样，这不是本文的内容。所以只简单解释这几个命令的作用： &quot;h&quot;命令：将当前模式空间中的内容覆盖到保持空间。 &quot;H&quot;命令：在保持空间的尾部加上一个换行符&quot;\\n&quot;，并将当前模式空间的内容追加到保持空间的尾部。 &quot;g&quot;命令：将保持空间的内容覆盖到当前模式空间。 &quot;G&quot;命令：在模式空间的尾部加上一个换行符&quot;\\n&quot;，并将当前保持空间的内容追加到模式空间的尾部。 &quot;x&quot;命令：交换模式空间和保持空间的内容。 注意，无论是交换、追加还是覆盖，原空间的内容都不会被删除。 转载自https://www.cnblogs.com/f-ck-need-u/p/7488469.html ","link":"http://quansen88.cn/sed-ji-ben-yong-fa/"},{"title":"CentOS7的swap分区管理（分区或文件）","content":"CentOS7的swap分区管理（分区或文件） 1、swap可以在安装操作系统的时候划分单独分区创建；也可以安装好操作系统后划分剩余硬盘创建；还可以创建一个文件当swap分区使用 2、建议创建一个新的分区当swap使用，如果想使用一个文件当swap分区用的话最好将文件放在固态硬盘上，使用文件充当swap的话可以随意变大变小，移动也方便，但性能不如分区好 创建分区来划分swap 一、使用free -h查看当前swap 当前系统有4G的swap空间 使用swapon -s显示当前系统的swap 二、使用lsblk查看当前系统的硬盘 可以看到，sda总共200G，现在才划分了150多G，还有可以用的空间 三、使用fdisk对/dev/sda硬盘进行创建分区操作 四、执行两下partprobe(CentOS6执行part /dev/sda -a) 五、创建文件系统 六、写入/etc/fstab，并mount -a测试 七、swapon -a 此时执行free -h，swap分区还没显示出来，执行swapon -a，启用所有swap 八、卸载这个swap 创建一个文件充当swap分区 一、使用dd命令创建一个文件100M，当swap用 二、对该文件创建文件系统 三、写入/etc/fstab,挂载（这里要注意，挂载设备不能写UUID，只能写文件名） 四、执行swapon -a 开启所有swap 五、增大swap，需要先取消挂载 六、卸载 ","link":"http://quansen88.cn/centos7-de-swap-fen-qu-guan-li-fen-qu-huo-wen-jian/"},{"title":"MBR分区表的备份与还原","content":"MBR分区表的备份与还原 MBR分区的存储 从下图可以看出，MBR分区前446字节是boot loader；接下来64字节是分区表；再然后就是三个主分区加一个拓展分区。 一、备份分区表，要跳过前446字节 二、发送分区表到另一个机器上（鸡蛋要放在不同的篮子里） 三、使用zero设备抹掉sda的分区表，要跳过前446字节，前446字节是bootloder bootloader都长得差不多，可以从同一批机器里恢复，如果抹掉了的话分区表不行 此时服务器一关机就开不了了： 四、光盘启动开始救援 可以参考这篇文章进入救援界面：https://blog.51cto.com/14012942/2426097 4.1、此时的救援模式没网，需要手动配个Ip把分区表scp过来 没网 临时手动配个IP,把分区表scp过来 4.2、lsblk查看下系统的硬盘名字，看到是sda 4.3、使用dd命令恢复，要跳过前446字节 4.4、查看下sda的前512字节 4.5、exit重启 五、救援成功 ","link":"http://quansen88.cn/mbr-fen-qu-biao-de-bei-fen-yu-huan-yuan/"},{"title":"手动编译httpd-2.4.25","content":"手动编译httpd-2.4.25 系统：CentOS7.1810 httpd：2.4.25 编译时报错解决技巧：报什么错，就装这个错误的devel，比如报http2错误，就yum search http2，找到libnghttp2-devel，然后yum install libnghttp2-devel再重新configure 一、下载地址： https://www.lanzous.com/i5csh0h http://archive.apache.org/dist/httpd/httpd-2.4.25.tar.bz2 二、安装依赖 三、解压 四、开始编译 五、根据Makefile，构建应用程序 六、make install 七、启动apache 可以考虑加PATH变量或做软链接 八、测试访问 主页内容：/apps/httpd24/htdocs/index.html 九、让httpd开机自启 ","link":"http://quansen88.cn/shou-dong-bian-yi-httpd-2425/"},{"title":"黑客屏幕cmaxtix编译安装","content":"黑客屏幕cmaxtix编译安装 系统：CentOS7 1810 软件：cmatrix-1.2 效果： 一、下载： https://www.lanzous.com/i5ct2ng 二、解压 [root@imooc-nginx ~]# tar xf cmatrix-1.2a.tar.gz 三、安装依赖 三、编译安装 五、执行命令 ","link":"http://quansen88.cn/hei-ke-ping-mu-cmaxtix-bian-yi-an-zhuang/"},{"title":"更新说明","content":"说明文档 来自：http://bbs.wuyou.net/forum.php?mod=viewthread&amp;tid=370573 本系统涵盖了MS公司自WinXP后发布主要系统，包括：WinXP/Win2003/Win7/Win8(32+64)/Win8.1(32+64)/Win10(32+64)，各系统共享外置工具和部分驱动程序；含多种介质启动方式：硬盘、光盘、USB盘（UD/U+/UDM）、网启（PXE/iPXE）；多种启动软件启动方式：MS(BIOS+EFI)、Grub4Dos、Syslinux、EasyBoot、Grub2(BIOS+EFI)、rEfind、xorboot；多种应用模式分层加载：第一层：内核层--&gt;第二层：系统维护层--&gt;第三层：网络应用层--&gt;第四层：影音娱乐游戏办公层，附加层：用户自定制层，进入桌面后可按需升级或降级应用层次。应用超多，体积巨大，确是一艘PE航母！ 本系统所含PE有各自不能被其他完全替代的特点： 项目 登录形式 内置网络驱动 桌面菜单样式 EFI****支持 磁盘驱动 网启支持 WIM****新驱动选择 应用特点 Win03PE PE（SYSTEM） No MS传统菜单 No 多 仅PXE No 一般维护等 非RAMXPPE PE（SYSTEM） No MS传统菜单 No 少 No No 最低可64M内存启动 Native 03PE PE（SYSTEM） No MS传统菜单 No 少 仅PXE No USB慢速机 全内置03PE PE（SYSTEM） Yes（手动） MS传统菜单 No 中 仅PXE（能装服务器外置） No 启动后可拔掉启动设备，也可作网启工作站 Win7PE PE（SYSTEM） Yes（手动） MS传统菜单 No 系统自带 (i)PXE（能装服务器外置） Yes 新老机维护，但WIM老驱动在位于只读媒体时有小问题 Win8PE(含64) PE（SYSTEM） No MS Win7菜单 Yes(32+64) 系统自带 (i)PXE Yes 新机安装维护，无网驱体积较小，载入较快。网络不驱动防火墙，方便做网启服务器 Win8.1PE(含64) RAMOS（Administrator） Yes（自动） MS Metro菜单（可切换到StartisBack） Yes(32+64) 系统自带 (i)PXE（能装服务器外置） Yes 新机安装维护应用，内置网卡自动启动，方便作网启工作站。如果作网启服务器，由于网络驱动防火墙，NT5与其连接不便。（64位含bitlocker组件） Win10PE(含64) PE（SYSTEM） Yes（自动） StartisBack Yes(32+64) 系统自带 (i)PXE（能装服务器外置） Yes 新机安装维护，内置网卡自动启动，方便作网启工作站。如果作网启服务器，由于网络驱动防火墙，NT5与其连接不便。 本系统应该从07年开始制作，生命不息，更新不止。本次开一个新帖来发布新的系统，新的系统将含有最新的Win10PE，老的不含Win10PE系统的版本可以到：http://bbs.wuyou.net/forum.php?m ... 6576&amp;extra=page%3D2去查询。 系统定位： 1、系统维护：系统安装恢复、数据救援、故障排查等； 2、系统替代：临时代替系统使用或移动办公； 3、PE研究制作：制作打包、工具测试、各种启动方式等 4、硬件测试：测试硬件对平台适应性及表现。 最新引用成果： PECMD的开发者mdyblog的PECMD工具及示例代码、slore的MTP HOOK工具、sp_star 的winbuilder制作脚本、红毛樱木/2012qnmd /yaojy等对Win10PE的研究、sinoxer定制的IQI工具、notepad/addaadda等对OFC2007的研究、527104427等关于挂载的研究、yamingw大侠对于驱动装载核心组件drvinst破解及Win10MTP驱动级拦截的研究...........这只是近期的，加上以前的太多了，没办法列举了！感谢论坛中为PE发展做出各种努力的无忧网友们！也对自己一直以来制作PE的热情点个赞！ 希望大家继续保持热情，我分享故我快乐！ 本帖最后由 hhh333 于 2019-7-18 15:09 编辑 H3多启多模集成PE系统 本系统涵盖了MS公司自WinXP后发布主要系统，包括：WinXP/Win2003/Win7/Win8(32+64)/Win8.1(32+64)/Win10(32+64)，各系统共享外置工具和部分驱动程序；含多种介质启动方式：硬盘、光盘、USB盘（UD/U+/UDM）、网启（PXE/iPXE）；多种启动软件启动方式：MS(BIOS+EFI)、Grub4Dos、Syslinux、EasyBoot、Grub2(BIOS+EFI)、rEfind、xorboot；多种应用模式分层加载：第一层：内核层--&gt;第二层：系统维护层--&gt;第三层：网络应用层--&gt;第四层：影音娱乐游戏办公层，附加层：用户自定制层，进入桌面后可按需升级或降级应用层次。应用超多，体积巨大，确是一艘PE航母！ 本系统所含PE有各自不能被其他完全替代的特点： 项目登录形式内置网络驱动桌面菜单样式EFI支持磁盘驱动网启支持WIM新驱动选择应用特点Win03PEPE（SYSTEM）NoMS传统菜单No多仅PXENo一般维护等非RAMXPPEPE（SYSTEM）NoMS传统菜单No少NoNo最低可64M内存启动Native 03PEPE（SYSTEM）NoMS传统菜单No少仅PXENoUSB慢速机全内置03PEPE（SYSTEM）Yes（手动）MS传统菜单No中仅PXE（能装服务器外置）No启动后可拔掉启动设备，也可作网启工作站Win7PEPE（SYSTEM）Yes（手动）MS传统菜单No系统自带(i)PXE（能装服务器外置）Yes新老机维护，但WIM老驱动在位于只读媒体时有小问题Win8PE(含64)PE（SYSTEM）NoMS Win7菜单Yes(32+64)系统自带(i)PXEYes新机安装维护，无网驱体积较小，载入较快。网络不驱动防火墙，方便做网启服务器Win8.1PE(含64)RAMOS（Administrator）Yes（自动）MS Metro菜单（可切换到StartisBack）Yes(32+64)系统自带(i)PXE（能装服务器外置）Yes新机安装维护应用，内置网卡自动启动，方便作网启工作站。如果作网启服务器，由于网络驱动防火墙，NT5与其连接不便。（64位含bitlocker组件）Win10PE(含64)PE（SYSTEM）Yes（自动）StartisBackYes(32+64)系统自带(i)PXE（能装服务器外置）Yes新机安装维护，内置网卡自动启动，方便作网启工作站。如果作网启服务器，由于网络驱动防火墙，NT5与其连接不便。 本系统应该从07年开始制作，生命不息，更新不止。本次开一个新帖来发布新的系统，新的系统将含有最新的Win10PE，老的不含Win10PE系统的版本可以到：http://bbs.wuyou.net/forum.php?m ... 6576&amp;extra=page%3D2去查询。 系统定位： 1、系统维护：系统安装恢复、数据救援、故障排查等； 2、系统替代：临时代替系统使用或移动办公； 3、PE研究制作：制作打包、工具测试、各种启动方式等 4、硬件测试：测试硬件对平台适应性及表现。 最新引用成果： PECMD的开发者mdyblog的PECMD工具及示例代码、slore的MTP HOOK工具、sp_star 的winbuilder制作脚本、红毛樱木/2012qnmd /yaojy等对Win10PE的研究、sinoxer定制的IQI工具、notepad/addaadda等对OFC2007的研究、527104427等关于挂载的研究、yamingw大侠对于驱动装载核心组件drvinst破解及Win10MTP驱动级拦截的研究...........这只是近期的，加上以前的太多了，没办法列举了！感谢论坛中为PE发展做出各种努力的无忧网友们！也对自己一直以来制作PE的热情点个赞！ 希望大家继续保持热情，我分享故我快乐！ 2019年7月5日新春第四次修订版 一、内核 1、Win8及以上增加BDESVC和DSMSVC服务，以便实现Bitlocker解锁和USB弹出功能； 2、Win10打印相关CAT文件外置； 3、Win10更换了一个稍大的精简字体以便显示偏僻字； 二、外置 1、修正指定INF文件目录安装驱动时如果该目录有多个INF文件只安装找到的第一个INF文件可能造成安装失败的问题； 2、修正Win8(64与32)打印组件中的错误，并让其共用Win8.1的打印驱动； 3、重新整理驱动总管工具界面，把可以选择安装方式的声、显、网、打印归为驱动类，其他不需要选择安装方式的统一归为组件类，如MTP、BitLocker等； 4、更改打印机安装逻辑，让其可以选择安装方式； 5、更改外置驱动安装逻辑：公共文件统一在启动时安装，其他所有驱动或组件安装时再不对公共文件进行判断和安装； 6、增加设备资源文件：在安装打印机后可以在设备和打印机控制面板中查看以3D图标显示的设备列表； 7、增加Win10的Bitlocker组件； 8、工具更新：7z--&gt;19.0.0、G4D--&gt;20190607、DISM++--&gt;10.1.1000.100、FastCopy--&gt;3.6.3.0、WinNTSetup--&gt;3.9.4；HFS驱动--&gt;6.0.1.0 9、PETOOLS中增加USB3 Drivers Smart Install v2.0.6.3和系统总裁工具，以方便离线注入SRS和USB3驱动； 三、其他 同步提供Win10 1903(18362.175)的全套文件，包括内核和外置，可以撤下更换1709的内核（H3_10PE.WIM、H3_1064.WIM）和外置（DR10、DR1064）。 （看了下UUP18362又有更新，干脆等稳定后再做再放出吧） 下载： 文件:H3CDALL.ISO 大小: 4024438784 字节 修改时间: 2019年7月5日, 8:33:49 MD5: B26EEC02B71F06DE719562D343DE2498 SHA1: 6A170A0748C8AEE13F7871EE675F8501079F6B3D CRC32: BEE2CD2F 链接：https://pan.baidu.com/s/1ON6RA0JTpda-x0Ictrz00A 提取码：wf9l 1903内核的完整版： 文件: H3CDALL.ISO 大小: 4065654784 字节 修改时间: 2019年7月18日, 11:39:00 MD5: 308478BF7D1B9370B57A40A8AF0EAB8A SHA1: B8C393B2A7FCD31B838FBDCDFCADCACA53035CF8 CRC32: D5E9C2A0 链接：https://pan.baidu.com/s/18rE_OP-rsJZA4xTYAuDv9A 提取码：pzyw ","link":"http://quansen88.cn/geng-xin-shuo-ming/"},{"title":"zabbix监控入门基础，监控tomcat，主被动模式","content":"（三）zabbix监控入门基础，监控tomcat，主被动模式 通过apt/yum安装zabbix-agent，对tomcat监控，导入模版 JMX监控参考官方文档：https://www.zabbix.com/documentation/4.0/zh/manual/config/items/itemtypes/jmx_monitoring zabbix_agent配置文件选项参考：https://www.zabbix.com/documentation/4.0/zh/manual/appendix/config/zabbix_agentd zabbix_server配置文件选项参考：https://www.zabbix.com/documentation/4.0/zh/manual/appendix/config/zabbix_server 资料在这：https://www.lanzous.com/i85szqh包含模版，脚本，pdf文档等 一、zabbix agent安装 下面是服务器是ubuntu18.04的系统， 二、配置zabbix_agentd.conf 所以下面这个配置就是被动模式的配置。被动模式需要zabbix server 可以访问agent的10050端口。 主动模式需要配置ServerActive到server的IP，并且zabbix server要允许客户端连接自己的10051端口 三、web界面添加主机 先创建组，不同业务用组来区分 配置 -&gt; 主机群组 -&gt; 创建主机群组 然后添加主机 配置 -&gt; 主机 -&gt;添加主机-&gt; 填写主机信息 -&gt; 添加模版（模版里有监控项，告警，图表等） 绿了就正常 四、用zabbix_get检测主机是不是通 zabbix_get用来检测agent端的监控项 可以查看图标看是否有数据 五、监控tomcat 学习通过java gateway实现对tomcat的指标进行数据采集和图形展示，如堆栈内存利用率当前会话连接数，繁忙线程等。 5.1 给tomcat服务器(ubuntu18.04)安装zabbix agent 上面zabbix_agentd.conf的配置因为没有指定ServerActice，因此是被动模式，通过抓包可以看看数据怎么传输的,被动模式是zabbix server的随机端口请求agent的10050端口 5.2 准备java环境 参考：https://xyz.uscwifi.xyz/post/D_3XBdJBN/ 5.3 准备tomcat 5.4 部署java gateway服务器 jave gateway是一台独立于zabbix server 和zabbix agent的组件，也就是java gateway 可以是一台单独的服务器，但是也可以和zabbix server 或者zabbix agent公用一台服务器，前提是端口别冲突了。 本次条件有限，和zabbix server公用一台 安装zabbix-java-gateway并修改配置 5.5 配置zabbix server 调用java gateway 5.6 tomcat开启JMX监控 参考：https://www.zabbix.com/documentation/4.0/zh/manual/config/items/itemtypes/jmx_monitoring 参考：https://blog.csdn.net/Hu_wen/article/details/53587250?locationNum=14&amp;fps=1 JMX在JAVA编程语言中定义了应用程序以及网络管理和监控的体系结构、设计模式、应用程序接口以及服务，通常使用JMX来监控系统的运行状态 参考：https://www.jianshu.com/p/8c5133cab858 这里加参数遇到了坑，下面的方法可行，这个谁的文档不能用，这里要么写成一行，要么写成多行 上面图片写法报这个错误： 5.7 通过jconsole验证JMX数据 通过这个链接：https://docs.oracle.com/javase/1.5.0/docs/guide/management/jconsole.html 知道jconsole在jdk_home/bin下面 C:\\Program Files\\Java\\jdk1.8.0_102\\bin 5.8 zabbix server添加 JMX监控项 zabbix模版里有这个JMX模版 5.9 导入zabbix模版 资料在这：https://www.lanzous.com/i85szqh 5.10 Linix获取JMX监控指标 使用jar包 资料在这：https://www.lanzous.com/i85szqh 脚本获取：https://zabbix.org/wiki/Docs/howto/zabbix_get_jmx反正我是没成功 六、zabbix主动与被动模式 6.1 被动模式介绍 无论主动模式，被动模式，都是基于zabbis_agent的。 被动模式：zabbix server周期性向agent发送数据收集指令。被动模式下，zabbix server 会根据主机关联的模版中的监控项和数据采集间隔时间，周期性地打开随机端口向agent的10050端口发起tcp连接，然后发送获取监控项数据的指令，即zabbix server发送什么指令，zabbix agent就收集什么数据，zabbix server什么时候发送，zabbix agent就什么时候采集；zabbix server一直不发送，zabbix agent就一直不采集不响应，所以zabbix agent不关系监控项和监控间隔。 **被动模式优势：**配置简单，安装后即用，也是zabbix的默认监控模式， **被动模式缺点：**加大zabbix server工作量，在数百上千台服务器下会导致zabbix server 需要轮训每个agent 发送数据采集指令，会导致zabbix server 压力山大，负载高的话还无法获取到最新的数据。 之前公司的zabbix基本都是被动模式监控，200台服务器其实压力还好，配置8核16G 6.12被动模式端口状态 之前tcpdump抓包其实也看到了 6.3 主动模式介绍 主动模式：zabbix agent主动向zabbix server的10051端口发起tcp请求，因此主动模式下必须在zabbix agent配置文件中指定zabbix server的Ip和ServerActive均为server的IP 在连接到zabbix server之前，agent也不知道自己要采集哪些数据，隔多久采集一次，连接到zabbix server后获取到自己的监控项和收集间隔，然后再去采集并返回zabbix server，这样zabbix server就很轻松了 总结：可以把zabbix server看成包租婆，agent就是租她房子的。主动模式就是agent坐在那收钱就行；被动模式就是包租婆挨家挨户跑去收钱。跑着当然累咯，哪有坐着收钱舒服 6.4 修改监控模式为主动模式 将mysql这个服务器的监控模式改下，只需要设置SererActive即可 [root@tomcat1 ~]# ss -an 6.5 生成主动模式模版 配置-&gt; 模版-&gt; 选择模版 -&gt; 全克隆 -&gt;新的模版 新的模版-&gt; 监控项 -&gt;批量更新 -&gt; 类型修改为客户端(主动式) 配置-&gt; 主机-&gt;选择主机 -&gt;取消原来的模版，替换为新的主动式模版 ","link":"http://quansen88.cn/zabbix-jian-kong-ru-men-ji-chu-jian-kong-tomcatzhu-bei-dong-mo-shi/"},{"title":"zabbix规划及部署，语言修改","content":"（二）zabbix规划及部署，语言修改 一、部署环境： 主机名 用途 IP 配置 系统 zabbix zabbix server+web 192.168.38.159 4C1G ubuntu18.04 mysql1 数据库 192.168.38.160 4C512MB ubuntu18.04 二、系统优化 内核各种调优，基础软件安装，略 参考：https://xyz.uscwifi.xyz/post/VmFRRSpr1/ 三、安装zabbix 参考：https://www.zabbix.com/cn/download 每个版本怎么装很详细。 3.1 安装zabbix源 3.2 安装Zabbix server，Web前端，agent 3.3 安装部署数据库 安装数据库，配置数据库目录 创建数据库 导入初始架构和数据，系统将提示您输入新创建的密码。 四、配置zabbix配置文件 五、配置zabbix前端 七、安装配置php7.2 php应当调优，进程数等 六、配置nginx，卸载apache zabbix的web界面应当加密一下 zabbix的web界面应当加密一下 七、安装zabbix http://192.168.38.159:81/setup.php 按照提示修改php参数： 八、zabbix修改语言为中文 8.1 要先安装中文语言包 参考：https://blog.csdn.net/qq_33317586/article/details/83869005 不然没法选： 8.2 重启zabbix，nginx，php 8.3 然后就有了 没有就重启把 8.4 从windows拷一个字体到服务器 微软雅黑，楷体，都行，拷一个 C:\\Windows\\Fonts\\阿里巴巴普惠体 -&gt;/var/www/zabbix/assets/fonts 如下图所示，改个名字就行 然后显示就正常了 ","link":"http://quansen88.cn/zabbix-gui-hua-ji-bu-shu-yu-yan-xiu-gai/"},{"title":"Vim编辑器与正则表达式实验手册","content":"4.20Vim编辑器与正则表达式实验手册 手册： 下载:https://www.lanzous.com/i569qhi 密码:c54x 1、 2、 1、 1、 1、 1、 1、 1、 1、 1、 1、 1、 1、 1、 1、 1、 1、 1、 1、 1、 1、 1、 1、 1、 1、 1、 1、 1、 1、 1、 1、 1、 1、 1、 1、 1、 ","link":"http://quansen88.cn/vim-bian-ji-qi-yu-zheng-ze-biao-da-shi-shi-yan-shou-ce/"},{"title":" 3.文件管理 实验手册","content":"3.文件管理 实验手册 实验目的 掌握创建和查看文件、复制、转移和删除文件 前提准备 linux系统，centos6系统，centos7或ubuntu 实验步骤 -：表示普通文件 d：表示目录文件 c：表示字符设备文件 b：表示块设备文件 l：表示软链接文件 p：表示管道文件 s：表示套接字文件 【例1】查看文件类型 显示结果中，第一个位置的符号&quot;-&quot;就代表了文件类型为普通文件 1、pwd命令：显示当前shell的工作目录 【例2】显示当前shell的工作目录 2、basename命令：取路径基名 【例3】获取/etc/sysconfig/的基名 3、dirname命令：取路径名 【例4】取/etc/sysconfig路径名 4、cd命令：切换目录 【例5】切换到用户家目录 或： 【例6】切换到父目录 【例7】切换到/etc/sysconfig目录下 【例8】切换到上一次所在的目录 5、ls命令：列出目录的内容 选项： ​ -a：包含隐藏文件 ​ -l：显示额外信息 ​ -R：目录递归显示 ​ -1：文件分行显示，一行显示一个 【例9】显示当前目录下所有文件 【例10】显示目录内容外的额外信息 或 【例11】递归显示目录内容 【例12】组合应用 6、stat命令：查看文件状态 【例13】查看test.txt文件的状态，注意三个时间戳 7、touch命令：创建空文件和刷新时间 touch一个已经存在的文件，不会改变文件内容，但会改变文件的时间，比如mtime等 【例14】创建空文件test.sh 8、cp命令 【例15】把/etc/httpd/conf/httpd.conf和/etc/my.cnf两个文件拷贝到当前目录 【例16】把/etc/nginx目录及其下面所有文件和子目录拷贝到当前目录 【例17】复制httpd.conf文件并重命名为httpd.conf.bak 【例18】复制/etc目录下面所有文件及其子目录并重命名为/etc_bak 9、mv命令：移动文件或目录。注意：移动目录时，无需添加-R递归选项，要与cp命令区别 【例19】把当前目录下nginx目录重命名为nginx_bak 【例20】把httpd.conf文件移动到/tmp目录下面 10、rm命令：删除文件或目录 【例21】删除当前目录下所有文件 11、mkdir命令 【例22】创建目录a，其下包含b和c两目录，且b和c目录下面都有一个目录d 12、tree命令：显示目录树 【例23】显示a目录的目录树 【例24】查看/usr/local目录树，但仅查看2级的目录深度 13、ln命令：创建链接文件 【例25】把/usr/sbin/apachectl文件在当前目录下创建软链接为apachectl ","link":"http://quansen88.cn/3wen-jian-guan-li-shi-yan-shou-ce/"},{"title":"podman制作镜像","content":"20200905podman制作镜像 podman制作镜像 原帖地址http://quansen88.cn/post/zhi-zuo-podman-jing-xiang podman是使用docker容器格式的容器管理软件，有k8s的pod容器组理念 一、安装 详见：https://podman.io 这里我用的是centos 二、编写Dockerfile或Containerfile dockerfile参考：https://www.runoob.com/docker/docker-dockerfile.html 建立利用Containerfiles说明生成的图像:https://podman.readthedocs.io/en/latest/markdown/podman-build.1.html podman的使用与docker十分相似，甚至可以使用docker的Dockerfile构建镜像 我最近的dockerfile: *我遇到的错误：COPY mc-server / ,其相当于 cp mc-server/ / ** 使用 COPY 时，会自动创建不存在的目录 COPY 源文件需要放在dockerfile同属文件夹或子文件夹，也无法使用绝对路径，必须使用相对路径 三、构建镜像 podman构建镜像，事实上只是将docker改成podman '.'表示当前目录下的Dockerfile 四、podman试运行镜像 查看运行进程 运行截图： 运行成功！ 官方建议：其中docker ps 是别名，因为使用习惯一时半会改不过来 改别名： 五、未完待续 ","link":"http://quansen88.cn/podman-zhi-zuo-jing-xiang/"},{"title":"docker/podman一键部署postwoman","content":"20200905docker/podman一键部署postwoman 官网：https://postwoman.io/ 一、一键部署postwoman命令： latest指的是dockerhub中该镜像的最新版本 二、查看是否成功 -p 3000:3000 那我们在网页中打开容器z所在ip的端口3000 登录后画面如下 成功 ","link":"http://quansen88.cn/dockerpodman-yi-jian-bu-shu-postwoman/"},{"title":"docker/podman快速部署jumpserver","content":"20200905docker/podman快速部署jumpserver 参考:https://hub.docker.com/r/jumpserver/jms_all jms是跳板机的英文缩写，使用容器方式启动更加方便，省资源 一、一键部署 参考:https://docs.jumpserver.org/zh/master/install/docker_install/ linux生成随机数密码 这一步是为了安全考虑 启动容器 podman:podman已经别名成docker的用户请直接运行 docker可以自动拉取hub上存在的镜像 二、检查运行情况 打开网页，输入容器所属服务器ip:80，查看界面 ","link":"http://quansen88.cn/dockerpodman-kuai-su-bu-shu-jumpserver/"},{"title":"制作我的世界服务器docker容器镜像","content":"我的世界、开服日志 <!-- more --> 20200829制作我的世界服务器docker容器镜像 本文原地址：http://quansen88.cn/post/zhi-zuo-wo-de-shi-jie-fu-wu-qi-docker-rong-qi-jing-xiang/ 一、vim 一个 Dockerfile 文件 参考：http://quansen88.cn/post/zai-ben-di-da-jian-wo-de-shi-jie-fu-wu-qi-yi/ 二、构建镜像 三、运行容器 四、测试游戏 五、完成！记得点赞 ","link":"http://quansen88.cn/zhi-zuo-wo-de-shi-jie-fu-wu-qi-docker-rong-qi-jing-xiang/"},{"title":"vmware-minecraft-server(我的世界服务器一)","content":"20200817vmware-minecraft-server(我的世界服务器一) 帖子原址：http://quansen88.cn/post/zai-ben-di-da-jian-wo-de-shi-jie-fu-wu-qi-yi/ 搭建我的世界服务器.logs centos7 https://msdn.itellyou.cn server.jar(测试版本：minecraft1.16.2) https://www.minecraft.net/zh-hans/download/server 一、安装与启动 下载服务器包时会给你一条命令 稍加思索 1. 安装java 一般需要注意版本兼容，本次测试没有问题，java1.8 2. 对官网的命令稍加修改 因为下载的文件，与命令中略微不同 然后会报错，不要慌，下一步 3. 根据提示修改配置文件eula.txt 编辑文件如下，即eula=flase改为eula=true 4.再次执行java 5.未完待续，下一期：如何让客户端测试连接 脚本、命令历史 ","link":"http://quansen88.cn/vmware-minecraft-serverwo-de-shi-jie-fu-wu-qi-yi/"},{"title":"ssh的优化","content":"20200819ssh的优化 原址:quansen88.cn/post/ssh-de-you-hua 一、添加端口 注意查看是否修改成功，有些机器已经取消port 22端口的‘#’注释了 二、禁止root用户登录 三、禁止空密码登录 四、优化 ssh连接过慢，DNS轮询导致的问题： 五、GSSAPIAuthentication，这个作用是为了时ssh连接更加快 ","link":"http://quansen88.cn/ssh-de-you-hua/"},{"title":"github-pages网页跳转（旧域名重定向到新域名）","content":"20200815-github-pages网页跳转（旧域名重定向到新域名） 原址：http://quansen88.cn/post/jiu-yu-ming-chong-ding-xiang-dao-xin-yu-ming/ 一、创建并编辑 index.html 其中http://quansen88.cn是新域名 二、创建并编辑 文件CNAME 无后缀，大写，里面填上旧域名 三、将文件上传到github的 纯净博客仓库（用户名.github.io） 创建仓库 ---&gt; 仓库名：（用户名.github.io）---&gt; 上传文件 一般来讲需要重新注册一个github,专门用于此事 四、设置github pages 依次打开github----&gt; 仓库_用户名.github.io -----&gt; 设置（settings） -----&gt; options (默认) -----&gt; github pages -----&gt; Source -----&gt; master -----&gt; save (保存) 刷新后会显示旧域名， 这时仓库名作为网址已经可以重定向到新域名，并且允许旧域名解析 五、域名解析 在旧域名上解析仓库名即可 ","link":"http://quansen88.cn/github-pages-wang-ye-tiao-zhuan-jiu-yu-ming-chong-ding-xiang-dao-xin-yu-ming/"},{"title":"磁盘清理","content":"20200729磁盘清理 一、查看下哪个分区磁盘利用率高 二、统计哪个目录最大 用到的命令 结果如下： 查得omiagent是azure自带的进程，kill -1了算了 ","link":"http://quansen88.cn/ci-pan-qing-li/"},{"title":"命令git开启代理加速","content":"20200719命令git开启代理加速 克隆github的代码太慢，解决办法： 1.两条命令 某代理软件的端口图 代理前 9.00 KiB/s，代理后1.31 MiB/s ","link":"http://quansen88.cn/ming-ling-git-kai-qi-dai-li-jia-su/"},{"title":"手把手从零安装win10-2004","content":"20200717手把手从零安装win10-2004 一、下载系统镜像 引用https://msdn.itellyou.cn/ 转到https://next.itellyou.cn/Original/Index#cbp=Product?ID=f905b2d9-11e7-4ee3-8b52-407a8befe8d1 消费者版64位迅雷链接 二、制作启动盘 参考https://blog.csdn.net/qq_30633777/article/details/84934977 下载微PE的安装程序(老版电脑使用v1.2) 链接：https://pan.baidu.com/s/1ironNRbDAwidktr27Flo0A 提取码：49yo 官网：http://www.wepe.com.cn/download.html?tdsourcetag=s_pcqq_aiomsg 打开工具（.exe），选好U盘和格式，点击立即安装，！！！危险操作！！！，检查备份。 完成后如下，再将下载好的系统镜像（.iso）放入U盘 三、安装系统 镜像放入后，将U盘插入需要重装的电脑主机上，进入dos系统界面，选择U盘启动 选择U盘启动（一般是默认选项），进入后打开CGI一键恢复，选择磁盘分区和镜像文件，点击执行 执行后弹窗如下，确认无误，再选择’完成后关机‘，点击’确定‘，待重装完成，记得**！！！拔掉U盘！！！**，再开机确认一下。 四、安装完成 ","link":"http://quansen88.cn/shou-ba-shou-cong-ling-an-zhuang-win10-2004/"},{"title":" 更换内核","content":"更换内核 vps系统选择CentOS7，用root用户登录系统，执行下面命令： 安装 yum install -y linux-firmware perl tar wget 下载三个包 wget https://dl.lamp.sh/kernel/el7/kernel-ml-5.10.16-1.el7.elrepo.x86_64.rpm wget https://dl.lamp.sh/kernel/el7/kernel-ml-devel-5.10.16-1.el7.elrepo.x86_64.rpm wget https://dl.lamp.sh/kernel/el7/kernel-ml-headers-5.10.16-1.el7.elrepo.x86_64.rpm 安装 yum localinstall kernel-ml-* 设置启动顺序 执行 awk -F' '$1==&quot;menuentry &quot; {print i++ &quot; : &quot; $2}' /boot/grub2/grub.cfg 查看最新的5.10.16是否排在第一行（第0位） 如果是则执行 grub2-set-default 0 再执行 grub2-editenv list 上面命令执行完毕后，执行reboot命令重启系统 重启系统后执行 uname -a 查看内核版本，是否正确更换到了5.10.16 来自 https://shiping.date/archives/how_to_install_wireguard_on_centos7_and_how_to_use_it_simply.html ","link":"http://quansen88.cn/geng-huan-nei-he/"},{"title":"贪吃蛇静态网站","content":"贪吃蛇静态网站 2021年3月25日 19:31 宝塔面板 搭建贪吃蛇 静态网站 一、准备 1. 工具： 宝塔面板 2. 环境：[宝塔环境] LNMP 二、创建站点 1. 在宝塔页面添加站点 进入宝塔页面后， 点击： 网站——添加站点——输入域名——点击创建即可 三、下载文件 1. 切换到，刚才创建的站点的目录 # cd /www/wwwroot/snake.quansen88.cn/ 四、验证是否成功 五、添加证书 若需要创建证书，参见相关教程。 已有证书可直接添加 ","link":"http://quansen88.cn/tan-chi-she-jing-tai-wang-zhan/"},{"title":"docker生成免费Ssl 证书","content":"docker生成免费Ssl 证书 2021年3月21日 13:17 第一步 使用acme镜像启动容器 docker run --rm -it -v /opt/acme:/acme neilpang/acme.sh sh 第二步 为这两个域名颁发证书 quansen88.cn *.quansen88.cn acme.sh --issue -d quansen88.cn -d &quot;*.quansen88.cn&quot; --dns dns_01 执行后会提示 按照提示在阿里云域名解析里面设置txt解析 然后执行以下命令，再次颁发证书 【其中添加了--renew选项表示重新申请证书】 acme.sh --issue -d quansen88.cn -d &quot;*.quansen88.cn&quot; --dns dns_01 --renew 执行结果如下 将证书持久化到宿主机 目录【如opt/acme/】 cp -a /acme.sh/quansen88.cn/ /acme ","link":"http://quansen88.cn/docker-sheng-cheng-mian-fei-ssl-zheng-shu/"},{"title":"office下载到安装","content":"20200716office下载到安装 一、下载office2019 https://msdn.itellyou.cn/ 二、安装 双击此文件（.镜像），挂载到驱动器 打开此驱动器，双击打开安装文件（.exe） 三、激活 参考：https://hub.docker.com/r/luodaoyi/kms-server 激活报错： 经查得office不是vl版本，需要安装vlkey，但是又报错 安装vlkey参考：https://xyz.uscwifi.xyz/post/9S2_vcvwJ/ 通过报错查得，需要使用一个脚本，将office转换成vl版本 参考：https://blog.csdn.net/alinathz/article/details/92630091 将下面脚本写入一个txt文档，修改后缀为bat，管理员身份执行这个脚本 脚本执行完成如下图 现在office版本变成vl版本，可以使用激活命令 执行成功如下 四、重启电脑 查看office激活状态，显示激活： ","link":"http://quansen88.cn/office-xia-zai-dao-an-zhuang/"},{"title":" centos7安装zabbix5.0","content":"centos7安装zabbix5.0 ！root用户！ #命令 一、安装mysql 参考：https://blog.csdn.net/qq_36582604/article/details/80526287 1 下载并安装MySQL官方的 Yum Repository 使用上面的命令就直接下载了安装用的Yum Repository，大概25KB的样子，然后就可以直接yum安装了。 之后就开始安装MySQL服务器。 这步可能会花些时间，安装完成后就会覆盖掉之前的mariadb。 2 MySQL数据库设置 首先启动MySQL 此时MySQL已经开始正常运行，不过要想进入MySQL还得先找出此时root用户的密码，通过如下命令可以在日志文件中找出密码： 如下命令进入数据库： 输入初始密码（是上一步最后面的‘5axt_ktGs:jm’），此时不能做任何事情，因为MySQL默认必须 修改密码之后才能操作数据库： 其中‘new password’替换成你要设置的密码，注意:密码设置必须要大小写字母数字和特殊符号（,/';:等）,不然不能配置成功 二、下载zabbix 参考：https://www.zabbix.com/cn/download?zabbix=5.0&amp;os_distribution=centos&amp;os_version=7&amp;db=mysql&amp;ws=nginx 1. 选择系统 详见上述参考链接 2. 选择您Zabbix服务器的平台 a. 安装 zabbix的软件仓库 b. 安装Zabbix服务器和代理 C。安装Zabbix前端web界面 编辑配置文件 /etc/yum.repos.d/zabbix.repo 并启用zabbix-frontend存储库。 安装Zabbix前端软件包。 d. 创建初始数据库 在数据库主机上运行以下命令。 其中‘password’替换成你要设置的密码，注意:密码设置必须要大小写字母数字和特殊符号（,/';:等）,不然不能配置成功 导入初始架构和数据，系统将提示您输入新创建的密码。 e. 为Zabbix server配置数据库 编辑配置文件 /etc/zabbix/zabbix_server.conf 其中‘password’替换成你要设置的密码 f. 为Zabbix前端配置PHP 编辑配置文件 /etc/opt/rh/rh-nginx116/nginx/conf.d/zabbix.conf 取消注释并设置“ listen”和“ server_name”指令。 其中‘example.com’可以替换成你要设置的域名（或可能 ip，未测试） 编辑配置文件 /etc/opt/rh/rh-php72/php-fpm.d/zabbix.conf 将nginx添加到listen.acl_users指令。 然后取消注释并为您设置正确的时区。 其中，前缀分号“;”为注释符 g. 启动Zabbix server和agent进程 启动Zabbix server和agent进程，并为它们设置开机自启： h. 配置Zabbix前端 连接到新安装的Zabbix前端： http://server_ip_or_name 根据Zabbix文件里步骤操作： Installing frontend 3. 开始使用Zabbix 查看快速开始指南 安装前端 步骤1 在浏览器中，打开Zabbix URL：http：// &lt;server_ip_or_name&gt; / zabbix 您应该看到前端安装向导的第一个屏幕。 第2步 确保满足所有软件先决条件。 前提条件最低值描述 PHP版本 7.2.0 PHP memory_limit选项 128MB 在php.ini中： memory_limit = 128M PHP post_max_size选项 16MB 在php.ini中： post_max_size = 16M PHP upload_max_filesize选项 2MB 在php.ini中： upload_max_filesize = 2M PHP max_execution_time选项 300秒（允许使用值0和-1） 在php.ini中： max_execution_time = 300 PHP max_input_time选项 300秒（允许使用值0和-1） 在php.ini中： max_input_time = 300 PHP session.auto_start选项 必须禁用 在php.ini中： session.auto_start = 0 数据库支持 其中之一：MySQL，Oracle，PostgreSQL。 必须安装以下模块之一： mysql，oci8，pgsql bcmath php-bcmath mbstring php-mbstring PHP mbstring.func_overload选项 必须禁用 In php.ini: mbstring.func_overload = 0 sockets php-net-socket. Required for user script support. gd 2.0.28 php-gd. PHP GD extension must support PNG images (--with-png-dir), JPEG (--with-jpeg-dir) images and FreeType 2 (--with-freetype-dir). libxml 2.6.15 php-xml xmlwriter php-xmlwriter xmlreader php-xmlreader ctype php-ctype session php-session gettext php-gettext Since Zabbix 2.2.1, the PHP gettext extension is not a mandatory requirement for installing Zabbix. If gettext is not installed, the frontend will work as usual, however, the translations will not be available. 列表中还可能包含可选的先决条件。失败的可选前提条件以橙色显示，并且具有警告状态。如果可选的先决条件失败，则设置可以继续。 第三步 输入用于连接数据库的详细信息。Zabbix数据库必须已经创建。 如果选中了TLS加密选项，则会以以下形式显示另外五个字段，用于配置与数据库的TLS连接：（仅MySQL或PostgreSQL）。 第四步 输入Zabbix服务器详细信息。 输入Zabbix服务器的名称是可选的，但是，如果提交了名称，它将显示在菜单栏和页面标题中。 第5步 查看设置摘要。 第6步 下载配置文件，并将其放在将Zabbix PHP文件复制到的Web服务器HTML文档子目录中的conf /下。 此版本未遇到该情况 步骤7 完成安装。 步骤8 Zabbix前端已准备就绪！默认用户名为Admin，密码为zabbix。 进到入门的zabbix。 ","link":"http://quansen88.cn/centos7-an-zhuang-zabbix50/"},{"title":"nginx配置文件模版","content":"nginx配置文件模版 静态网站模版 ","link":"http://quansen88.cn/nginx-pei-zhi-wen-jian-mo-ban/"},{"title":"AutoPiano：30s部署一个钢琴小程序","content":"AutoPiano：30s部署一个钢琴小程序 一条命令部署 访问ip+端口（1234）例如www.huksxi.xyz:1234其中‘1234‘是上述命令决定 删除 ","link":"http://quansen88.cn/autopiano30s-bu-shu-yi-ge-gang-qin-xiao-cheng-xu/"},{"title":"centos7安装docker","content":"<!-- more --> centos7安装docker 国外服务器： 国内服务器： ​ 国内需要镜像加速！否则安装很慢！ ","link":"http://quansen88.cn/centos7-an-zhuang-docker/"},{"title":"关于","content":" ","link":"http://quansen88.cn/about/"}]}